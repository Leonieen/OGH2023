[
  {
    "objectID": "xcube.html",
    "href": "xcube.html",
    "title": "xcube for Spatiotemporal Data Analysis and Visualization",
    "section": "",
    "text": "Date: 2023-08-30, 15:30–17:00 Speaker: Alicja Balfanz"
  },
  {
    "objectID": "xcube.html#introduction-to-xcube",
    "href": "xcube.html#introduction-to-xcube",
    "title": "xcube for Spatiotemporal Data Analysis and Visualization",
    "section": "Introduction to xcube",
    "text": "Introduction to xcube\nThis session provided an in-depth exploration of xcube, an open-source Python package based on xarray, designed for Earth observation (EO) data analysis. The focus was on transforming EO data into analysis-ready, self-contained data cubes suitable for cloud publishing.\nxcube is an innovative open-source software package developed primarily for processing and analyzing Earth Observation (EO) data. Based on the xarray package, xcube is designed to handle spatiotemporal data efficiently, making it a powerful tool in the field of remote sensing and geospatial data analysis."
  },
  {
    "objectID": "xcube.html#key-features-of-xcube",
    "href": "xcube.html#key-features-of-xcube",
    "title": "xcube for Spatiotemporal Data Analysis and Visualization",
    "section": "Key Features of xcube",
    "text": "Key Features of xcube\n\nData Cube Technology: xcube transforms traditional EO data into multidimensional data cubes, making it easier to manipulate and analyze large datasets over space and time.\nAnalysis-Ready Data: The package focuses on providing data in an analysis-ready format. This means that users can spend less time on data preprocessing and more on actual analysis.\nCloud Compatibility: xcube’s data cubes can be published and stored in the cloud, facilitating easy access and scalable analysis.\nSupport for Various EO Data Sources: xcube is designed to work with data from various EO missions, including but not limited to Landsat and Sentinel. This makes it versatile for different types of environmental analysis."
  },
  {
    "objectID": "xcube.html#workshop-objectives-and-coverage",
    "href": "xcube.html#workshop-objectives-and-coverage",
    "title": "xcube for Spatiotemporal Data Analysis and Visualization",
    "section": "Workshop Objectives and Coverage",
    "text": "Workshop Objectives and Coverage\n\nxcube Ecosystem: Introduction to the ecosystem surrounding xcube, including its software components and functionalities.\nData Cube Generation: Learning how xcube converts various EO data sources into accessible data cubes.\nSpatiotemporal Analysis and Visualization: Hands-on experience in using these data cubes for in-depth spatiotemporal data analysis and visualization."
  },
  {
    "objectID": "xcube.html#embedding-workshop-materials",
    "href": "xcube.html#embedding-workshop-materials",
    "title": "xcube for Spatiotemporal Data Analysis and Visualization",
    "section": "Embedding Workshop Materials",
    "text": "Embedding Workshop Materials"
  },
  {
    "objectID": "sentinel2.html",
    "href": "sentinel2.html",
    "title": "Sentinel-2 data in R",
    "section": "",
    "text": "The libraries we will use for this exercise are listed below.\n\nlibrary(dplyr) # data wrangling\nlibrary(gdalcubes) # on-demand data cubes\nlibrary(ggplot2) # plotting\nlibrary(here) # resolve relative paths\nlibrary(knitr) # visualize URLs\nlibrary(osmdata) # retrieving OSM data, AOI bounding box\nlibrary(rstac) # connecting to the STAC API\nlibrary(sf) # handle geospatial data frames\nlibrary(stars) # handle spatio-temporal arrays\n\n\n\nWe will obtain our area of interest with the osmdata package.\n\n## 405 error last time tested\naoi = getbb(\"poznan poland\", format_out = \"sf_polygon\", limit = 1)\n\n\n## backup geojson\naoi = read_sf(here(\"data/poznan.geojson\"))\n\nWe can make sure the AOI is correct (run cell on source .qmd)\n\nmapview::mapview(aoi)\n\nAnd lastly the time extent:\n\ntime_extent = c(\"2022-04-01\", \"2022-10-01\")\n\nWe compute the bounding box both in EPSG:4326 and EPSG:3857.\n\nbb4326 = st_bbox(aoi)\nbb3857 = aoi |&gt; \n  st_transform(3857) |&gt; \n  st_bbox()\n\n\n\n\nSimilarly to the pystac-client in Python, with rstac we define our STAC API URL, from where we can query the collections available.\nLet’s stay with the earth-search API.\n\ns = stac(\"https://earth-search.aws.element84.com/v0\")\ncollections(s) |&gt; get_request()\n\nTo search for the data we will refer to the parameters we defined during the extent definition.\n\nitems = s  |&gt; \n    stac_search(\n      collections = \"sentinel-s2-l2a-cogs\",\n      bbox = c(\n        bb4326[\"xmin\"], bb4326[\"ymin\"], \n        bb4326[\"xmax\"], bb4326[\"ymax\"]\n      ), \n      datetime = paste0(time_extent, collapse = \"/\"),\n      limit = 500\n    ) |&gt; \n    post_request() \n\nitems\n\n\n\n\n\n\n\nQuiz\n\n\n\nCan you spot the difference between the search exercise with Python and R?\n\n\nWe can explore the items as sf objects:\n\n(i = items_as_sf(items))\n\nAnd easily view the cloud cover for the area:\n\nggplot(i) +\n  aes(x = as.Date(datetime), y = `eo:cloud_cover`) +\n  geom_point() +\n  geom_line(group = 1) +\n  scale_x_date(date_breaks = \"2 months\")\n\nThe item properties can prove useful to filter the data collection we just obtained.\nLet’s take a look at the properties present.\n\nitems$features[[1]]$properties\n\nWe already explored the eo:cloud_cover property, but there are other properties that might turn out useful, e.g. sentinel:valid_cloud_cover and sentinel:data_coverage.\nWe can filter the sf object we created before for this values and select the first item from our result.\n\nids = i |&gt; \n  mutate(fid = row_number()) |&gt; \n  filter(\n    `sentinel:valid_cloud_cover` == 1, \n    `sentinel:data_coverage` &gt;= 80,\n    `eo:cloud_cover` == min(`eo:cloud_cover`)\n  ) |&gt; \n  pull(fid)\nitem = items$features[[ids[1]]]\n\nWe can take a look at a preview of one item by getting the URL of the thumbnail asset. Note that rstac has a preview_plot function but it does not accept JPG formats yet.\n\nitem |&gt; \n  assets_url(asset_names = \"thumbnail\") |&gt; \n  include_graphics()\n\n\n\n\nOnce we have made our query and fetched the data, we can create an on-demand data cube with gdalcubes.\nWe can filter the times collection with the property_filter parameter. As we saw before we will keep only scenes with valid cloud cover values below 10%.\n\nassets = c(\n  \"B01\",\"B02\",\"B03\",\"B04\",\"B05\",\"B06\",\n  \"B07\",\"B08\",\"B8A\",\"B09\",\"B11\",\"SCL\"\n)\ncol = stac_image_collection(\n  items$features,\n  asset_names = assets,\n  property_filter = function(x) {x[[\"eo:cloud_cover\"]] &lt; 10 & x[['sentinel:valid_cloud_cover']]}\n)\ncol\n\n\n\n\nTo view the data, we create a cube_view() object considering the AOI defined before but with EPSG:3857.\nArguments dx and dy define the spatial resolution of our output, while dt corresponds to the temporal resolution.\n\n\n\n\n\n\nQuiz\n\n\n\nHow would you define a biweekly temporal interval? Hint ?cube_view().\n\n\n\nv = cube_view(\n  srs = \"EPSG:3857\",  \n  extent = list(t0 = time_extent[1],\n                t1 = time_extent[2],\n                left = bb3857[\"xmin\"],\n                bottom = bb3857[\"ymin\"], \n                right = bb3857[\"xmax\"],\n                top = bb3857[\"ymax\"]),\n  dx = 200, dy = 200, dt = \"P1D\",\n  aggregation = \"median\",\n  resampling = \"average\"\n)\n\nA cloud mask can also be defined. This will be based on the SCL values.\nFor that let’s first expand on SCL, which is the result of the Sentinel-2 scene classification.\nWe will use the stars package to visualize the layer. But first we let’s select an item with moderate cloud cover to have an idea of the values present.\n\nids = i |&gt; \n  mutate(fid = row_number()) |&gt; \n  filter(\n    `sentinel:valid_cloud_cover` == 1, \n    `sentinel:data_coverage` &gt;= 90,\n    `eo:cloud_cover` &lt;= 50\n  ) |&gt; \n  pull(fid)\nitem = items$features[[ids[1]]]\n\nscl_ex = item |&gt; \n  assets_url(asset_names = \"SCL\", append_gdalvsi = TRUE) |&gt;\n  read_stars(RasterIO = list(nBufXSize = 512, nBufYSize = 512))\n\nIn the data folder of this repo I added a CSV file with the SCL classes that we will use for plotting.\n\nscl = read.csv(\"../../data/SCL_classes.csv\")\nscl = scl |&gt; \n  mutate(label = paste(code, desc, sep = \": \"))\nscl_pal = scl$color\nnames(scl_pal) = scl$label\nscl_ex_factor = scl_ex |&gt; \n  mutate(\n      SCL.tif = factor(SCL.tif, levels = scl$code, labels = scl$label)\n    )\nggplot() +\n  geom_stars(data = scl_ex_factor) +\n  scale_fill_manual(values = scl_pal) +\n  theme_void()\n\nWe can then see that masking out clouds would require to reference classes 3, 8 and 9.\n\n# clouds and cloud shadows\nS2.mask = image_mask(\"SCL\", values=c(3,8,9)) \n\nFinally, we can visualize a median composite of our collection. This particular chunk will take a while since the data is fetched from the cloud before plotting. For this reason we include the gdalcubes_options(parallel = 4) line which would use any parallel processing available in your system. We will run this code chunk interactively.\n\ngdalcubes_options(parallel = 4) \nraster_cube(col, v, mask = S2.mask) |&gt; \n    select_bands(c(\"B02\",\"B03\",\"B04\")) |&gt; \n    reduce_time(c(\"median(B02)\", \"median(B03)\", \"median(B04)\")) |&gt; \n    plot(rgb = 3:1, zlim=c(0,1800)) \n\n\n\n\nNowadays, there is a lot that can be done to process data on the cloud. However, if you still need to download datasets, rstac will have you covered with the assets_download() function. This will download all of the items from your search, so make sure you apply enough filtering so that you don’t download data that you don’t need. More info on the function can be found on the package documentation."
  },
  {
    "objectID": "sentinel2.html#accessing-data-via-stac-apis",
    "href": "sentinel2.html#accessing-data-via-stac-apis",
    "title": "Sentinel-2 data in R",
    "section": "",
    "text": "The libraries we will use for this exercise are listed below.\n\nlibrary(dplyr) # data wrangling\nlibrary(gdalcubes) # on-demand data cubes\nlibrary(ggplot2) # plotting\nlibrary(here) # resolve relative paths\nlibrary(knitr) # visualize URLs\nlibrary(osmdata) # retrieving OSM data, AOI bounding box\nlibrary(rstac) # connecting to the STAC API\nlibrary(sf) # handle geospatial data frames\nlibrary(stars) # handle spatio-temporal arrays\n\n\n\nWe will obtain our area of interest with the osmdata package.\n\n## 405 error last time tested\naoi = getbb(\"poznan poland\", format_out = \"sf_polygon\", limit = 1)\n\n\n## backup geojson\naoi = read_sf(here(\"data/poznan.geojson\"))\n\nWe can make sure the AOI is correct (run cell on source .qmd)\n\nmapview::mapview(aoi)\n\nAnd lastly the time extent:\n\ntime_extent = c(\"2022-04-01\", \"2022-10-01\")\n\nWe compute the bounding box both in EPSG:4326 and EPSG:3857.\n\nbb4326 = st_bbox(aoi)\nbb3857 = aoi |&gt; \n  st_transform(3857) |&gt; \n  st_bbox()\n\n\n\n\nSimilarly to the pystac-client in Python, with rstac we define our STAC API URL, from where we can query the collections available.\nLet’s stay with the earth-search API.\n\ns = stac(\"https://earth-search.aws.element84.com/v0\")\ncollections(s) |&gt; get_request()\n\nTo search for the data we will refer to the parameters we defined during the extent definition.\n\nitems = s  |&gt; \n    stac_search(\n      collections = \"sentinel-s2-l2a-cogs\",\n      bbox = c(\n        bb4326[\"xmin\"], bb4326[\"ymin\"], \n        bb4326[\"xmax\"], bb4326[\"ymax\"]\n      ), \n      datetime = paste0(time_extent, collapse = \"/\"),\n      limit = 500\n    ) |&gt; \n    post_request() \n\nitems\n\n\n\n\n\n\n\nQuiz\n\n\n\nCan you spot the difference between the search exercise with Python and R?\n\n\nWe can explore the items as sf objects:\n\n(i = items_as_sf(items))\n\nAnd easily view the cloud cover for the area:\n\nggplot(i) +\n  aes(x = as.Date(datetime), y = `eo:cloud_cover`) +\n  geom_point() +\n  geom_line(group = 1) +\n  scale_x_date(date_breaks = \"2 months\")\n\nThe item properties can prove useful to filter the data collection we just obtained.\nLet’s take a look at the properties present.\n\nitems$features[[1]]$properties\n\nWe already explored the eo:cloud_cover property, but there are other properties that might turn out useful, e.g. sentinel:valid_cloud_cover and sentinel:data_coverage.\nWe can filter the sf object we created before for this values and select the first item from our result.\n\nids = i |&gt; \n  mutate(fid = row_number()) |&gt; \n  filter(\n    `sentinel:valid_cloud_cover` == 1, \n    `sentinel:data_coverage` &gt;= 80,\n    `eo:cloud_cover` == min(`eo:cloud_cover`)\n  ) |&gt; \n  pull(fid)\nitem = items$features[[ids[1]]]\n\nWe can take a look at a preview of one item by getting the URL of the thumbnail asset. Note that rstac has a preview_plot function but it does not accept JPG formats yet.\n\nitem |&gt; \n  assets_url(asset_names = \"thumbnail\") |&gt; \n  include_graphics()\n\n\n\n\nOnce we have made our query and fetched the data, we can create an on-demand data cube with gdalcubes.\nWe can filter the times collection with the property_filter parameter. As we saw before we will keep only scenes with valid cloud cover values below 10%.\n\nassets = c(\n  \"B01\",\"B02\",\"B03\",\"B04\",\"B05\",\"B06\",\n  \"B07\",\"B08\",\"B8A\",\"B09\",\"B11\",\"SCL\"\n)\ncol = stac_image_collection(\n  items$features,\n  asset_names = assets,\n  property_filter = function(x) {x[[\"eo:cloud_cover\"]] &lt; 10 & x[['sentinel:valid_cloud_cover']]}\n)\ncol\n\n\n\n\nTo view the data, we create a cube_view() object considering the AOI defined before but with EPSG:3857.\nArguments dx and dy define the spatial resolution of our output, while dt corresponds to the temporal resolution.\n\n\n\n\n\n\nQuiz\n\n\n\nHow would you define a biweekly temporal interval? Hint ?cube_view().\n\n\n\nv = cube_view(\n  srs = \"EPSG:3857\",  \n  extent = list(t0 = time_extent[1],\n                t1 = time_extent[2],\n                left = bb3857[\"xmin\"],\n                bottom = bb3857[\"ymin\"], \n                right = bb3857[\"xmax\"],\n                top = bb3857[\"ymax\"]),\n  dx = 200, dy = 200, dt = \"P1D\",\n  aggregation = \"median\",\n  resampling = \"average\"\n)\n\nA cloud mask can also be defined. This will be based on the SCL values.\nFor that let’s first expand on SCL, which is the result of the Sentinel-2 scene classification.\nWe will use the stars package to visualize the layer. But first we let’s select an item with moderate cloud cover to have an idea of the values present.\n\nids = i |&gt; \n  mutate(fid = row_number()) |&gt; \n  filter(\n    `sentinel:valid_cloud_cover` == 1, \n    `sentinel:data_coverage` &gt;= 90,\n    `eo:cloud_cover` &lt;= 50\n  ) |&gt; \n  pull(fid)\nitem = items$features[[ids[1]]]\n\nscl_ex = item |&gt; \n  assets_url(asset_names = \"SCL\", append_gdalvsi = TRUE) |&gt;\n  read_stars(RasterIO = list(nBufXSize = 512, nBufYSize = 512))\n\nIn the data folder of this repo I added a CSV file with the SCL classes that we will use for plotting.\n\nscl = read.csv(\"../../data/SCL_classes.csv\")\nscl = scl |&gt; \n  mutate(label = paste(code, desc, sep = \": \"))\nscl_pal = scl$color\nnames(scl_pal) = scl$label\nscl_ex_factor = scl_ex |&gt; \n  mutate(\n      SCL.tif = factor(SCL.tif, levels = scl$code, labels = scl$label)\n    )\nggplot() +\n  geom_stars(data = scl_ex_factor) +\n  scale_fill_manual(values = scl_pal) +\n  theme_void()\n\nWe can then see that masking out clouds would require to reference classes 3, 8 and 9.\n\n# clouds and cloud shadows\nS2.mask = image_mask(\"SCL\", values=c(3,8,9)) \n\nFinally, we can visualize a median composite of our collection. This particular chunk will take a while since the data is fetched from the cloud before plotting. For this reason we include the gdalcubes_options(parallel = 4) line which would use any parallel processing available in your system. We will run this code chunk interactively.\n\ngdalcubes_options(parallel = 4) \nraster_cube(col, v, mask = S2.mask) |&gt; \n    select_bands(c(\"B02\",\"B03\",\"B04\")) |&gt; \n    reduce_time(c(\"median(B02)\", \"median(B03)\", \"median(B04)\")) |&gt; \n    plot(rgb = 3:1, zlim=c(0,1800)) \n\n\n\n\nNowadays, there is a lot that can be done to process data on the cloud. However, if you still need to download datasets, rstac will have you covered with the assets_download() function. This will download all of the items from your search, so make sure you apply enough filtering so that you don’t download data that you don’t need. More info on the function can be found on the package documentation."
  },
  {
    "objectID": "sentinel2.html#exercises",
    "href": "sentinel2.html#exercises",
    "title": "Sentinel-2 data in R",
    "section": "Exercises",
    "text": "Exercises\n\nBased on the examples from the Jupyter notebook, how would you compute the NDVI anomaly with gdalcubes? Go ahead and do it for any area of interest you would like. Get some hints from this r-spatial blog on gdalcubes by Marius Appel.\nCompute a time series of NDVI values for one crop parcel of your choice. Hint: you can easily create a geojson polygon with https://geojson.io/. Take the temporal grouping of your choice, but what would make sense to compare such vegetation values?"
  },
  {
    "objectID": "sentinel2.html#more-resources",
    "href": "sentinel2.html#more-resources",
    "title": "Sentinel-2 data in R",
    "section": "More resources:",
    "text": "More resources:\nThis notebook is a small demo on how to use rstac and gdalcubes to work with Sentinel-2 data in particular. For further examples on data processing with both packages check Marius Appel repository from the OpenGeoHub 2021."
  },
  {
    "objectID": "Sentinel.html",
    "href": "Sentinel.html",
    "title": "Sentinel Satellite Data Analysis Course",
    "section": "",
    "text": "Date: 2023-08-31, 13:30–15:00 and 2023-09-01, 09:00-10:30 Speaker: Lorena Abad\nUnderstanding Sentinel Products: A comprehensive look at the data access methods and processing techniques for Sentinel-1 and Sentinel-2 data.\nSkill Enhancement: Practical training on how to employ Python and R for satellite data analysis, with a focus on processing and interpreting the data from both radar and optical sensors.\nIn this course I’ve gathered invaluable insights and practical skills that have significantly broadened my understanding of satellite data applications. The course provided a robust foundation for working with some of the most sophisticated tools in remote sensing within Python and R environments."
  },
  {
    "objectID": "Sentinel.html#practical-sessions-and-applied-learning",
    "href": "Sentinel.html#practical-sessions-and-applied-learning",
    "title": "Sentinel Satellite Data Analysis Course",
    "section": "Practical Sessions and Applied Learning",
    "text": "Practical Sessions and Applied Learning\nThe course was structured to provide us with direct experience in handling real data sets, exemplified by the Jupyter notebooks we worked on."
  },
  {
    "objectID": "Sentinel.html#sentinel-1",
    "href": "Sentinel.html#sentinel-1",
    "title": "Sentinel Satellite Data Analysis Course",
    "section": "Sentinel 1",
    "text": "Sentinel 1"
  },
  {
    "objectID": "Sentinel.html#sentinel-2",
    "href": "Sentinel.html#sentinel-2",
    "title": "Sentinel Satellite Data Analysis Course",
    "section": "Sentinel 2",
    "text": "Sentinel 2"
  },
  {
    "objectID": "Sentinel.html#concluding-thoughts",
    "href": "Sentinel.html#concluding-thoughts",
    "title": "Sentinel Satellite Data Analysis Course",
    "section": "Concluding Thoughts",
    "text": "Concluding Thoughts\nThe course has equipped me with the confidence to take on independent satellite data analysis projects. It has been an enlightening experience to see how freely available satellite data can be transformed into actionable insights. The transition from theoretical understanding to practical application was seamless, thanks to the expertly crafted curriculum and the hands-on approach adopted by the course instructors.\nMoving forward, I am excited to apply the skills and to explore the various dimensions of Earth observation that such satellite data can unveil. I hope that my journey and the materials shared here serve as an inspiration and a resource for others interested in this field."
  },
  {
    "objectID": "panel_discussion.html",
    "href": "panel_discussion.html",
    "title": "Combating Climate Crisis: Insights from R, Python, and Julia Communities",
    "section": "",
    "text": "Date: 2023-08-30, 17:15–18:45"
  },
  {
    "objectID": "panel_discussion.html#overview-of-the-discussion-panel",
    "href": "panel_discussion.html#overview-of-the-discussion-panel",
    "title": "Combating Climate Crisis: Insights from R, Python, and Julia Communities",
    "section": "Overview of the Discussion Panel",
    "text": "Overview of the Discussion Panel\nThe discussion panel brought together experts in the fields of spatial data science and geoinformatics to explore how the development communities of R, Python, and Julia can contribute to combating the climate crisis. This interactive session provided a platform for participants to engage with leading experts and delve into potential solutions."
  },
  {
    "objectID": "panel_discussion.html#expert-panelists-and-their-contributions",
    "href": "panel_discussion.html#expert-panelists-and-their-contributions",
    "title": "Combating Climate Crisis: Insights from R, Python, and Julia Communities",
    "section": "Expert Panelists and Their Contributions",
    "text": "Expert Panelists and Their Contributions\n\nAnita Graser: Spatial Data Scientist at the Austrian Institute of Technology in Vienna.\nEdzer Pebesma: Director of the Institute for Geoinformatics, University of Münster.\nMaarten Pronk: GeoData Scientist at Deltares.\nLorena Abad: Researcher at Z_GIS – Department of Geoinformatics, University of Salzburg.\nTomislav Hengl: Data Scientist and Technical Director of OpenGeoHub Foundation."
  },
  {
    "objectID": "panel_discussion.html#discussion-themes",
    "href": "panel_discussion.html#discussion-themes",
    "title": "Combating Climate Crisis: Insights from R, Python, and Julia Communities",
    "section": "Discussion Themes",
    "text": "Discussion Themes\n\nThe panel focused on the role of programming languages in addressing environmental challenges.\nExperts shared their insights on leveraging data science and geoinformatics in climate research and policy-making.\nThe discussion highlighted the importance of interdisciplinary collaboration and open-source tools in advancing climate-related research."
  },
  {
    "objectID": "panel_discussion.html#interactive-engagement",
    "href": "panel_discussion.html#interactive-engagement",
    "title": "Combating Climate Crisis: Insights from R, Python, and Julia Communities",
    "section": "Interactive Engagement",
    "text": "Interactive Engagement\n\nThe session included an interactive Q&A, allowing attendees to ask questions and contribute their perspectives.\nOnline polls and real-time feedback mechanisms were employed to gauge audience opinions and foster a dynamic discussion."
  },
  {
    "objectID": "panel_discussion.html#key-takeaways",
    "href": "panel_discussion.html#key-takeaways",
    "title": "Combating Climate Crisis: Insights from R, Python, and Julia Communities",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\nEmphasis on the critical role of data science and spatial analysis in understanding and mitigating climate change.\nDiscussion of innovative applications of R, Python, and Julia in environmental research and sustainable development.\nRecognition of the need for community-driven efforts and shared resources to maximize the impact of technology in environmental conservation.\n\nPersonal impression:"
  },
  {
    "objectID": "panel_discussion.html#discussion-slides",
    "href": "panel_discussion.html#discussion-slides",
    "title": "Combating Climate Crisis: Insights from R, Python, and Julia Communities",
    "section": "Discussion Slides",
    "text": "Discussion Slides"
  },
  {
    "objectID": "panel_discussion.html#discussion-slides-1",
    "href": "panel_discussion.html#discussion-slides-1",
    "title": "Combating Climate Crisis: Insights from R, Python, and Julia Communities",
    "section": "Discussion Slides",
    "text": "Discussion Slides\nView the Discussion Forum Slides"
  },
  {
    "objectID": "julia.html",
    "href": "julia.html",
    "title": "Processing Geospatial Data with JuliaGeo",
    "section": "",
    "text": "Date: 2023-08-29, 09:00–10:30 and 2023-08-29, 11:00–12:30 Speaker: Maarten Pronk\nExploration of JuliaGeo: An introduction to the Julia programming language, focusing on the JuliaGeo ecosystem for geospatial data processing. The course offered a balanced view of Julia’s general-purpose programming prowess and specialized geospatial packages.\nInnovation in Geospatial Analysis: The session encouraged hands-on learning with Julia’s tools for spatial data and opened discussions on the language’s application in geospatial sciences, including integration with other Julia organizations like JuliaClimate and EcoJulia.\nReflection on OSS and Teaching Style: An appreciation for Maarten Pronk’s engaging and insightful teaching, which highlighted the practical use of Julia in open-source software development and its potential for research in various geospatial domains.\nI was very excited that I had the opportunity to participate in a course focused on the JuliaGeo framework as part of my continuous exploration of geospatial data processing, because I have not worked with Julia before. This session was a deep dive into the Julia programming language—a language that combines the ease of use found in scripting languages with the high performance of compiled languages.\nThe course was led by Maarten Pronk from Deltares, who is not only an early adopter of Julia but also an open-source software enthusiast contributing significantly to the geospatial research community. His teaching style was particularly inspiring, combining clarity with an interactive and engaging approach that made complex concepts accessible. Maarten’s open discussion sessions were invaluable, offering insights into the practical and innovative use of Julia in geoscience.\nJuliaGeo’s session was split into two parts: the first provided an introduction to Julia’s general programming capabilities, and the second focused on specific geospatial applications. The discussion highlighted the collaborative nature of JuliaGeo within the broader geospatial community and its integration with other organizations like JuliaGeometry, JuliaImages, and domain-specific groups such as JuliaClimate and EcoJulia."
  },
  {
    "objectID": "julia.html#julia-code",
    "href": "julia.html#julia-code",
    "title": "Processing Geospatial Data with JuliaGeo",
    "section": "Julia Code",
    "text": "Julia Code\nThe following notebooks show, what code we worked on during the course\n\nIntroduction to Julia with “intro.ipynb”\nThis notebook served as our first foray into Julia, presenting the language’s fundamentals and scripting capabilities. It was an eye-opener to Julia’s potential in simplifying complex coding tasks, setting the stage for more advanced geospatial analyses.\n\n\n\n\nExploring JuliaGeo with “juliageo.ipynb”\nDiving into the “juliageo.ipynb” notebook, we explored the JuliaGeo ecosystem, experiencing firsthand the power of Julia in processing geospatial data. The exercises we undertook underscored the breadth of functionality available to geospatial scientists within this framework.\n\n\n\n\nPackage Management with “package-manager.ipynb”\nThe “package-manager.ipynb” notebook provided a practical guide to Julia’s package ecosystem, emphasizing efficient package management and environment handling, which is crucial for reproducible research and collaborative projects.\n\n\n\n\nParallel Computing in Julia with “parallel.ipynb”\nLastly, “parallel.ipynb” introduced us to the parallel computing capabilities in Julia, demonstrating how to leverage multi-core processors and distributed computing to handle large datasets and computationally intensive tasks effectively."
  },
  {
    "objectID": "julia.html#final-remarks",
    "href": "julia.html#final-remarks",
    "title": "Processing Geospatial Data with JuliaGeo",
    "section": "Final Remarks",
    "text": "Final Remarks\nMy admiration for Maarten Pronk’s teaching style cannot be overstated. His ability to articulate the strengths of Julia while fostering a collaborative learning environment made the course exceptionally rewarding. The engaging discussions and practical sessions provided a wealth of knowledge that I am eager to apply in my future geospatial projects."
  },
  {
    "objectID": "env_time_series.html",
    "href": "env_time_series.html",
    "title": "Environmental Analysis Using Satellite Image Time Series",
    "section": "",
    "text": "Date: 2023-08-30, 13:30–15:00 Speaker: Ewa Grabska-Szwagrzyk"
  },
  {
    "objectID": "env_time_series.html#introduction-to-satellite-image-time-series-analysis",
    "href": "env_time_series.html#introduction-to-satellite-image-time-series-analysis",
    "title": "Environmental Analysis Using Satellite Image Time Series",
    "section": "Introduction to Satellite Image Time Series Analysis",
    "text": "Introduction to Satellite Image Time Series Analysis\nThe workshop focused on the powerful tool of satellite imagery time series for detecting and analyzing environmental changes. With open-access data from missions like Landsat and Sentinel, the course delved into the methods of studying short- and long-term land cover changes."
  },
  {
    "objectID": "env_time_series.html#workshop-objectives-and-coverage",
    "href": "env_time_series.html#workshop-objectives-and-coverage",
    "title": "Environmental Analysis Using Satellite Image Time Series",
    "section": "Workshop Objectives and Coverage",
    "text": "Workshop Objectives and Coverage\n\nData Preprocessing: Emphasized the importance of preprocessing steps such as outlier removal and handling missing observations to ensure data quality.\nTime Series Modeling: Participants learned various methods to effectively model time series data.\nDetection of Trends and Breaks: The workshop provided techniques for identifying trends and discontinuities within the time series.\nTypes of Changes Analyzed: The analysis included a range of environmental changes, from urban growth to vegetation succession, encompassing both abrupt and gradual transitions."
  },
  {
    "objectID": "env_time_series.html#practical-skills-and-tools",
    "href": "env_time_series.html#practical-skills-and-tools",
    "title": "Environmental Analysis Using Satellite Image Time Series",
    "section": "Practical Skills and Tools",
    "text": "Practical Skills and Tools\n\nParticipants were trained in using the R programming language for environmental analysis.\nThe workshop combined theoretical knowledge with practical application, ensuring a comprehensive learning experience."
  },
  {
    "objectID": "env_time_series.html#resources-and-repository",
    "href": "env_time_series.html#resources-and-repository",
    "title": "Environmental Analysis Using Satellite Image Time Series",
    "section": "Resources and Repository",
    "text": "Resources and Repository\n\nWorkshop Repository: Environmental Analysis Workshop GitHub\nDetailed Instructions: Workshop Instructions"
  },
  {
    "objectID": "env_time_series.html#notebook",
    "href": "env_time_series.html#notebook",
    "title": "Environmental Analysis Using Satellite Image Time Series",
    "section": "Notebook",
    "text": "Notebook"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "a.html",
    "href": "a.html",
    "title": "Test",
    "section": "",
    "text": "Here’s some introductory text for my test page.\n\n\nMore detailed text or code can go here."
  },
  {
    "objectID": "a.html#subheading",
    "href": "a.html#subheading",
    "title": "Test",
    "section": "",
    "text": "More detailed text or code can go here."
  },
  {
    "objectID": "clustering_spatial_r.html",
    "href": "clustering_spatial_r.html",
    "title": "Unsupervised Classification of Satellite Images",
    "section": "",
    "text": "Date: 2023-08-29, 13:30–15:00 and 2023-08-29, 15:30–17:00 Speaker: Krzysztof Dyba\nKey Concepts Learned:\nBasics of unsupervised satellite image classification Preparation and analysis of Landsat raster data in R Grouping methods in unsupervised learning and their practical execution Crafting and interpreting land cover maps Tackling challenges in cluster selection, result interpretation, and validation This workshop was particularly beneficial as it required no prior labeling of data, making it a versatile and accessible approach for my initial forays into satellite image analysis. It was a skillful blend of theory and practice, ensuring that we understood both the “how” and “why” of the techniques we employed.\nThe “Unsupervised classification (clustering) of satellite images” workshop, introduced me to the essential techniques of grouping pixels in satellite imagery based on their spectral information. The session was an engaging introduction to the practical applications of unsupervised classification in environmental science, land cover mapping, and emergency response."
  },
  {
    "objectID": "clustering_spatial_r.html#course-tutorial",
    "href": "clustering_spatial_r.html#course-tutorial",
    "title": "Unsupervised Classification of Satellite Images",
    "section": "Course Tutorial",
    "text": "Course Tutorial\nIn our tutorial with “Clustering.Rmd,” we went through the step-by-step process of clustering analysis in R. The tutorial was comprehensive, covering data preparation, execution of clustering algorithms, and the creation of land cover maps."
  },
  {
    "objectID": "clustering_spatial_r.html#practical-exercise",
    "href": "clustering_spatial_r.html#practical-exercise",
    "title": "Unsupervised Classification of Satellite Images",
    "section": "Practical Exercise",
    "text": "Practical Exercise\nHands on the practical exercise to cement the concepts covered in the tutorial. We were tasked with applying our new knowledge to classify a new set of satellite data, confronting real-world challenges such as selecting an appropriate number of clusters and validating the classification results."
  },
  {
    "objectID": "clustering_spatial_r.html#reflections-on-the-workshop",
    "href": "clustering_spatial_r.html#reflections-on-the-workshop",
    "title": "Unsupervised Classification of Satellite Images",
    "section": "Reflections on the Workshop",
    "text": "Reflections on the Workshop\nAttending this workshop has been an enlightening experience, revealing the potential of unsupervised classification to contribute to critical areas of research and application. The guidance provided during the workshop addressed the common challenges faced in unsupervised classification, offering valuable insights into overcoming them."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "OpenGeoHub Summer School 2023: Processing and Visualizing Large Geospatial Data Using R, Python, and Julia",
    "section": "",
    "text": "Dates: 27 August 2023 – 02 September 2023\nLocation: Adam Mickiewicz University, Poznan, Poland\nWebsite: OGHSummerSchool2023\nWelcome to my personal summary of the OpenGeoHub Summer School 2023. This year, the event, held at Adam Mickiewicz University in Poznan, focused on “Processing and Visualizing Large Geospatial Data Using R, Python, and Julia”. As a participant, I had the opportunity to dive into a range of topics, from data engineering in Python to geospatial analysis with Julia and R. This website is a curated collection of my experiences, offering insights into the courses I attended and the knowledge I gained. While this selection is not exhaustive, it represents the sessions that resonated most with me, both during the event and in my follow-up studies."
  },
  {
    "objectID": "openeo.html",
    "href": "openeo.html",
    "title": "Cloud-based Analysis of Earth Observation Data using openEO Platform, R, and Python",
    "section": "",
    "text": "Date: 2023-08-30, 09:00–10:30 Speaker: Edzer Pebesma"
  },
  {
    "objectID": "openeo.html#introduction-to-openeo",
    "href": "openeo.html#introduction-to-openeo",
    "title": "Cloud-based Analysis of Earth Observation Data using openEO Platform, R, and Python",
    "section": "Introduction to openEO",
    "text": "Introduction to openEO\nThis course offered a comprehensive look at the openEO platform, a pivotal tool for accessing and analyzing a vast array of free, open, and commercial Earth Observation (EO) data. The openEO platform stands out for its open API, which allows for cloud computing and unified, reproducible EO data access."
  },
  {
    "objectID": "openeo.html#key-features-of-openeo",
    "href": "openeo.html#key-features-of-openeo",
    "title": "Cloud-based Analysis of Earth Observation Data using openEO Platform, R, and Python",
    "section": "Key Features of openEO",
    "text": "Key Features of openEO\n\nUnified API: OpenEO provides a consistent and reproducible way to access and analyze EO data.\nMultiple Client Libraries: It supports client libraries in R, Python, and Javascript, catering to a broad range of users.\nInteractive Development Tools: The JupyterLab environment and the Web Editor provide user-friendly interfaces for developing processing workflows.\nUser-Centric Design: The platform is developed with a strong focus on user requirements and ease of use."
  },
  {
    "objectID": "openeo.html#practical-demonstrations-and-use-cases",
    "href": "openeo.html#practical-demonstrations-and-use-cases",
    "title": "Cloud-based Analysis of Earth Observation Data using openEO Platform, R, and Python",
    "section": "Practical Demonstrations and Use Cases",
    "text": "Practical Demonstrations and Use Cases\n\nThe course highlighted various completed use cases to illustrate the capabilities of the openEO platform.\nDemonstrations included the development of processing workflows and how to efficiently use the platform’s resources."
  },
  {
    "objectID": "openeo.html#future-evolution-and-community-engagement",
    "href": "openeo.html#future-evolution-and-community-engagement",
    "title": "Cloud-based Analysis of Earth Observation Data using openEO Platform, R, and Python",
    "section": "Future Evolution and Community Engagement",
    "text": "Future Evolution and Community Engagement\n\nThe future development of openEO will be closely tied to community requirements, with feature requests from users playing a crucial role.\nThe platform’s evolution will focus on expanding data availability and enhancing processing capabilities."
  },
  {
    "objectID": "openeo.html#enhancing-eo-data-analysis-with-fair-principles",
    "href": "openeo.html#enhancing-eo-data-analysis-with-fair-principles",
    "title": "Cloud-based Analysis of Earth Observation Data using openEO Platform, R, and Python",
    "section": "Enhancing EO Data Analysis with FAIR Principles",
    "text": "Enhancing EO Data Analysis with FAIR Principles\n\nThe openEO platform exemplifies the ease of processing and analyzing large amounts of EO data, aligning with FAIR data principles (Findable, Accessible, Interoperable, and Reusable).\nThis alignment supports the broader EO community in turning data into meaningful information products."
  },
  {
    "objectID": "openeo.html#additional-resources",
    "href": "openeo.html#additional-resources",
    "title": "Cloud-based Analysis of Earth Observation Data using openEO Platform, R, and Python",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nEU Horizon Projects: Open-Earth-Monitor Cyberinfrastructure (Grant agreement ID: 101059548)\nMaterial Distribution URL : openEO Software"
  },
  {
    "objectID": "openeo.html#course-material",
    "href": "openeo.html#course-material",
    "title": "Cloud-based Analysis of Earth Observation Data using openEO Platform, R, and Python",
    "section": "Course Material",
    "text": "Course Material\nLinks"
  },
  {
    "objectID": "r_lovelace.html",
    "href": "r_lovelace.html",
    "title": "Tidy Geographic Data in R",
    "section": "",
    "text": "Date: 2023-08-28, 11:00–12:30 and 2023-08-28, 13:30–15:00 Speaker: Robin Lovelace\nMastering ‘Tidy’ Geospatial Analysis in R: A detailed walkthrough of managing and visualizing geographic data with ‘tidy’ principles using the sf package in harmony with the tidyverse.\nLeveraging R Packages for Geospatial Data: The course illuminated the advantages of using sf and tidyverse together, showcasing how this combination enhances data analysis efficiency and code readability.\nBroadening the Data Analysis Toolkit: Exposure to various R packages and tools such as geos and terra, and discussions on alternative data analysis frameworks like data.table. Insight into how ‘tidy’ concepts are implemented across programming languages, with practical implications for project management and development environments.\nAs someone traditionally versed in languages other than R, I found the “Tidy geographic data with sf, dplyr, ggplot2, geos and friends” course to be the perfect introduction to managing and visualizing geographical data using R’s tidy principles. This workshop was an enlightening expedition into the ‘tidy’ data concept and its application in geospatial analysis. The course unveiled the power of the sf package as a tool for efficient geographic data management within the tidyverse ecosystem, streamlining the way data scientists can read, write, manipulate, and plot geographic information."
  },
  {
    "objectID": "r_lovelace.html#course-insights",
    "href": "r_lovelace.html#course-insights",
    "title": "Tidy Geographic Data in R",
    "section": "Course Insights",
    "text": "Course Insights\nThe workshop was structured around interactive learning sessions that taught us how to integrate packages such as sf with tidyverse tools for writing more readable and efficient code. We explored the geos package’s capabilities for geometric operations and discussed alternatives like the terra package for raster data processing. The discussion also spanned to project management tools, emphasizing the utility of IDEs like VS Code and RStudio, and the importance of version control systems in a collaborative environment."
  },
  {
    "objectID": "r_lovelace.html#practical-part",
    "href": "r_lovelace.html#practical-part",
    "title": "Tidy Geographic Data in R",
    "section": "Practical Part",
    "text": "Practical Part\nFor a hands-on look at the tidy Quarto document, which outlines the coding exercises and examples we worked through, see the embedded content below:"
  },
  {
    "objectID": "r_lovelace.html#final-reflection",
    "href": "r_lovelace.html#final-reflection",
    "title": "Tidy Geographic Data in R",
    "section": "Final Reflection",
    "text": "Final Reflection\nEmbracing the ‘tidy’ philosophy has not only honed my R programming skills but also expanded my methodological approach to data analysis. I am now better equipped to tackle geospatial data challenges and look forward to integrating these techniques into my work, leveraging the power of R’s coherent and comprehensive suite of packages for geographic data analysis.\nInterested in how to deal with geospatial data in Python, feel free to visit the page from Michal Dorman about his course: Working with Spatial Data in Python."
  },
  {
    "objectID": "sentinel1.html",
    "href": "sentinel1.html",
    "title": "Sentinel-1 data in Python",
    "section": "",
    "text": "OpenGeoHub Summer School 2023"
  },
  {
    "objectID": "sentinel1.html#querying-s1-slc-data",
    "href": "sentinel1.html#querying-s1-slc-data",
    "title": "Sentinel-1 data in Python",
    "section": "Querying S1-SLC data",
    "text": "Querying S1-SLC data\nSentinel-1 data comes at different levels and provides different products. For applications such as measuring deformation due to tectonic or volcanic activity, quantifying ground subsidence or to generate digital elevation models (DEM), interferometric SAR (InSAR) techniques can be used.\nTo apply such workflows with Sentinel data, we can use Sentinel-1 Level 1 Single Look Complex products.\n\nSM mode is designed to support ERS (European Remote Sensing) and Envisat missions; IW mode is the default mode over land; EW mode is designed for maritime, ice, and polar zone observation services where wide coverage and short revisit times are demanded; and WV mode is the default mode over the open ocean.\nSo far, very few cloud computing capabilities are available to compute such complex workflows, therefore, there is still a need to download data. Depending on the application, we will need to download data with certain characteristics.\n\n\nFigure from: Xiong S, Muller J-P, Li G. The Application of ALOS/PALSAR InSAR to Measure Subsurface Penetration Depths in Deserts. Remote Sensing. 2017; 9(6):638. https://doi.org/10.3390/rs9060638\n\nNote on terminology.\nFor DEM generation, for example, we would require a pair of Sentinel-1 scenes acquired closely in time and that have a perpendicular baseline between 150 and 300 m. Usually, computing the perpendicular baseline between two images requires the download of the image pairs.\nTo avoid downloading several unnecessary Sentinel-1 scenes, we can make use of the Alaska Satellite Facility (ASF) geographic and baseline tools to query the data we need via their API.\nLibraries needed for this exercise are imported below:\n\nimport asf_search as asf\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n\nDefine extent\nWe will define an aoi and a start and end date for our queries.\n\naoi = gpd.read_file(\"D:/Daten/OpenGeoHub2023/Sentinel Lorena/ogh23/data/poznan.geojson\")\naoi.explore()\n\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\n\nfootprint = aoi.to_wkt()\ndate_start = \"2022/05/01\"\ndate_end = \"2022/10/01\"\n\n\n\nGeographical search\nNow we can use the asf_search Python module to perform our geographical search. We specify here the platform and the processing level (SLC) that we are looking for, and we limit the results for this exercise to 10 scenes.\n\nproducts = asf.geo_search(platform=[asf.PLATFORM.SENTINEL1],\n                          intersectsWith=footprint.geometry[0],\n                          processingLevel=[asf.PRODUCT_TYPE.SLC],\n                          # beamSwath='IW', #Nothing will come for EW, because that would be for the arctic\n                          start=date_start,\n                          end=date_end,\n                          maxResults=10)\n\n\nproducts\n\nASFSearchResults([&lt;asf_search.ASFProduct.ASFProduct at 0x1b1ed935090&gt;,\n                  &lt;asf_search.ASFProduct.ASFProduct at 0x1b19332d450&gt;,\n                  &lt;asf_search.ASFProduct.ASFProduct at 0x1b19332e7d0&gt;,\n                  &lt;asf_search.ASFProduct.ASFProduct at 0x1b19332ee10&gt;,\n                  &lt;asf_search.ASFProduct.ASFProduct at 0x1b19332f410&gt;,\n                  &lt;asf_search.ASFProduct.ASFProduct at 0x1b19332fa10&gt;,\n                  &lt;asf_search.ASFProduct.ASFProduct at 0x1b19332ff90&gt;,\n                  &lt;asf_search.ASFProduct.ASFProduct at 0x1b193328390&gt;,\n                  &lt;asf_search.ASFProduct.ASFProduct at 0x1b193328950&gt;,\n                  &lt;asf_search.ASFProduct.ASFProduct at 0x1b19332f990&gt;])\n\n\nWe can then add the results of the query to a pandas dataframe for easier inspection:\n\nproducts_df = pd.DataFrame([p.properties for p in products])\nproducts_df\n\n\n\n\n\n\n\n\nbeamModeType\nbrowse\nbytes\ncenterLat\ncenterLon\nfaradayRotation\nfileID\nflightDirection\ngroupID\ngranuleType\n...\nprocessingDate\nprocessingLevel\nsceneName\nsensor\nstartTime\nstopTime\nurl\npgeVersion\nfileName\nframeNumber\n\n\n\n\n0\nIW\nNone\n4657751122\n52.2492\n17.9661\nNone\nS1A_IW_SLC__1SDV_20220929T163603_20220929T1636...\nASCENDING\nS1A_IWDV_0167_0173_045222_175\nSENTINEL_1A_FRAME\n...\n2022-09-29T16:36:03.000Z\nSLC\nS1A_IW_SLC__1SDV_20220929T163603_20220929T1636...\nC-SAR\n2022-09-29T16:36:03.000Z\n2022-09-29T16:36:30.000Z\nhttps://datapool.asf.alaska.edu/SLC/SA/S1A_IW_...\n003.52\nS1A_IW_SLC__1SDV_20220929T163603_20220929T1636...\n167\n\n\n1\nIW\nNone\n4580763215\n52.6218\n18.4544\nNone\nS1A_IW_SLC__1SDV_20220926T050057_20220926T0501...\nDESCENDING\nS1A_IWDV_0416_0423_045171_124\nSENTINEL_1A_FRAME\n...\n2022-09-26T05:00:57.000Z\nSLC\nS1A_IW_SLC__1SDV_20220926T050057_20220926T0501...\nC-SAR\n2022-09-26T05:00:57.000Z\n2022-09-26T05:01:24.000Z\nhttps://datapool.asf.alaska.edu/SLC/SA/S1A_IW_...\n003.52\nS1A_IW_SLC__1SDV_20220926T050057_20220926T0501...\n417\n\n\n2\nIW\nNone\n4609579705\n53.0143\n15.6840\nNone\nS1A_IW_SLC__1SDV_20220922T164428_20220922T1644...\nASCENDING\nS1A_IWDV_0169_0176_045120_073\nSENTINEL_1A_FRAME\n...\n2022-09-22T16:44:28.000Z\nSLC\nS1A_IW_SLC__1SDV_20220922T164428_20220922T1644...\nC-SAR\n2022-09-22T16:44:28.000Z\n2022-09-22T16:44:56.000Z\nhttps://datapool.asf.alaska.edu/SLC/SA/S1A_IW_...\n003.52\nS1A_IW_SLC__1SDV_20220922T164428_20220922T1644...\n170\n\n\n3\nIW\nNone\n4646654586\n51.5302\n16.1188\nNone\nS1A_IW_SLC__1SDV_20220922T164404_20220922T1644...\nASCENDING\nS1A_IWDV_0165_0170_045120_073\nSENTINEL_1A_FRAME\n...\n2022-09-22T16:44:04.000Z\nSLC\nS1A_IW_SLC__1SDV_20220922T164404_20220922T1644...\nC-SAR\n2022-09-22T16:44:04.000Z\n2022-09-22T16:44:31.000Z\nhttps://datapool.asf.alaska.edu/SLC/SA/S1A_IW_...\n003.52\nS1A_IW_SLC__1SDV_20220922T164404_20220922T1644...\n165\n\n\n4\nIW\nNone\n4686861613\n53.0102\n16.5167\nNone\nS1A_IW_SLC__1SDV_20220919T050904_20220919T0509...\nDESCENDING\nS1A_IWDV_0415_0421_045069_022\nSENTINEL_1A_FRAME\n...\n2022-09-19T05:09:04.000Z\nSLC\nS1A_IW_SLC__1SDV_20220919T050904_20220919T0509...\nC-SAR\n2022-09-19T05:09:04.000Z\n2022-09-19T05:09:31.000Z\nhttps://datapool.asf.alaska.edu/SLC/SA/S1A_IW_...\n003.52\nS1A_IW_SLC__1SDV_20220919T050904_20220919T0509...\n415\n\n\n5\nIW\nNone\n4652270299\n52.2492\n17.9662\nNone\nS1A_IW_SLC__1SDV_20220917T163602_20220917T1636...\nASCENDING\nS1A_IWDV_0167_0173_045047_175\nSENTINEL_1A_FRAME\n...\n2022-09-17T16:36:02.000Z\nSLC\nS1A_IW_SLC__1SDV_20220917T163602_20220917T1636...\nC-SAR\n2022-09-17T16:36:02.000Z\n2022-09-17T16:36:30.000Z\nhttps://datapool.asf.alaska.edu/SLC/SA/S1A_IW_...\n003.52\nS1A_IW_SLC__1SDV_20220917T163602_20220917T1636...\n167\n\n\n6\nIW\nNone\n4734573721\n52.6220\n18.4523\nNone\nS1A_IW_SLC__1SDV_20220914T050057_20220914T0501...\nDESCENDING\nS1A_IWDV_0416_0423_044996_124\nSENTINEL_1A_FRAME\n...\n2022-09-14T05:00:57.000Z\nSLC\nS1A_IW_SLC__1SDV_20220914T050057_20220914T0501...\nC-SAR\n2022-09-14T05:00:57.000Z\n2022-09-14T05:01:24.000Z\nhttps://datapool.asf.alaska.edu/SLC/SA/S1A_IW_...\n003.52\nS1A_IW_SLC__1SDV_20220914T050057_20220914T0501...\n417\n\n\n7\nIW\nNone\n4707081403\n53.0145\n15.6814\nNone\nS1A_IW_SLC__1SDV_20220910T164429_20220910T1644...\nASCENDING\nS1A_IWDV_0169_0176_044945_073\nSENTINEL_1A_FRAME\n...\n2022-09-10T16:44:29.000Z\nSLC\nS1A_IW_SLC__1SDV_20220910T164429_20220910T1644...\nC-SAR\n2022-09-10T16:44:29.000Z\n2022-09-10T16:44:56.000Z\nhttps://datapool.asf.alaska.edu/SLC/SA/S1A_IW_...\n003.52\nS1A_IW_SLC__1SDV_20220910T164429_20220910T1644...\n170\n\n\n8\nIW\nNone\n4721237800\n51.5303\n16.1161\nNone\nS1A_IW_SLC__1SDV_20220910T164404_20220910T1644...\nASCENDING\nS1A_IWDV_0164_0171_044945_073\nSENTINEL_1A_FRAME\n...\n2022-09-10T16:44:04.000Z\nSLC\nS1A_IW_SLC__1SDV_20220910T164404_20220910T1644...\nC-SAR\n2022-09-10T16:44:04.000Z\n2022-09-10T16:44:32.000Z\nhttps://datapool.asf.alaska.edu/SLC/SA/S1A_IW_...\n003.52\nS1A_IW_SLC__1SDV_20220910T164404_20220910T1644...\n165\n\n\n9\nIW\nNone\n4575317676\n53.0107\n16.5132\nNone\nS1A_IW_SLC__1SDV_20220907T050904_20220907T0509...\nDESCENDING\nS1A_IWDV_0415_0421_044894_022\nSENTINEL_1A_FRAME\n...\n2022-09-07T05:09:04.000Z\nSLC\nS1A_IW_SLC__1SDV_20220907T050904_20220907T0509...\nC-SAR\n2022-09-07T05:09:04.000Z\n2022-09-07T05:09:31.000Z\nhttps://datapool.asf.alaska.edu/SLC/SA/S1A_IW_...\n003.52\nS1A_IW_SLC__1SDV_20220907T050904_20220907T0509...\n415\n\n\n\n\n10 rows × 28 columns\n\n\n\nAscending vs. Descending:  -  - “/&gt;\n\n\nBaseline search\nNow that we have scenes that intersect with our defined extent, we can do a baseline search that will allow us to fetch all the S1 scenes that pair with the first S1 result from our geographical query. The baseline search returns a set of products with precomputed perpendicular baselines, so that we can focus our download on the data that we need.\n\nstack = products[0].stack()\n\n\nprint(f'{len(stack)} products found in stack')\n\n446 products found in stack\n\n\nWe can take a look at the data again as a pandas data frame and we will see that the last two columns correspond to the temporal and perpendicular baseline.\n\nstack_df = pd.DataFrame([p.properties for p in stack])\nstack_df\n\n# sort_values()\n\n\n\n\n\n\n\n\nbeamModeType\nbrowse\nbytes\ncenterLat\ncenterLon\nfaradayRotation\nfileID\nflightDirection\ngroupID\ngranuleType\n...\nsceneName\nsensor\nstartTime\nstopTime\nurl\npgeVersion\nfileName\nframeNumber\ntemporalBaseline\nperpendicularBaseline\n\n\n\n\n0\nIW\nNone\n4619446112\n52.5775\n17.8534\nNone\nS1A_IW_SLC__1SDV_20141029T163519_20141029T1635...\nASCENDING\nS1A_IWDV_0168_0173_003047_175\nSENTINEL_1A_FRAME\n...\nS1A_IW_SLC__1SDV_20141029T163519_20141029T1635...\nC-SAR\n2014-10-29T16:35:19.000Z\n2014-10-29T16:35:46.000Z\nhttps://datapool.asf.alaska.edu/SLC/SA/S1A_IW_...\n002.71\nS1A_IW_SLC__1SDV_20141029T163519_20141029T1635...\n168\n-2892\n7.0\n\n\n1\nIW\nNone\n4722951640\n52.5774\n17.8506\nNone\nS1A_IW_SLC__1SDV_20141122T163518_20141122T1635...\nASCENDING\nS1A_IWDV_0168_0173_003397_175\nSENTINEL_1A_FRAME\n...\nS1A_IW_SLC__1SDV_20141122T163518_20141122T1635...\nC-SAR\n2014-11-22T16:35:18.000Z\n2014-11-22T16:35:46.000Z\nhttps://datapool.asf.alaska.edu/SLC/SA/S1A_IW_...\n002.71\nS1A_IW_SLC__1SDV_20141122T163518_20141122T1635...\n168\n-2868\n69.0\n\n\n2\nIW\nNone\n4522111160\n52.5774\n17.8509\nNone\nS1A_IW_SLC__1SDV_20141204T163518_20141204T1635...\nASCENDING\nS1A_IWDV_0168_0173_003572_175\nSENTINEL_1A_FRAME\n...\nS1A_IW_SLC__1SDV_20141204T163518_20141204T1635...\nC-SAR\n2014-12-04T16:35:18.000Z\n2014-12-04T16:35:45.000Z\nhttps://datapool.asf.alaska.edu/SLC/SA/S1A_IW_...\n002.71\nS1A_IW_SLC__1SDV_20141204T163518_20141204T1635...\n168\n-2856\n90.0\n\n\n3\nIW\nNone\n4728062249\n52.5777\n17.8487\nNone\nS1A_IW_SLC__1SDV_20141216T163518_20141216T1635...\nASCENDING\nS1A_IWDV_0168_0173_003747_175\nSENTINEL_1A_FRAME\n...\nS1A_IW_SLC__1SDV_20141216T163518_20141216T1635...\nC-SAR\n2014-12-16T16:35:18.000Z\n2014-12-16T16:35:45.000Z\nhttps://datapool.asf.alaska.edu/SLC/SA/S1A_IW_...\n002.71\nS1A_IW_SLC__1SDV_20141216T163518_20141216T1635...\n168\n-2844\n-55.0\n\n\n4\nIW\nNone\n4486483588\n52.5775\n17.8488\nNone\nS1A_IW_SLC__1SDV_20141228T163517_20141228T1635...\nASCENDING\nS1A_IWDV_0167_0174_003922_175\nSENTINEL_1A_FRAME\n...\nS1A_IW_SLC__1SDV_20141228T163517_20141228T1635...\nC-SAR\n2014-12-28T16:35:17.000Z\n2014-12-28T16:35:44.000Z\nhttps://datapool.asf.alaska.edu/SLC/SA/S1A_IW_...\n002.71\nS1A_IW_SLC__1SDV_20141228T163517_20141228T1635...\n168\n-2832\n-56.0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n441\nIW\nNone\n4718179946\n52.2499\n17.9680\nNone\nS1A_IW_SLC__1SDV_20230702T163603_20230702T1636...\nASCENDING\nS1A_IWDV_0167_0173_049247_175\nSENTINEL_1A_FRAME\n...\nS1A_IW_SLC__1SDV_20230702T163603_20230702T1636...\nC-SAR\n2023-07-02T16:36:03.964Z\n2023-07-02T16:36:31.045Z\nhttps://datapool.asf.alaska.edu/SLC/SA/S1A_IW_...\n003.61\nS1A_IW_SLC__1SDV_20230702T163603_20230702T1636...\n167\n276\nNaN\n\n\n442\nIW\nNone\n4626122112\n52.2499\n17.9659\nNone\nS1A_IW_SLC__1SDV_20230714T163604_20230714T1636...\nASCENDING\nS1A_IWDV_0167_0172_049422_175\nSENTINEL_1A_FRAME\n...\nS1A_IW_SLC__1SDV_20230714T163604_20230714T1636...\nC-SAR\n2023-07-14T16:36:04.988Z\n2023-07-14T16:36:32.070Z\nhttps://datapool.asf.alaska.edu/SLC/SA/S1A_IW_...\n003.61\nS1A_IW_SLC__1SDV_20230714T163604_20230714T1636...\n167\n288\nNaN\n\n\n443\nIW\nNone\n4675450333\n52.2497\n17.9655\nNone\nS1A_IW_SLC__1SDV_20230726T163605_20230726T1636...\nASCENDING\nS1A_IWDV_0167_0173_049597_175\nSENTINEL_1A_FRAME\n...\nS1A_IW_SLC__1SDV_20230726T163605_20230726T1636...\nC-SAR\n2023-07-26T16:36:05.545Z\n2023-07-26T16:36:32.627Z\nhttps://datapool.asf.alaska.edu/SLC/SA/S1A_IW_...\n003.61\nS1A_IW_SLC__1SDV_20230726T163605_20230726T1636...\n167\n300\nNaN\n\n\n444\nIW\nNone\n4713498249\n52.2496\n17.9664\nNone\nS1A_IW_SLC__1SDV_20230807T163606_20230807T1636...\nASCENDING\nS1A_IWDV_0167_0173_049772_175\nSENTINEL_1A_FRAME\n...\nS1A_IW_SLC__1SDV_20230807T163606_20230807T1636...\nC-SAR\n2023-08-07T16:36:06.044Z\n2023-08-07T16:36:33.128Z\nhttps://datapool.asf.alaska.edu/SLC/SA/S1A_IW_...\n003.61\nS1A_IW_SLC__1SDV_20230807T163606_20230807T1636...\n167\n312\nNaN\n\n\n445\nIW\nNone\n4643445782\n52.2501\n17.9667\nNone\nS1A_IW_SLC__1SDV_20230819T163607_20230819T1636...\nASCENDING\nS1A_IWDV_0167_0173_049947_175\nSENTINEL_1A_FRAME\n...\nS1A_IW_SLC__1SDV_20230819T163607_20230819T1636...\nC-SAR\n2023-08-19T16:36:07.038Z\n2023-08-19T16:36:34.120Z\nhttps://datapool.asf.alaska.edu/SLC/SA/S1A_IW_...\n003.61\nS1A_IW_SLC__1SDV_20230819T163607_20230819T1636...\n167\n324\nNaN\n\n\n\n\n446 rows × 30 columns\n\n\n\nTo have an idea of how spread our data is, we can plot the temporal and the perpendicular baselines against each other.\n\nstack_df.plot.scatter(x=\"temporalBaseline\", y=\"perpendicularBaseline\")\n\n&lt;Axes: xlabel='temporalBaseline', ylabel='perpendicularBaseline'&gt;\n\n\n\n\n\nIdeally, we will filter those values where temporalBaseline &lt;= 30 and 150 &lt;= perpendicularBaseline &lt;= 300 for instance to get image pairs suitable for DEM generation. So we can filter our data frame for those values. We look for absolute values since the order of the images is not relevant.\n\nstack_df[(abs(stack_df['temporalBaseline']) &lt;= 30) &\n         (abs(stack_df['perpendicularBaseline']) &gt;= 150) &\n         (abs(stack_df['perpendicularBaseline']) &lt;= 300)]\n\n\n\n\n\n\n\n\nbeamModeType\nbrowse\nbytes\ncenterLat\ncenterLon\nfaradayRotation\nfileID\nflightDirection\ngroupID\ngranuleType\n...\nsceneName\nsensor\nstartTime\nstopTime\nurl\npgeVersion\nfileName\nframeNumber\ntemporalBaseline\nperpendicularBaseline\n\n\n\n\n416\nIW\nNone\n4563266039\n52.2489\n17.9638\nNone\nS1A_IW_SLC__1SDV_20220905T163603_20220905T1636...\nASCENDING\nS1A_IWDV_0167_0173_044872_175\nSENTINEL_1A_FRAME\n...\nS1A_IW_SLC__1SDV_20220905T163603_20220905T1636...\nC-SAR\n2022-09-05T16:36:03.000Z\n2022-09-05T16:36:30.000Z\nhttps://datapool.asf.alaska.edu/SLC/SA/S1A_IW_...\n003.52\nS1A_IW_SLC__1SDV_20220905T163603_20220905T1636...\n167\n-24\n-184.0\n\n\n\n\n1 rows × 30 columns\n\n\n\nWe only get one image fitting the characteristics we require. Let’s look at its properties:\n\nstack[416].properties\n\n{'beamModeType': 'IW',\n 'browse': None,\n 'bytes': 4563266039,\n 'centerLat': 52.2489,\n 'centerLon': 17.9638,\n 'faradayRotation': None,\n 'fileID': 'S1A_IW_SLC__1SDV_20220905T163603_20220905T163630_044872_055BFF_5F88-SLC',\n 'flightDirection': 'ASCENDING',\n 'groupID': 'S1A_IWDV_0167_0173_044872_175',\n 'granuleType': 'SENTINEL_1A_FRAME',\n 'insarStackId': None,\n 'md5sum': '72e8baa2456d336cb9b71e2c5f7e93be',\n 'offNadirAngle': None,\n 'orbit': 44872,\n 'pathNumber': 175,\n 'platform': 'Sentinel-1A',\n 'pointingAngle': None,\n 'polarization': 'VV+VH',\n 'processingDate': '2022-09-05T16:36:03.000Z',\n 'processingLevel': 'SLC',\n 'sceneName': 'S1A_IW_SLC__1SDV_20220905T163603_20220905T163630_044872_055BFF_5F88',\n 'sensor': 'C-SAR',\n 'startTime': '2022-09-05T16:36:03.000Z',\n 'stopTime': '2022-09-05T16:36:30.000Z',\n 'url': 'https://datapool.asf.alaska.edu/SLC/SA/S1A_IW_SLC__1SDV_20220905T163603_20220905T163630_044872_055BFF_5F88.zip',\n 'pgeVersion': '003.52',\n 'fileName': 'S1A_IW_SLC__1SDV_20220905T163603_20220905T163630_044872_055BFF_5F88.zip',\n 'frameNumber': 167,\n 'temporalBaseline': -24,\n 'perpendicularBaseline': -184}\n\n\nLet’s also remember this is paired with the original product we calcualted the baselines for.\n\nproducts[0].properties\n\n{'beamModeType': 'IW',\n 'browse': None,\n 'bytes': 4657751122,\n 'centerLat': 52.2492,\n 'centerLon': 17.9661,\n 'faradayRotation': None,\n 'fileID': 'S1A_IW_SLC__1SDV_20220929T163603_20220929T163630_045222_0567B7_46CF-SLC',\n 'flightDirection': 'ASCENDING',\n 'groupID': 'S1A_IWDV_0167_0173_045222_175',\n 'granuleType': 'SENTINEL_1A_FRAME',\n 'insarStackId': None,\n 'md5sum': 'a37a41c9155ed7a93b4055066710e224',\n 'offNadirAngle': None,\n 'orbit': 45222,\n 'pathNumber': 175,\n 'platform': 'Sentinel-1A',\n 'pointingAngle': None,\n 'polarization': 'VV+VH',\n 'processingDate': '2022-09-29T16:36:03.000Z',\n 'processingLevel': 'SLC',\n 'sceneName': 'S1A_IW_SLC__1SDV_20220929T163603_20220929T163630_045222_0567B7_46CF',\n 'sensor': 'C-SAR',\n 'startTime': '2022-09-29T16:36:03.000Z',\n 'stopTime': '2022-09-29T16:36:30.000Z',\n 'url': 'https://datapool.asf.alaska.edu/SLC/SA/S1A_IW_SLC__1SDV_20220929T163603_20220929T163630_045222_0567B7_46CF.zip',\n 'pgeVersion': '003.52',\n 'fileName': 'S1A_IW_SLC__1SDV_20220929T163603_20220929T163630_045222_0567B7_46CF.zip',\n 'frameNumber': 167}\n\n\n\n\nDownloading the data\nFinally, with the ASF API we can download our data to further analyse it with, e.g. SNAP. To do so we can make use of the url property.\n\nurls = [\n    products[0].properties['url'],\n    stack[416].properties['url']\n]\n\nOnce that is set we can use the download_urls() function as speccified below to get our data in a desired directory. To download the data we will need EarthData credentials. This notebook from the ASF describes the authentication process.\nasf.download_urls(urls=urls, path='data/s1', session=user_pass_session, processes=5)"
  },
  {
    "objectID": "sentinel1.html#exploring-s1-rtc-data",
    "href": "sentinel1.html#exploring-s1-rtc-data",
    "title": "Sentinel-1 data in Python",
    "section": "Exploring S1-RTC data",
    "text": "Exploring S1-RTC data\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport pandas as pd\nimport rioxarray as rio\nimport xarray as xr\n\nNow let’s take a look at a bit more processed data that we can directly work with. Still in Level-1 you will see the Ground Range Detected (GRD) product in the figure above. This is S1 data that has been further processed (it has been detected, multi-looked and projected to ground range). The SLC products we queried before preserve phase information and are processed at the natural pixel spacing whereas GRD products contain the detected amplitude and are multi-looked to reduce the impact of speckle.\nAn extra processing step is to perform Radiometric Terrain Correction, and some data providers like Microsoft Planetary Computer make this dataset available worldwide. Feel free to explore the Planetary Computer access options to work on larger datasets if you are interested.\nIn the spirit to avoid the need for you to get credentials for this particular workshop, we will use a Sentinel-1 RTC dataset for the Contiguous United States (CONUS) which is freely accessible.\nWe will access this data using the Amazon Web Services (AWS) CLI directly (with the awscli package). Let’s explore the available data:\n\n!aws s3 ls s3://sentinel-s1-rtc-indigo/tiles/RTC/1/ --no-sign-request\n\n                           PRE IW/\n\n\nDateityp \"Python.File\" nicht gefunden, oder diesem Dateityp wurde kein ™ffnen-Befehl\nzugeordnet.\n\n\n\n!aws s3 ls s3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/ --no-sign-request\n\n                           PRE 10/\n                           PRE 11/\n                           PRE 12/\n                           PRE 13/\n                           PRE 14/\n                           PRE 15/\n                           PRE 16/\n                           PRE 17/\n                           PRE 18/\n                           PRE 19/\n\n\nDateityp \"Python.File\" nicht gefunden, oder diesem Dateityp wurde kein ™ffnen-Befehl\nzugeordnet.\n\n\n\n!aws s3 ls s3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/10/S/DH/2016/S1A_20160729_10SDH_ASC/Gamma0_VV.tif/ --no-sign-request\n\nDateityp \"Python.File\" nicht gefunden, oder diesem Dateityp wurde kein ™ffnen-Befehl\nzugeordnet.\nDateityp \"Python.File\" nicht gefunden, oder diesem Dateityp wurde kein ™ffnen-Befehl\nzugeordnet.\n\n\nCompleted 256.0 KiB/118.6 MiB (23.9 KiB/s) with 1 file(s) remaining\nCompleted 512.0 KiB/118.6 MiB (47.2 KiB/s) with 1 file(s) remaining\nCompleted 768.0 KiB/118.6 MiB (64.7 KiB/s) with 1 file(s) remaining\nCompleted 1.0 MiB/118.6 MiB (63.2 KiB/s) with 1 file(s) remaining  \nCompleted 1.2 MiB/118.6 MiB (76.5 KiB/s) with 1 file(s) remaining  \nCompleted 1.5 MiB/118.6 MiB (80.8 KiB/s) with 1 file(s) remaining  \nCompleted 1.8 MiB/118.6 MiB (93.9 KiB/s) with 1 file(s) remaining  \nCompleted 2.0 MiB/118.6 MiB (103.4 KiB/s) with 1 file(s) remaining \nCompleted 2.2 MiB/118.6 MiB (91.3 KiB/s) with 1 file(s) remaining  \nCompleted 2.5 MiB/118.6 MiB (100.7 KiB/s) with 1 file(s) remaining \nCompleted 2.8 MiB/118.6 MiB (98.9 KiB/s) with 1 file(s) remaining  \nCompleted 3.0 MiB/118.6 MiB (107.9 KiB/s) with 1 file(s) remaining \nCompleted 3.2 MiB/118.6 MiB (105.7 KiB/s) with 1 file(s) remaining \nCompleted 3.5 MiB/118.6 MiB (113.7 KiB/s) with 1 file(s) remaining \nCompleted 3.8 MiB/118.6 MiB (115.9 KiB/s) with 1 file(s) remaining \nCompleted 4.0 MiB/118.6 MiB (118.4 KiB/s) with 1 file(s) remaining \nCompleted 4.2 MiB/118.6 MiB (125.0 KiB/s) with 1 file(s) remaining \nCompleted 4.5 MiB/118.6 MiB (129.9 KiB/s) with 1 file(s) remaining \nCompleted 4.8 MiB/118.6 MiB (135.1 KiB/s) with 1 file(s) remaining \nCompleted 5.0 MiB/118.6 MiB (138.3 KiB/s) with 1 file(s) remaining \nCompleted 5.2 MiB/118.6 MiB (144.9 KiB/s) with 1 file(s) remaining \nCompleted 5.5 MiB/118.6 MiB (146.9 KiB/s) with 1 file(s) remaining \nCompleted 5.8 MiB/118.6 MiB (108.1 KiB/s) with 1 file(s) remaining \nCompleted 6.0 MiB/118.6 MiB (112.3 KiB/s) with 1 file(s) remaining \nCompleted 6.2 MiB/118.6 MiB (116.5 KiB/s) with 1 file(s) remaining \nCompleted 6.5 MiB/118.6 MiB (110.8 KiB/s) with 1 file(s) remaining \nCompleted 6.8 MiB/118.6 MiB (115.1 KiB/s) with 1 file(s) remaining \nCompleted 7.0 MiB/118.6 MiB (116.7 KiB/s) with 1 file(s) remaining \nCompleted 7.2 MiB/118.6 MiB (120.5 KiB/s) with 1 file(s) remaining \nCompleted 7.5 MiB/118.6 MiB (116.7 KiB/s) with 1 file(s) remaining \nCompleted 7.8 MiB/118.6 MiB (116.4 KiB/s) with 1 file(s) remaining \nCompleted 8.0 MiB/118.6 MiB (119.3 KiB/s) with 1 file(s) remaining \nCompleted 8.2 MiB/118.6 MiB (122.8 KiB/s) with 1 file(s) remaining \nCompleted 8.5 MiB/118.6 MiB (125.9 KiB/s) with 1 file(s) remaining \nCompleted 8.8 MiB/118.6 MiB (126.5 KiB/s) with 1 file(s) remaining \nCompleted 9.0 MiB/118.6 MiB (128.1 KiB/s) with 1 file(s) remaining \nCompleted 9.2 MiB/118.6 MiB (129.2 KiB/s) with 1 file(s) remaining \nCompleted 9.5 MiB/118.6 MiB (132.0 KiB/s) with 1 file(s) remaining \nCompleted 9.8 MiB/118.6 MiB (131.4 KiB/s) with 1 file(s) remaining \nCompleted 10.0 MiB/118.6 MiB (133.6 KiB/s) with 1 file(s) remaining\nCompleted 10.2 MiB/118.6 MiB (135.5 KiB/s) with 1 file(s) remaining\nCompleted 10.5 MiB/118.6 MiB (135.1 KiB/s) with 1 file(s) remaining\nCompleted 10.8 MiB/118.6 MiB (137.7 KiB/s) with 1 file(s) remaining\nCompleted 11.0 MiB/118.6 MiB (140.6 KiB/s) with 1 file(s) remaining\nCompleted 11.2 MiB/118.6 MiB (143.4 KiB/s) with 1 file(s) remaining\nCompleted 11.5 MiB/118.6 MiB (144.2 KiB/s) with 1 file(s) remaining\nCompleted 11.8 MiB/118.6 MiB (144.3 KiB/s) with 1 file(s) remaining\nCompleted 12.0 MiB/118.6 MiB (146.1 KiB/s) with 1 file(s) remaining\nCompleted 12.2 MiB/118.6 MiB (147.5 KiB/s) with 1 file(s) remaining\nCompleted 12.5 MiB/118.6 MiB (150.3 KiB/s) with 1 file(s) remaining\nCompleted 12.8 MiB/118.6 MiB (152.6 KiB/s) with 1 file(s) remaining\nCompleted 13.0 MiB/118.6 MiB (151.6 KiB/s) with 1 file(s) remaining\nCompleted 13.2 MiB/118.6 MiB (153.9 KiB/s) with 1 file(s) remaining\nCompleted 13.5 MiB/118.6 MiB (156.3 KiB/s) with 1 file(s) remaining\nCompleted 13.8 MiB/118.6 MiB (158.1 KiB/s) with 1 file(s) remaining\nCompleted 14.0 MiB/118.6 MiB (157.1 KiB/s) with 1 file(s) remaining\nCompleted 14.2 MiB/118.6 MiB (159.7 KiB/s) with 1 file(s) remaining\nCompleted 14.5 MiB/118.6 MiB (162.3 KiB/s) with 1 file(s) remaining\nCompleted 14.8 MiB/118.6 MiB (160.6 KiB/s) with 1 file(s) remaining\nCompleted 15.0 MiB/118.6 MiB (159.4 KiB/s) with 1 file(s) remaining\nCompleted 15.2 MiB/118.6 MiB (161.9 KiB/s) with 1 file(s) remaining\nCompleted 15.5 MiB/118.6 MiB (164.4 KiB/s) with 1 file(s) remaining\nCompleted 15.8 MiB/118.6 MiB (166.8 KiB/s) with 1 file(s) remaining\nCompleted 16.0 MiB/118.6 MiB (167.9 KiB/s) with 1 file(s) remaining\nCompleted 16.2 MiB/118.6 MiB (166.4 KiB/s) with 1 file(s) remaining\nCompleted 16.5 MiB/118.6 MiB (167.6 KiB/s) with 1 file(s) remaining\nCompleted 16.8 MiB/118.6 MiB (167.7 KiB/s) with 1 file(s) remaining\nCompleted 17.0 MiB/118.6 MiB (170.1 KiB/s) with 1 file(s) remaining\nCompleted 17.2 MiB/118.6 MiB (172.6 KiB/s) with 1 file(s) remaining\nCompleted 17.5 MiB/118.6 MiB (170.9 KiB/s) with 1 file(s) remaining\nCompleted 17.8 MiB/118.6 MiB (173.3 KiB/s) with 1 file(s) remaining\nCompleted 18.0 MiB/118.6 MiB (175.2 KiB/s) with 1 file(s) remaining\nCompleted 18.2 MiB/118.6 MiB (174.4 KiB/s) with 1 file(s) remaining\nCompleted 18.5 MiB/118.6 MiB (175.5 KiB/s) with 1 file(s) remaining\nCompleted 18.8 MiB/118.6 MiB (177.2 KiB/s) with 1 file(s) remaining\nCompleted 19.0 MiB/118.6 MiB (177.7 KiB/s) with 1 file(s) remaining\nCompleted 19.2 MiB/118.6 MiB (176.3 KiB/s) with 1 file(s) remaining\nCompleted 19.5 MiB/118.6 MiB (176.6 KiB/s) with 1 file(s) remaining\nCompleted 19.8 MiB/118.6 MiB (177.8 KiB/s) with 1 file(s) remaining\nCompleted 20.0 MiB/118.6 MiB (178.7 KiB/s) with 1 file(s) remaining\nCompleted 20.2 MiB/118.6 MiB (180.8 KiB/s) with 1 file(s) remaining\nCompleted 20.5 MiB/118.6 MiB (182.8 KiB/s) with 1 file(s) remaining\nCompleted 20.8 MiB/118.6 MiB (184.9 KiB/s) with 1 file(s) remaining\nCompleted 21.0 MiB/118.6 MiB (182.7 KiB/s) with 1 file(s) remaining\nCompleted 21.2 MiB/118.6 MiB (184.0 KiB/s) with 1 file(s) remaining\nCompleted 21.5 MiB/118.6 MiB (185.0 KiB/s) with 1 file(s) remaining\nCompleted 21.8 MiB/118.6 MiB (185.4 KiB/s) with 1 file(s) remaining\nCompleted 22.0 MiB/118.6 MiB (186.0 KiB/s) with 1 file(s) remaining\nCompleted 22.2 MiB/118.6 MiB (187.8 KiB/s) with 1 file(s) remaining\nCompleted 22.5 MiB/118.6 MiB (189.7 KiB/s) with 1 file(s) remaining\nCompleted 22.8 MiB/118.6 MiB (189.7 KiB/s) with 1 file(s) remaining\nCompleted 23.0 MiB/118.6 MiB (191.4 KiB/s) with 1 file(s) remaining\nCompleted 23.2 MiB/118.6 MiB (190.9 KiB/s) with 1 file(s) remaining\nCompleted 23.5 MiB/118.6 MiB (191.9 KiB/s) with 1 file(s) remaining\nCompleted 23.8 MiB/118.6 MiB (192.8 KiB/s) with 1 file(s) remaining\nCompleted 24.0 MiB/118.6 MiB (192.7 KiB/s) with 1 file(s) remaining\nCompleted 24.2 MiB/118.6 MiB (194.3 KiB/s) with 1 file(s) remaining\nCompleted 24.5 MiB/118.6 MiB (194.4 KiB/s) with 1 file(s) remaining\nCompleted 24.8 MiB/118.6 MiB (192.8 KiB/s) with 1 file(s) remaining\nCompleted 25.0 MiB/118.6 MiB (193.8 KiB/s) with 1 file(s) remaining\nCompleted 25.2 MiB/118.6 MiB (195.1 KiB/s) with 1 file(s) remaining\nCompleted 25.5 MiB/118.6 MiB (195.3 KiB/s) with 1 file(s) remaining\nCompleted 25.8 MiB/118.6 MiB (195.9 KiB/s) with 1 file(s) remaining\nCompleted 26.0 MiB/118.6 MiB (195.9 KiB/s) with 1 file(s) remaining\nCompleted 26.2 MiB/118.6 MiB (195.3 KiB/s) with 1 file(s) remaining\nCompleted 26.5 MiB/118.6 MiB (197.1 KiB/s) with 1 file(s) remaining\nCompleted 26.8 MiB/118.6 MiB (198.7 KiB/s) with 1 file(s) remaining\nCompleted 27.0 MiB/118.6 MiB (199.3 KiB/s) with 1 file(s) remaining\nCompleted 27.2 MiB/118.6 MiB (200.6 KiB/s) with 1 file(s) remaining\nCompleted 27.5 MiB/118.6 MiB (201.6 KiB/s) with 1 file(s) remaining\nCompleted 27.8 MiB/118.6 MiB (200.2 KiB/s) with 1 file(s) remaining\nCompleted 28.0 MiB/118.6 MiB (201.3 KiB/s) with 1 file(s) remaining\nCompleted 28.2 MiB/118.6 MiB (200.5 KiB/s) with 1 file(s) remaining\nCompleted 28.5 MiB/118.6 MiB (200.3 KiB/s) with 1 file(s) remaining\nCompleted 28.8 MiB/118.6 MiB (201.7 KiB/s) with 1 file(s) remaining\nCompleted 29.0 MiB/118.6 MiB (203.4 KiB/s) with 1 file(s) remaining\nCompleted 29.2 MiB/118.6 MiB (202.8 KiB/s) with 1 file(s) remaining\nCompleted 29.5 MiB/118.6 MiB (203.7 KiB/s) with 1 file(s) remaining\nCompleted 29.8 MiB/118.6 MiB (202.2 KiB/s) with 1 file(s) remaining\nCompleted 30.0 MiB/118.6 MiB (203.5 KiB/s) with 1 file(s) remaining\nCompleted 30.2 MiB/118.6 MiB (205.1 KiB/s) with 1 file(s) remaining\nCompleted 30.5 MiB/118.6 MiB (205.4 KiB/s) with 1 file(s) remaining\nCompleted 30.8 MiB/118.6 MiB (205.3 KiB/s) with 1 file(s) remaining\nCompleted 31.0 MiB/118.6 MiB (206.0 KiB/s) with 1 file(s) remaining\nCompleted 31.2 MiB/118.6 MiB (207.5 KiB/s) with 1 file(s) remaining\nCompleted 31.5 MiB/118.6 MiB (209.1 KiB/s) with 1 file(s) remaining\nCompleted 31.8 MiB/118.6 MiB (210.7 KiB/s) with 1 file(s) remaining\nCompleted 32.0 MiB/118.6 MiB (211.2 KiB/s) with 1 file(s) remaining\nCompleted 32.2 MiB/118.6 MiB (210.6 KiB/s) with 1 file(s) remaining\nCompleted 32.5 MiB/118.6 MiB (211.0 KiB/s) with 1 file(s) remaining\nCompleted 32.8 MiB/118.6 MiB (211.1 KiB/s) with 1 file(s) remaining\nCompleted 33.0 MiB/118.6 MiB (210.4 KiB/s) with 1 file(s) remaining\nCompleted 33.2 MiB/118.6 MiB (211.8 KiB/s) with 1 file(s) remaining\nCompleted 33.5 MiB/118.6 MiB (211.3 KiB/s) with 1 file(s) remaining\nCompleted 33.8 MiB/118.6 MiB (212.4 KiB/s) with 1 file(s) remaining\nCompleted 34.0 MiB/118.6 MiB (212.2 KiB/s) with 1 file(s) remaining\nCompleted 34.2 MiB/118.6 MiB (213.0 KiB/s) with 1 file(s) remaining\nCompleted 34.5 MiB/118.6 MiB (214.2 KiB/s) with 1 file(s) remaining\nCompleted 34.8 MiB/118.6 MiB (215.5 KiB/s) with 1 file(s) remaining\nCompleted 35.0 MiB/118.6 MiB (214.0 KiB/s) with 1 file(s) remaining\nCompleted 35.2 MiB/118.6 MiB (212.1 KiB/s) with 1 file(s) remaining\nCompleted 35.5 MiB/118.6 MiB (212.7 KiB/s) with 1 file(s) remaining\nCompleted 35.8 MiB/118.6 MiB (213.9 KiB/s) with 1 file(s) remaining\nCompleted 36.0 MiB/118.6 MiB (215.3 KiB/s) with 1 file(s) remaining\nCompleted 36.2 MiB/118.6 MiB (216.8 KiB/s) with 1 file(s) remaining\nCompleted 36.5 MiB/118.6 MiB (218.3 KiB/s) with 1 file(s) remaining\nCompleted 36.8 MiB/118.6 MiB (218.1 KiB/s) with 1 file(s) remaining\nCompleted 37.0 MiB/118.6 MiB (219.3 KiB/s) with 1 file(s) remaining\nCompleted 37.2 MiB/118.6 MiB (216.9 KiB/s) with 1 file(s) remaining\nCompleted 37.5 MiB/118.6 MiB (218.0 KiB/s) with 1 file(s) remaining\nCompleted 37.8 MiB/118.6 MiB (219.3 KiB/s) with 1 file(s) remaining\nCompleted 38.0 MiB/118.6 MiB (219.7 KiB/s) with 1 file(s) remaining\nCompleted 38.2 MiB/118.6 MiB (219.4 KiB/s) with 1 file(s) remaining\nCompleted 38.5 MiB/118.6 MiB (220.5 KiB/s) with 1 file(s) remaining\nCompleted 38.8 MiB/118.6 MiB (221.5 KiB/s) with 1 file(s) remaining\nCompleted 39.0 MiB/118.6 MiB (222.1 KiB/s) with 1 file(s) remaining\nCompleted 39.2 MiB/118.6 MiB (220.6 KiB/s) with 1 file(s) remaining\nCompleted 39.5 MiB/118.6 MiB (221.6 KiB/s) with 1 file(s) remaining\nCompleted 39.8 MiB/118.6 MiB (223.0 KiB/s) with 1 file(s) remaining\nCompleted 40.0 MiB/118.6 MiB (222.9 KiB/s) with 1 file(s) remaining\nCompleted 40.2 MiB/118.6 MiB (222.8 KiB/s) with 1 file(s) remaining\nCompleted 40.5 MiB/118.6 MiB (223.9 KiB/s) with 1 file(s) remaining\nCompleted 40.8 MiB/118.6 MiB (225.2 KiB/s) with 1 file(s) remaining\nCompleted 41.0 MiB/118.6 MiB (225.4 KiB/s) with 1 file(s) remaining\nCompleted 41.2 MiB/118.6 MiB (224.3 KiB/s) with 1 file(s) remaining\nCompleted 41.5 MiB/118.6 MiB (225.6 KiB/s) with 1 file(s) remaining\nCompleted 41.8 MiB/118.6 MiB (224.8 KiB/s) with 1 file(s) remaining\nCompleted 42.0 MiB/118.6 MiB (226.0 KiB/s) with 1 file(s) remaining\nCompleted 42.2 MiB/118.6 MiB (226.5 KiB/s) with 1 file(s) remaining\nCompleted 42.5 MiB/118.6 MiB (227.3 KiB/s) with 1 file(s) remaining\nCompleted 42.8 MiB/118.6 MiB (226.8 KiB/s) with 1 file(s) remaining\nCompleted 43.0 MiB/118.6 MiB (227.9 KiB/s) with 1 file(s) remaining\nCompleted 43.2 MiB/118.6 MiB (225.9 KiB/s) with 1 file(s) remaining\nCompleted 43.5 MiB/118.6 MiB (226.8 KiB/s) with 1 file(s) remaining\nCompleted 43.8 MiB/118.6 MiB (227.3 KiB/s) with 1 file(s) remaining\nCompleted 44.0 MiB/118.6 MiB (228.2 KiB/s) with 1 file(s) remaining\nCompleted 44.2 MiB/118.6 MiB (228.9 KiB/s) with 1 file(s) remaining\nCompleted 44.5 MiB/118.6 MiB (229.4 KiB/s) with 1 file(s) remaining\nCompleted 44.8 MiB/118.6 MiB (229.0 KiB/s) with 1 file(s) remaining\nCompleted 45.0 MiB/118.6 MiB (229.3 KiB/s) with 1 file(s) remaining\nCompleted 45.2 MiB/118.6 MiB (229.6 KiB/s) with 1 file(s) remaining\nCompleted 45.5 MiB/118.6 MiB (229.7 KiB/s) with 1 file(s) remaining\nCompleted 45.8 MiB/118.6 MiB (231.0 KiB/s) with 1 file(s) remaining\nCompleted 46.0 MiB/118.6 MiB (232.0 KiB/s) with 1 file(s) remaining\nCompleted 46.2 MiB/118.6 MiB (230.8 KiB/s) with 1 file(s) remaining\nCompleted 46.5 MiB/118.6 MiB (231.0 KiB/s) with 1 file(s) remaining\nCompleted 46.8 MiB/118.6 MiB (230.3 KiB/s) with 1 file(s) remaining\nCompleted 47.0 MiB/118.6 MiB (230.7 KiB/s) with 1 file(s) remaining\nCompleted 47.2 MiB/118.6 MiB (231.1 KiB/s) with 1 file(s) remaining\nCompleted 47.5 MiB/118.6 MiB (231.7 KiB/s) with 1 file(s) remaining\nCompleted 47.8 MiB/118.6 MiB (232.0 KiB/s) with 1 file(s) remaining\nCompleted 48.0 MiB/118.6 MiB (233.0 KiB/s) with 1 file(s) remaining\nCompleted 48.2 MiB/118.6 MiB (231.9 KiB/s) with 1 file(s) remaining\nCompleted 48.5 MiB/118.6 MiB (232.8 KiB/s) with 1 file(s) remaining\nCompleted 48.8 MiB/118.6 MiB (233.3 KiB/s) with 1 file(s) remaining\nCompleted 49.0 MiB/118.6 MiB (232.5 KiB/s) with 1 file(s) remaining\nCompleted 49.2 MiB/118.6 MiB (233.3 KiB/s) with 1 file(s) remaining\nCompleted 49.5 MiB/118.6 MiB (233.4 KiB/s) with 1 file(s) remaining\nCompleted 49.8 MiB/118.6 MiB (233.6 KiB/s) with 1 file(s) remaining\nCompleted 50.0 MiB/118.6 MiB (234.8 KiB/s) with 1 file(s) remaining\nCompleted 50.2 MiB/118.6 MiB (235.8 KiB/s) with 1 file(s) remaining\nCompleted 50.5 MiB/118.6 MiB (234.0 KiB/s) with 1 file(s) remaining\nCompleted 50.8 MiB/118.6 MiB (235.1 KiB/s) with 1 file(s) remaining\nCompleted 51.0 MiB/118.6 MiB (235.8 KiB/s) with 1 file(s) remaining\nCompleted 51.2 MiB/118.6 MiB (236.3 KiB/s) with 1 file(s) remaining\nCompleted 51.5 MiB/118.6 MiB (236.9 KiB/s) with 1 file(s) remaining\nCompleted 51.8 MiB/118.6 MiB (237.2 KiB/s) with 1 file(s) remaining\nCompleted 52.0 MiB/118.6 MiB (236.8 KiB/s) with 1 file(s) remaining\nCompleted 52.2 MiB/118.6 MiB (236.4 KiB/s) with 1 file(s) remaining\nCompleted 52.5 MiB/118.6 MiB (236.7 KiB/s) with 1 file(s) remaining\nCompleted 52.8 MiB/118.6 MiB (237.6 KiB/s) with 1 file(s) remaining\nCompleted 53.0 MiB/118.6 MiB (236.9 KiB/s) with 1 file(s) remaining\nCompleted 53.2 MiB/118.6 MiB (236.0 KiB/s) with 1 file(s) remaining\nCompleted 53.5 MiB/118.6 MiB (237.1 KiB/s) with 1 file(s) remaining\nCompleted 53.8 MiB/118.6 MiB (236.2 KiB/s) with 1 file(s) remaining\nCompleted 54.0 MiB/118.6 MiB (236.0 KiB/s) with 1 file(s) remaining\nCompleted 54.2 MiB/118.6 MiB (235.9 KiB/s) with 1 file(s) remaining\nCompleted 54.5 MiB/118.6 MiB (232.9 KiB/s) with 1 file(s) remaining\nCompleted 54.8 MiB/118.6 MiB (233.7 KiB/s) with 1 file(s) remaining\nCompleted 55.0 MiB/118.6 MiB (234.6 KiB/s) with 1 file(s) remaining\nCompleted 55.2 MiB/118.6 MiB (235.4 KiB/s) with 1 file(s) remaining\nCompleted 55.5 MiB/118.6 MiB (236.3 KiB/s) with 1 file(s) remaining\nCompleted 55.8 MiB/118.6 MiB (237.1 KiB/s) with 1 file(s) remaining\nCompleted 56.0 MiB/118.6 MiB (238.1 KiB/s) with 1 file(s) remaining\nCompleted 56.2 MiB/118.6 MiB (236.7 KiB/s) with 1 file(s) remaining\nCompleted 56.5 MiB/118.6 MiB (237.6 KiB/s) with 1 file(s) remaining\nCompleted 56.8 MiB/118.6 MiB (237.8 KiB/s) with 1 file(s) remaining\nCompleted 57.0 MiB/118.6 MiB (236.8 KiB/s) with 1 file(s) remaining\nCompleted 57.2 MiB/118.6 MiB (236.6 KiB/s) with 1 file(s) remaining\nCompleted 57.5 MiB/118.6 MiB (236.8 KiB/s) with 1 file(s) remaining\nCompleted 57.8 MiB/118.6 MiB (237.5 KiB/s) with 1 file(s) remaining\nCompleted 58.0 MiB/118.6 MiB (238.1 KiB/s) with 1 file(s) remaining\nCompleted 58.2 MiB/118.6 MiB (238.1 KiB/s) with 1 file(s) remaining\nCompleted 58.5 MiB/118.6 MiB (235.6 KiB/s) with 1 file(s) remaining\nCompleted 58.8 MiB/118.6 MiB (236.4 KiB/s) with 1 file(s) remaining\nCompleted 59.0 MiB/118.6 MiB (237.2 KiB/s) with 1 file(s) remaining\nCompleted 59.2 MiB/118.6 MiB (237.7 KiB/s) with 1 file(s) remaining\nCompleted 59.5 MiB/118.6 MiB (238.6 KiB/s) with 1 file(s) remaining\nCompleted 59.8 MiB/118.6 MiB (237.7 KiB/s) with 1 file(s) remaining\nCompleted 60.0 MiB/118.6 MiB (237.8 KiB/s) with 1 file(s) remaining\nCompleted 60.2 MiB/118.6 MiB (238.8 KiB/s) with 1 file(s) remaining\nCompleted 60.5 MiB/118.6 MiB (239.4 KiB/s) with 1 file(s) remaining\nCompleted 60.8 MiB/118.6 MiB (238.9 KiB/s) with 1 file(s) remaining\nCompleted 61.0 MiB/118.6 MiB (238.8 KiB/s) with 1 file(s) remaining\nCompleted 61.2 MiB/118.6 MiB (239.6 KiB/s) with 1 file(s) remaining\nCompleted 61.5 MiB/118.6 MiB (240.3 KiB/s) with 1 file(s) remaining\nCompleted 61.8 MiB/118.6 MiB (240.9 KiB/s) with 1 file(s) remaining\nCompleted 62.0 MiB/118.6 MiB (237.1 KiB/s) with 1 file(s) remaining\nCompleted 62.2 MiB/118.6 MiB (238.0 KiB/s) with 1 file(s) remaining\nCompleted 62.5 MiB/118.6 MiB (238.8 KiB/s) with 1 file(s) remaining\nCompleted 62.8 MiB/118.6 MiB (239.5 KiB/s) with 1 file(s) remaining\nCompleted 63.0 MiB/118.6 MiB (238.8 KiB/s) with 1 file(s) remaining\nCompleted 63.2 MiB/118.6 MiB (239.5 KiB/s) with 1 file(s) remaining\nCompleted 63.5 MiB/118.6 MiB (240.3 KiB/s) with 1 file(s) remaining\nCompleted 63.8 MiB/118.6 MiB (236.7 KiB/s) with 1 file(s) remaining\nCompleted 64.0 MiB/118.6 MiB (237.4 KiB/s) with 1 file(s) remaining\nCompleted 64.2 MiB/118.6 MiB (237.6 KiB/s) with 1 file(s) remaining\nCompleted 64.5 MiB/118.6 MiB (238.1 KiB/s) with 1 file(s) remaining\nCompleted 64.8 MiB/118.6 MiB (238.5 KiB/s) with 1 file(s) remaining\nCompleted 65.0 MiB/118.6 MiB (238.8 KiB/s) with 1 file(s) remaining\nCompleted 65.2 MiB/118.6 MiB (239.1 KiB/s) with 1 file(s) remaining\nCompleted 65.5 MiB/118.6 MiB (233.1 KiB/s) with 1 file(s) remaining\nCompleted 65.8 MiB/118.6 MiB (233.4 KiB/s) with 1 file(s) remaining\nCompleted 66.0 MiB/118.6 MiB (231.8 KiB/s) with 1 file(s) remaining\nCompleted 66.2 MiB/118.6 MiB (232.5 KiB/s) with 1 file(s) remaining\nCompleted 66.5 MiB/118.6 MiB (232.6 KiB/s) with 1 file(s) remaining\nCompleted 66.8 MiB/118.6 MiB (233.2 KiB/s) with 1 file(s) remaining\nCompleted 67.0 MiB/118.6 MiB (226.1 KiB/s) with 1 file(s) remaining\nCompleted 67.2 MiB/118.6 MiB (224.9 KiB/s) with 1 file(s) remaining\nCompleted 67.5 MiB/118.6 MiB (225.6 KiB/s) with 1 file(s) remaining\nCompleted 67.8 MiB/118.6 MiB (226.0 KiB/s) with 1 file(s) remaining\nCompleted 68.0 MiB/118.6 MiB (226.7 KiB/s) with 1 file(s) remaining\nCompleted 68.2 MiB/118.6 MiB (225.8 KiB/s) with 1 file(s) remaining\nCompleted 68.5 MiB/118.6 MiB (225.2 KiB/s) with 1 file(s) remaining\nCompleted 68.8 MiB/118.6 MiB (225.2 KiB/s) with 1 file(s) remaining\nCompleted 69.0 MiB/118.6 MiB (225.7 KiB/s) with 1 file(s) remaining\nCompleted 69.2 MiB/118.6 MiB (225.8 KiB/s) with 1 file(s) remaining\nCompleted 69.5 MiB/118.6 MiB (226.5 KiB/s) with 1 file(s) remaining\nCompleted 69.8 MiB/118.6 MiB (227.1 KiB/s) with 1 file(s) remaining\nCompleted 70.0 MiB/118.6 MiB (227.8 KiB/s) with 1 file(s) remaining\nCompleted 70.2 MiB/118.6 MiB (226.9 KiB/s) with 1 file(s) remaining\nCompleted 70.5 MiB/118.6 MiB (222.6 KiB/s) with 1 file(s) remaining\nCompleted 70.8 MiB/118.6 MiB (221.1 KiB/s) with 1 file(s) remaining\nCompleted 71.0 MiB/118.6 MiB (220.5 KiB/s) with 1 file(s) remaining\nCompleted 71.2 MiB/118.6 MiB (218.5 KiB/s) with 1 file(s) remaining\nCompleted 71.5 MiB/118.6 MiB (212.5 KiB/s) with 1 file(s) remaining\nCompleted 71.8 MiB/118.6 MiB (213.0 KiB/s) with 1 file(s) remaining\nCompleted 72.0 MiB/118.6 MiB (213.4 KiB/s) with 1 file(s) remaining\nCompleted 72.2 MiB/118.6 MiB (212.7 KiB/s) with 1 file(s) remaining\nCompleted 72.5 MiB/118.6 MiB (213.4 KiB/s) with 1 file(s) remaining\nCompleted 72.8 MiB/118.6 MiB (213.9 KiB/s) with 1 file(s) remaining\nCompleted 73.0 MiB/118.6 MiB (213.8 KiB/s) with 1 file(s) remaining\nCompleted 73.2 MiB/118.6 MiB (213.6 KiB/s) with 1 file(s) remaining\nCompleted 73.5 MiB/118.6 MiB (214.0 KiB/s) with 1 file(s) remaining\nCompleted 73.8 MiB/118.6 MiB (212.6 KiB/s) with 1 file(s) remaining\nCompleted 74.0 MiB/118.6 MiB (212.6 KiB/s) with 1 file(s) remaining\nCompleted 74.2 MiB/118.6 MiB (213.2 KiB/s) with 1 file(s) remaining\nCompleted 74.5 MiB/118.6 MiB (213.2 KiB/s) with 1 file(s) remaining\nCompleted 74.8 MiB/118.6 MiB (213.8 KiB/s) with 1 file(s) remaining\nCompleted 75.0 MiB/118.6 MiB (211.5 KiB/s) with 1 file(s) remaining\nCompleted 75.2 MiB/118.6 MiB (211.8 KiB/s) with 1 file(s) remaining\nCompleted 75.5 MiB/118.6 MiB (211.2 KiB/s) with 1 file(s) remaining\nCompleted 75.8 MiB/118.6 MiB (205.8 KiB/s) with 1 file(s) remaining\nCompleted 76.0 MiB/118.6 MiB (205.0 KiB/s) with 1 file(s) remaining\nCompleted 76.2 MiB/118.6 MiB (205.4 KiB/s) with 1 file(s) remaining\nCompleted 76.5 MiB/118.6 MiB (205.7 KiB/s) with 1 file(s) remaining\nCompleted 76.8 MiB/118.6 MiB (206.2 KiB/s) with 1 file(s) remaining\nCompleted 77.0 MiB/118.6 MiB (206.7 KiB/s) with 1 file(s) remaining\nCompleted 77.2 MiB/118.6 MiB (207.2 KiB/s) with 1 file(s) remaining\nCompleted 77.5 MiB/118.6 MiB (207.7 KiB/s) with 1 file(s) remaining\nCompleted 77.8 MiB/118.6 MiB (207.2 KiB/s) with 1 file(s) remaining\nCompleted 78.0 MiB/118.6 MiB (206.4 KiB/s) with 1 file(s) remaining\nCompleted 78.2 MiB/118.6 MiB (206.4 KiB/s) with 1 file(s) remaining\nCompleted 78.5 MiB/118.6 MiB (206.5 KiB/s) with 1 file(s) remaining\nCompleted 78.8 MiB/118.6 MiB (204.6 KiB/s) with 1 file(s) remaining\nCompleted 79.0 MiB/118.6 MiB (205.2 KiB/s) with 1 file(s) remaining\nCompleted 79.2 MiB/118.6 MiB (205.7 KiB/s) with 1 file(s) remaining\nCompleted 79.5 MiB/118.6 MiB (204.4 KiB/s) with 1 file(s) remaining\nCompleted 79.8 MiB/118.6 MiB (204.8 KiB/s) with 1 file(s) remaining\nCompleted 80.0 MiB/118.6 MiB (204.8 KiB/s) with 1 file(s) remaining\nCompleted 80.2 MiB/118.6 MiB (205.4 KiB/s) with 1 file(s) remaining\nCompleted 80.5 MiB/118.6 MiB (205.9 KiB/s) with 1 file(s) remaining\nCompleted 80.8 MiB/118.6 MiB (203.0 KiB/s) with 1 file(s) remaining\nCompleted 81.0 MiB/118.6 MiB (201.0 KiB/s) with 1 file(s) remaining\nCompleted 81.2 MiB/118.6 MiB (201.4 KiB/s) with 1 file(s) remaining\nCompleted 81.5 MiB/118.6 MiB (200.3 KiB/s) with 1 file(s) remaining\nCompleted 81.8 MiB/118.6 MiB (199.9 KiB/s) with 1 file(s) remaining\nCompleted 82.0 MiB/118.6 MiB (199.9 KiB/s) with 1 file(s) remaining\nCompleted 82.2 MiB/118.6 MiB (199.5 KiB/s) with 1 file(s) remaining\nCompleted 82.5 MiB/118.6 MiB (196.9 KiB/s) with 1 file(s) remaining\nCompleted 82.8 MiB/118.6 MiB (196.0 KiB/s) with 1 file(s) remaining\nCompleted 83.0 MiB/118.6 MiB (192.0 KiB/s) with 1 file(s) remaining\nCompleted 83.2 MiB/118.6 MiB (192.4 KiB/s) with 1 file(s) remaining\nCompleted 83.5 MiB/118.6 MiB (192.8 KiB/s) with 1 file(s) remaining\nCompleted 83.8 MiB/118.6 MiB (192.5 KiB/s) with 1 file(s) remaining\nCompleted 84.0 MiB/118.6 MiB (191.5 KiB/s) with 1 file(s) remaining\nCompleted 84.2 MiB/118.6 MiB (189.3 KiB/s) with 1 file(s) remaining\nCompleted 84.5 MiB/118.6 MiB (188.5 KiB/s) with 1 file(s) remaining\nCompleted 84.8 MiB/118.6 MiB (188.9 KiB/s) with 1 file(s) remaining\nCompleted 85.0 MiB/118.6 MiB (185.5 KiB/s) with 1 file(s) remaining\nCompleted 85.2 MiB/118.6 MiB (185.6 KiB/s) with 1 file(s) remaining\nCompleted 85.5 MiB/118.6 MiB (185.9 KiB/s) with 1 file(s) remaining\nCompleted 79.0 MiB/118.6 MiB (171.0 KiB/s) with 1 file(s) remaining\nCompleted 79.2 MiB/118.6 MiB (169.3 KiB/s) with 1 file(s) remaining\nCompleted 79.5 MiB/118.6 MiB (167.6 KiB/s) with 1 file(s) remaining\nCompleted 79.8 MiB/118.6 MiB (168.0 KiB/s) with 1 file(s) remaining\nCompleted 80.0 MiB/118.6 MiB (168.1 KiB/s) with 1 file(s) remaining\nCompleted 80.2 MiB/118.6 MiB (168.6 KiB/s) with 1 file(s) remaining\nCompleted 80.5 MiB/118.6 MiB (168.1 KiB/s) with 1 file(s) remaining\nCompleted 80.8 MiB/118.6 MiB (168.2 KiB/s) with 1 file(s) remaining\nCompleted 81.0 MiB/118.6 MiB (167.5 KiB/s) with 1 file(s) remaining\nCompleted 81.2 MiB/118.6 MiB (167.4 KiB/s) with 1 file(s) remaining\nCompleted 81.5 MiB/118.6 MiB (166.4 KiB/s) with 1 file(s) remaining\nCompleted 81.8 MiB/118.6 MiB (162.1 KiB/s) with 1 file(s) remaining\nCompleted 82.0 MiB/118.6 MiB (162.2 KiB/s) with 1 file(s) remaining\nCompleted 82.2 MiB/118.6 MiB (160.5 KiB/s) with 1 file(s) remaining\nCompleted 82.5 MiB/118.6 MiB (158.8 KiB/s) with 1 file(s) remaining\nCompleted 82.8 MiB/118.6 MiB (158.0 KiB/s) with 1 file(s) remaining\nCompleted 83.0 MiB/118.6 MiB (158.3 KiB/s) with 1 file(s) remaining\nCompleted 83.2 MiB/118.6 MiB (158.7 KiB/s) with 1 file(s) remaining\nCompleted 83.5 MiB/118.6 MiB (157.1 KiB/s) with 1 file(s) remaining\nCompleted 83.8 MiB/118.6 MiB (157.5 KiB/s) with 1 file(s) remaining\nCompleted 84.0 MiB/118.6 MiB (157.5 KiB/s) with 1 file(s) remaining\nCompleted 84.2 MiB/118.6 MiB (157.9 KiB/s) with 1 file(s) remaining\nCompleted 84.5 MiB/118.6 MiB (157.3 KiB/s) with 1 file(s) remaining\nCompleted 84.8 MiB/118.6 MiB (157.6 KiB/s) with 1 file(s) remaining\nCompleted 85.0 MiB/118.6 MiB (156.4 KiB/s) with 1 file(s) remaining\nCompleted 85.2 MiB/118.6 MiB (156.7 KiB/s) with 1 file(s) remaining\nCompleted 85.5 MiB/118.6 MiB (156.9 KiB/s) with 1 file(s) remaining\nCompleted 85.8 MiB/118.6 MiB (157.3 KiB/s) with 1 file(s) remaining\nCompleted 86.0 MiB/118.6 MiB (157.4 KiB/s) with 1 file(s) remaining\nCompleted 86.2 MiB/118.6 MiB (156.8 KiB/s) with 1 file(s) remaining\nCompleted 82.8 MiB/118.6 MiB (150.1 KiB/s) with 1 file(s) remaining\nCompleted 75.0 MiB/118.6 MiB (135.3 KiB/s) with 1 file(s) remaining\nCompleted 75.2 MiB/118.6 MiB (135.2 KiB/s) with 1 file(s) remaining\nCompleted 75.5 MiB/118.6 MiB (135.5 KiB/s) with 1 file(s) remaining\nCompleted 75.8 MiB/118.6 MiB (135.7 KiB/s) with 1 file(s) remaining\nCompleted 76.0 MiB/118.6 MiB (135.3 KiB/s) with 1 file(s) remaining\nCompleted 76.2 MiB/118.6 MiB (134.9 KiB/s) with 1 file(s) remaining\nCompleted 76.5 MiB/118.6 MiB (135.3 KiB/s) with 1 file(s) remaining\nCompleted 76.8 MiB/118.6 MiB (135.8 KiB/s) with 1 file(s) remaining\nCompleted 77.0 MiB/118.6 MiB (136.0 KiB/s) with 1 file(s) remaining\nCompleted 77.2 MiB/118.6 MiB (136.2 KiB/s) with 1 file(s) remaining\nCompleted 77.5 MiB/118.6 MiB (136.3 KiB/s) with 1 file(s) remaining\nCompleted 77.8 MiB/118.6 MiB (136.2 KiB/s) with 1 file(s) remaining\nCompleted 78.0 MiB/118.6 MiB (135.7 KiB/s) with 1 file(s) remaining\nCompleted 78.2 MiB/118.6 MiB (135.9 KiB/s) with 1 file(s) remaining\nCompleted 78.5 MiB/118.6 MiB (135.8 KiB/s) with 1 file(s) remaining\nCompleted 78.8 MiB/118.6 MiB (136.1 KiB/s) with 1 file(s) remaining\nCompleted 79.0 MiB/118.6 MiB (136.0 KiB/s) with 1 file(s) remaining\nCompleted 79.2 MiB/118.6 MiB (136.4 KiB/s) with 1 file(s) remaining\nCompleted 79.5 MiB/118.6 MiB (136.4 KiB/s) with 1 file(s) remaining\nCompleted 79.8 MiB/118.6 MiB (136.7 KiB/s) with 1 file(s) remaining\nCompleted 80.0 MiB/118.6 MiB (136.7 KiB/s) with 1 file(s) remaining\nCompleted 80.2 MiB/118.6 MiB (136.9 KiB/s) with 1 file(s) remaining\nCompleted 80.5 MiB/118.6 MiB (136.3 KiB/s) with 1 file(s) remaining\nCompleted 80.8 MiB/118.6 MiB (136.6 KiB/s) with 1 file(s) remaining\nCompleted 81.0 MiB/118.6 MiB (136.9 KiB/s) with 1 file(s) remaining\nCompleted 81.2 MiB/118.6 MiB (136.5 KiB/s) with 1 file(s) remaining\nCompleted 81.5 MiB/118.6 MiB (136.9 KiB/s) with 1 file(s) remaining\nCompleted 81.8 MiB/118.6 MiB (137.0 KiB/s) with 1 file(s) remaining\nCompleted 82.0 MiB/118.6 MiB (137.3 KiB/s) with 1 file(s) remaining\nCompleted 82.2 MiB/118.6 MiB (134.0 KiB/s) with 1 file(s) remaining\nCompleted 82.5 MiB/118.6 MiB (134.3 KiB/s) with 1 file(s) remaining\nCompleted 82.8 MiB/118.6 MiB (134.5 KiB/s) with 1 file(s) remaining\nCompleted 83.0 MiB/118.6 MiB (134.8 KiB/s) with 1 file(s) remaining\nCompleted 83.2 MiB/118.6 MiB (135.0 KiB/s) with 1 file(s) remaining\nCompleted 83.5 MiB/118.6 MiB (135.1 KiB/s) with 1 file(s) remaining\nCompleted 83.8 MiB/118.6 MiB (135.4 KiB/s) with 1 file(s) remaining\nCompleted 84.0 MiB/118.6 MiB (135.5 KiB/s) with 1 file(s) remaining\nCompleted 84.2 MiB/118.6 MiB (135.8 KiB/s) with 1 file(s) remaining\nCompleted 84.5 MiB/118.6 MiB (135.8 KiB/s) with 1 file(s) remaining\nCompleted 84.8 MiB/118.6 MiB (136.1 KiB/s) with 1 file(s) remaining\nCompleted 85.0 MiB/118.6 MiB (135.5 KiB/s) with 1 file(s) remaining\nCompleted 85.2 MiB/118.6 MiB (135.8 KiB/s) with 1 file(s) remaining\nCompleted 85.5 MiB/118.6 MiB (135.9 KiB/s) with 1 file(s) remaining\nCompleted 85.8 MiB/118.6 MiB (136.1 KiB/s) with 1 file(s) remaining\nCompleted 86.0 MiB/118.6 MiB (136.4 KiB/s) with 1 file(s) remaining\nCompleted 86.2 MiB/118.6 MiB (136.4 KiB/s) with 1 file(s) remaining\nCompleted 86.5 MiB/118.6 MiB (136.8 KiB/s) with 1 file(s) remaining\nCompleted 86.8 MiB/118.6 MiB (135.4 KiB/s) with 1 file(s) remaining\nCompleted 87.0 MiB/118.6 MiB (135.5 KiB/s) with 1 file(s) remaining\nCompleted 87.2 MiB/118.6 MiB (135.8 KiB/s) with 1 file(s) remaining\nCompleted 87.5 MiB/118.6 MiB (136.1 KiB/s) with 1 file(s) remaining\nCompleted 87.8 MiB/118.6 MiB (136.4 KiB/s) with 1 file(s) remaining\nCompleted 88.0 MiB/118.6 MiB (136.7 KiB/s) with 1 file(s) remaining\nCompleted 88.2 MiB/118.6 MiB (134.8 KiB/s) with 1 file(s) remaining\nCompleted 88.5 MiB/118.6 MiB (134.3 KiB/s) with 1 file(s) remaining\nCompleted 88.8 MiB/118.6 MiB (134.6 KiB/s) with 1 file(s) remaining\nCompleted 89.0 MiB/118.6 MiB (134.8 KiB/s) with 1 file(s) remaining\nCompleted 89.2 MiB/118.6 MiB (135.0 KiB/s) with 1 file(s) remaining\nCompleted 89.5 MiB/118.6 MiB (135.3 KiB/s) with 1 file(s) remaining\nCompleted 89.8 MiB/118.6 MiB (135.0 KiB/s) with 1 file(s) remaining\nCompleted 90.0 MiB/118.6 MiB (134.5 KiB/s) with 1 file(s) remaining\nCompleted 90.2 MiB/118.6 MiB (133.7 KiB/s) with 1 file(s) remaining\nCompleted 90.5 MiB/118.6 MiB (134.1 KiB/s) with 1 file(s) remaining\nCompleted 90.8 MiB/118.6 MiB (134.0 KiB/s) with 1 file(s) remaining\nCompleted 91.0 MiB/118.6 MiB (132.0 KiB/s) with 1 file(s) remaining\nCompleted 91.1 MiB/118.6 MiB (132.0 KiB/s) with 1 file(s) remaining\nCompleted 91.4 MiB/118.6 MiB (131.7 KiB/s) with 1 file(s) remaining\nCompleted 91.6 MiB/118.6 MiB (132.1 KiB/s) with 1 file(s) remaining\nCompleted 91.9 MiB/118.6 MiB (131.6 KiB/s) with 1 file(s) remaining\nCompleted 92.1 MiB/118.6 MiB (131.9 KiB/s) with 1 file(s) remaining\nCompleted 92.4 MiB/118.6 MiB (131.8 KiB/s) with 1 file(s) remaining\nCompleted 92.6 MiB/118.6 MiB (131.9 KiB/s) with 1 file(s) remaining\nCompleted 92.9 MiB/118.6 MiB (132.1 KiB/s) with 1 file(s) remaining\nCompleted 93.1 MiB/118.6 MiB (132.0 KiB/s) with 1 file(s) remaining\nCompleted 93.4 MiB/118.6 MiB (131.7 KiB/s) with 1 file(s) remaining\nCompleted 93.6 MiB/118.6 MiB (132.0 KiB/s) with 1 file(s) remaining\nCompleted 93.9 MiB/118.6 MiB (131.8 KiB/s) with 1 file(s) remaining\nCompleted 94.1 MiB/118.6 MiB (131.6 KiB/s) with 1 file(s) remaining\nCompleted 94.4 MiB/118.6 MiB (131.4 KiB/s) with 1 file(s) remaining\nCompleted 94.6 MiB/118.6 MiB (131.1 KiB/s) with 1 file(s) remaining\nCompleted 94.9 MiB/118.6 MiB (130.9 KiB/s) with 1 file(s) remaining\nCompleted 95.1 MiB/118.6 MiB (131.2 KiB/s) with 1 file(s) remaining\nCompleted 95.4 MiB/118.6 MiB (131.4 KiB/s) with 1 file(s) remaining\nCompleted 95.6 MiB/118.6 MiB (130.9 KiB/s) with 1 file(s) remaining\nCompleted 95.9 MiB/118.6 MiB (130.9 KiB/s) with 1 file(s) remaining\nCompleted 96.1 MiB/118.6 MiB (131.2 KiB/s) with 1 file(s) remaining\nCompleted 96.4 MiB/118.6 MiB (131.4 KiB/s) with 1 file(s) remaining\nCompleted 96.6 MiB/118.6 MiB (131.4 KiB/s) with 1 file(s) remaining\nCompleted 96.9 MiB/118.6 MiB (131.3 KiB/s) with 1 file(s) remaining\nCompleted 97.1 MiB/118.6 MiB (131.7 KiB/s) with 1 file(s) remaining\nCompleted 97.4 MiB/118.6 MiB (131.4 KiB/s) with 1 file(s) remaining\nCompleted 97.6 MiB/118.6 MiB (131.2 KiB/s) with 1 file(s) remaining\nCompleted 97.9 MiB/118.6 MiB (131.3 KiB/s) with 1 file(s) remaining\nCompleted 98.1 MiB/118.6 MiB (131.5 KiB/s) with 1 file(s) remaining\nCompleted 98.4 MiB/118.6 MiB (131.8 KiB/s) with 1 file(s) remaining\nCompleted 98.6 MiB/118.6 MiB (132.0 KiB/s) with 1 file(s) remaining\nCompleted 98.9 MiB/118.6 MiB (132.3 KiB/s) with 1 file(s) remaining\nCompleted 99.1 MiB/118.6 MiB (132.5 KiB/s) with 1 file(s) remaining\nCompleted 99.4 MiB/118.6 MiB (132.6 KiB/s) with 1 file(s) remaining\nCompleted 99.6 MiB/118.6 MiB (132.7 KiB/s) with 1 file(s) remaining\nCompleted 99.9 MiB/118.6 MiB (132.3 KiB/s) with 1 file(s) remaining\nCompleted 100.1 MiB/118.6 MiB (132.4 KiB/s) with 1 file(s) remaining\nCompleted 100.4 MiB/118.6 MiB (132.3 KiB/s) with 1 file(s) remaining\nCompleted 100.6 MiB/118.6 MiB (132.5 KiB/s) with 1 file(s) remaining\nCompleted 100.9 MiB/118.6 MiB (132.3 KiB/s) with 1 file(s) remaining\nCompleted 101.1 MiB/118.6 MiB (132.4 KiB/s) with 1 file(s) remaining\nCompleted 101.4 MiB/118.6 MiB (132.7 KiB/s) with 1 file(s) remaining\nCompleted 101.6 MiB/118.6 MiB (133.0 KiB/s) with 1 file(s) remaining\nCompleted 101.9 MiB/118.6 MiB (132.8 KiB/s) with 1 file(s) remaining\nCompleted 102.1 MiB/118.6 MiB (133.1 KiB/s) with 1 file(s) remaining\nCompleted 102.4 MiB/118.6 MiB (132.9 KiB/s) with 1 file(s) remaining\nCompleted 102.6 MiB/118.6 MiB (133.2 KiB/s) with 1 file(s) remaining\nCompleted 102.9 MiB/118.6 MiB (133.5 KiB/s) with 1 file(s) remaining\nCompleted 103.1 MiB/118.6 MiB (133.4 KiB/s) with 1 file(s) remaining\nCompleted 103.4 MiB/118.6 MiB (133.5 KiB/s) with 1 file(s) remaining\nCompleted 103.6 MiB/118.6 MiB (133.8 KiB/s) with 1 file(s) remaining\nCompleted 103.9 MiB/118.6 MiB (133.5 KiB/s) with 1 file(s) remaining\nCompleted 104.1 MiB/118.6 MiB (133.2 KiB/s) with 1 file(s) remaining\nCompleted 104.4 MiB/118.6 MiB (133.5 KiB/s) with 1 file(s) remaining\nCompleted 104.6 MiB/118.6 MiB (133.6 KiB/s) with 1 file(s) remaining\nCompleted 104.9 MiB/118.6 MiB (133.0 KiB/s) with 1 file(s) remaining\nCompleted 105.1 MiB/118.6 MiB (133.2 KiB/s) with 1 file(s) remaining\nCompleted 105.4 MiB/118.6 MiB (133.5 KiB/s) with 1 file(s) remaining\nCompleted 105.6 MiB/118.6 MiB (133.8 KiB/s) with 1 file(s) remaining\nCompleted 105.9 MiB/118.6 MiB (133.4 KiB/s) with 1 file(s) remaining\nCompleted 106.1 MiB/118.6 MiB (133.2 KiB/s) with 1 file(s) remaining\nCompleted 106.4 MiB/118.6 MiB (133.4 KiB/s) with 1 file(s) remaining\nCompleted 106.6 MiB/118.6 MiB (133.7 KiB/s) with 1 file(s) remaining\nCompleted 106.9 MiB/118.6 MiB (133.7 KiB/s) with 1 file(s) remaining\nCompleted 107.1 MiB/118.6 MiB (133.7 KiB/s) with 1 file(s) remaining\nCompleted 107.4 MiB/118.6 MiB (133.7 KiB/s) with 1 file(s) remaining\nCompleted 107.6 MiB/118.6 MiB (134.0 KiB/s) with 1 file(s) remaining\nCompleted 107.9 MiB/118.6 MiB (134.1 KiB/s) with 1 file(s) remaining\nCompleted 108.1 MiB/118.6 MiB (134.0 KiB/s) with 1 file(s) remaining\nCompleted 108.4 MiB/118.6 MiB (134.3 KiB/s) with 1 file(s) remaining\nCompleted 108.6 MiB/118.6 MiB (134.4 KiB/s) with 1 file(s) remaining\nCompleted 108.9 MiB/118.6 MiB (134.6 KiB/s) with 1 file(s) remaining\nCompleted 109.1 MiB/118.6 MiB (134.8 KiB/s) with 1 file(s) remaining\nCompleted 109.4 MiB/118.6 MiB (134.9 KiB/s) with 1 file(s) remaining\nCompleted 109.6 MiB/118.6 MiB (134.9 KiB/s) with 1 file(s) remaining\nCompleted 109.9 MiB/118.6 MiB (135.0 KiB/s) with 1 file(s) remaining\nCompleted 110.1 MiB/118.6 MiB (135.2 KiB/s) with 1 file(s) remaining\nCompleted 110.4 MiB/118.6 MiB (135.5 KiB/s) with 1 file(s) remaining\nCompleted 110.6 MiB/118.6 MiB (135.4 KiB/s) with 1 file(s) remaining\nCompleted 110.9 MiB/118.6 MiB (135.5 KiB/s) with 1 file(s) remaining\nCompleted 111.1 MiB/118.6 MiB (135.8 KiB/s) with 1 file(s) remaining\nCompleted 111.4 MiB/118.6 MiB (136.0 KiB/s) with 1 file(s) remaining\nCompleted 111.6 MiB/118.6 MiB (136.0 KiB/s) with 1 file(s) remaining\nCompleted 111.9 MiB/118.6 MiB (135.3 KiB/s) with 1 file(s) remaining\nCompleted 112.1 MiB/118.6 MiB (134.9 KiB/s) with 1 file(s) remaining\nCompleted 112.4 MiB/118.6 MiB (135.2 KiB/s) with 1 file(s) remaining\nCompleted 112.6 MiB/118.6 MiB (135.1 KiB/s) with 1 file(s) remaining\nCompleted 112.9 MiB/118.6 MiB (135.4 KiB/s) with 1 file(s) remaining\nCompleted 113.1 MiB/118.6 MiB (135.6 KiB/s) with 1 file(s) remaining\nCompleted 113.4 MiB/118.6 MiB (135.8 KiB/s) with 1 file(s) remaining\nCompleted 113.6 MiB/118.6 MiB (135.9 KiB/s) with 1 file(s) remaining\nCompleted 113.9 MiB/118.6 MiB (136.1 KiB/s) with 1 file(s) remaining\nCompleted 114.1 MiB/118.6 MiB (136.3 KiB/s) with 1 file(s) remaining\nCompleted 114.4 MiB/118.6 MiB (136.5 KiB/s) with 1 file(s) remaining\nCompleted 114.6 MiB/118.6 MiB (136.5 KiB/s) with 1 file(s) remaining\nCompleted 114.9 MiB/118.6 MiB (136.8 KiB/s) with 1 file(s) remaining\nCompleted 115.1 MiB/118.6 MiB (137.0 KiB/s) with 1 file(s) remaining\nCompleted 115.4 MiB/118.6 MiB (136.9 KiB/s) with 1 file(s) remaining\nCompleted 115.6 MiB/118.6 MiB (137.2 KiB/s) with 1 file(s) remaining\nCompleted 115.9 MiB/118.6 MiB (137.4 KiB/s) with 1 file(s) remaining\nCompleted 116.1 MiB/118.6 MiB (136.8 KiB/s) with 1 file(s) remaining\nCompleted 116.4 MiB/118.6 MiB (136.9 KiB/s) with 1 file(s) remaining\nCompleted 116.6 MiB/118.6 MiB (137.1 KiB/s) with 1 file(s) remaining\nCompleted 116.9 MiB/118.6 MiB (137.2 KiB/s) with 1 file(s) remaining\nCompleted 117.1 MiB/118.6 MiB (137.3 KiB/s) with 1 file(s) remaining\nCompleted 117.4 MiB/118.6 MiB (137.1 KiB/s) with 1 file(s) remaining\nCompleted 117.6 MiB/118.6 MiB (137.2 KiB/s) with 1 file(s) remaining\nCompleted 117.9 MiB/118.6 MiB (136.9 KiB/s) with 1 file(s) remaining\nCompleted 118.1 MiB/118.6 MiB (136.9 KiB/s) with 1 file(s) remaining\nCompleted 118.4 MiB/118.6 MiB (137.1 KiB/s) with 1 file(s) remaining\nCompleted 118.6 MiB/118.6 MiB (137.3 KiB/s) with 1 file(s) remaining\ndownload: s3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/12/R/UV/2021/S1B_20210121_12RUV_DSC/Gamma0_VV.tif to S1B_20210121_12RUV_DSC\\Gamma0_VV.tif\n\n\nTo download a scene we can directly request the data as:\n\n# Run only if you want to have 110MB of random data on your laptop!\n!aws s3 cp s3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/12/R/UV/2021/S1B_20210121_12RUV_DSC/Gamma0_VV.tif S1B_20210121_12RUV_DSC/Gamma0_VV.tif --no-sign-request\n\n^C\n\n\nThe available bands have the prefix Gamma0. This is the result of the RTC algorithm. Read more about the backscatter types here.\nWe will also see that the data has a suffix, either VV or VH, this is the polarization. That refers to the way data is collected.\n \nRead more about it here, here and here.\nLet’s start exploring the data. For this we will use rioxarray. We will set an environment key to establish no sign request for AWS. And we will also be leveraging the tight integration between xarray and dask to lazily read in data via the chunks parameter.\nWe will get both the vv and vh data.\n\nos.environ['AWS_NO_SIGN_REQUEST'] = 'YES'\n\n\nurl_vv = 's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/10/U/CU/2019/S1B_20190109_10UCU_ASC/Gamma0_VV.tif'\nurl_vh = 's3://sentinel-s1-rtc-indigo/tiles/RTC/1/IW/10/U/CU/2019/S1B_20190109_10UCU_ASC/Gamma0_VH.tif'\ns1_vv = rio.open_rasterio(url_vv, chunks=True)\ns1_vh = rio.open_rasterio(url_vh, chunks=True)\n\n\ns1_vv\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (band: 1, y: 5490, x: 5490)&gt;\ndask.array&lt;open_rasterio-19cbe1dffda706ec0d650050fad8aee1&lt;this-array&gt;, shape=(1, 5490, 5490), dtype=float32, chunksize=(1, 5490, 5490), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * band         (band) int32 1\n  * x            (x) float64 3e+05 3e+05 3e+05 ... 4.098e+05 4.098e+05 4.098e+05\n  * y            (y) float64 5.4e+06 5.4e+06 5.4e+06 ... 5.29e+06 5.29e+06\n    spatial_ref  int32 0\nAttributes: (12/18)\n    ABSOLUTE_ORBIT_NUMBER:  14411\n    AREA_OR_POINT:          Area\n    DATE:                   2019-01-09\n    MISSION_ID:             S1B\n    NUMBER_SCENES:          2\n    ORBIT_DIRECTION:        ascending\n    ...                     ...\n    TILE_ID:                10UCU\n    VALID_PIXEL_PERCENT:    87.946\n    _FillValue:             0.0\n    scale_factor:           1.0\n    add_offset:             0.0\n    long_name:              Gamma0_VVxarray.DataArrayband: 1y: 5490x: 5490dask.array&lt;chunksize=(1, 5490, 5490), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n114.98 MiB\n114.98 MiB\n\n\nShape\n(1, 5490, 5490)\n(1, 5490, 5490)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\nCoordinates: (4)band(band)int321array([1])x(x)float643e+05 3e+05 ... 4.098e+05 4.098e+05array([300010., 300030., 300050., ..., 409750., 409770., 409790.])y(y)float645.4e+06 5.4e+06 ... 5.29e+06array([5399990., 5399970., 5399950., ..., 5290250., 5290230., 5290210.])spatial_ref()int320crs_wkt :PROJCS[\"WGS 84 / UTM zone 10N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-123],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32610\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :WGS 84 / UTM zone 10Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-123.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"WGS 84 / UTM zone 10N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-123],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32610\"]]GeoTransform :300000.0 20.0 0.0 5400000.0 0.0 -20.0array(0)Indexes: (3)bandPandasIndexPandasIndex(Index([1], dtype='int32', name='band'))xPandasIndexPandasIndex(Index([300010.0, 300030.0, 300050.0, 300070.0, 300090.0, 300110.0, 300130.0,\n       300150.0, 300170.0, 300190.0,\n       ...\n       409610.0, 409630.0, 409650.0, 409670.0, 409690.0, 409710.0, 409730.0,\n       409750.0, 409770.0, 409790.0],\n      dtype='float64', name='x', length=5490))yPandasIndexPandasIndex(Index([5399990.0, 5399970.0, 5399950.0, 5399930.0, 5399910.0, 5399890.0,\n       5399870.0, 5399850.0, 5399830.0, 5399810.0,\n       ...\n       5290390.0, 5290370.0, 5290350.0, 5290330.0, 5290310.0, 5290290.0,\n       5290270.0, 5290250.0, 5290230.0, 5290210.0],\n      dtype='float64', name='y', length=5490))Attributes: (18)ABSOLUTE_ORBIT_NUMBER :14411AREA_OR_POINT :AreaDATE :2019-01-09MISSION_ID :S1BNUMBER_SCENES :2ORBIT_DIRECTION :ascendingOVR_RESAMPLING_ALG :AVERAGESCENES :S1B_IW_GRDH_1SDV_20190109T020931_20190109T020956_014411_01AD36_7CA8,S1B_IW_GRDH_1SDV_20190109T020956_20190109T021021_014411_01AD36_9989SCENE_1_METADATA :{\"title\": \"S1B_IW_GRDH_1SDV_20190109T020931_20190109T020956_014411_01AD36_7CA8\", \"mission_id\": \"S1B\", \"sensor_operational_mode\": \"IW\", \"product_type\": \"RTC\", \"resolution_class\": \"H\", \"processing_level\": \"1\", \"polarization_mode\": \"DV\", \"start_time\": \"2019-01-09T02:09:31\", \"end_time\": \"2019-01-09T02:09:56\", \"absolute_orbit_number\": \"14411\", \"mission_data_take_id\": \"01AD36\", \"product_unique_identifier\": \"7CA8\", \"footprint\": \"{\\\"type\\\": \\\"Polygon\\\", \\\"coordinates\\\": [[[-126.535973, 47.750252], [-123.125053, 48.149876], [-122.782219, 46.652382], [-126.098656, 46.253361], [-126.535973, 47.750252]]]}\", \"orbit_direction\": \"ASC\", \"ingested_at\": \"2019-01-09T07:16:25.694000\", \"size\": \"914219674\"}SCENE_1_PRODUCT_INFO :{\"id\": \"S1B_IW_GRDH_1SDV_20190109T020931_20190109T020956_014411_01AD36_7CA8\", \"path\": \"scenes/RTC/1/2019/1/9/IW/DV/S1B_IW_GRDH_1SDV_20190109T020931_20190109T020956_014411_01AD36_7CA8/\", \"missionId\": \"S1B\", \"productType\": \"RTC\", \"mode\": \"IW\", \"polarization\": \"DV\", \"startTime\": \"2019-01-09T02:09:31\", \"stopTime\": \"2019-01-09T02:09:56\", \"absoluteOrbitNumber\": 14411, \"missionDataTakeId\": \"01AD36\", \"productUniqueIdentifier\": \"7CA8\", \"sciHubIngestion\": \"2019-01-09T07:16:25.694000Z\", \"s3Ingestion\": \"2020-09-23T18:01:22.339964Z\", \"sciHubId\": \"073d0c7d-47c7-44dd-be5f-bea7479c3cfa\", \"footprint\": {\"type\": \"Polygon\", \"coordinates\": [[[-126.535973, 47.750252], [-123.125053, 48.149876], [-122.782219, 46.652382], [-126.098656, 46.253361], [-126.535973, 47.750252]]]}}SCENE_2_METADATA :{\"title\": \"S1B_IW_GRDH_1SDV_20190109T020956_20190109T021021_014411_01AD36_9989\", \"mission_id\": \"S1B\", \"sensor_operational_mode\": \"IW\", \"product_type\": \"RTC\", \"resolution_class\": \"H\", \"processing_level\": \"1\", \"polarization_mode\": \"DV\", \"start_time\": \"2019-01-09T02:09:56\", \"end_time\": \"2019-01-09T02:10:21\", \"absolute_orbit_number\": \"14411\", \"mission_data_take_id\": \"01AD36\", \"product_unique_identifier\": \"9989\", \"footprint\": \"{\\\"type\\\": \\\"Polygon\\\", \\\"coordinates\\\": [[[-126.984451, 49.24667], [-123.469872, 49.647362], [-123.123749, 48.150101], [-126.535995, 47.75034], [-126.984451, 49.24667]]]}\", \"orbit_direction\": \"ASC\", \"ingested_at\": \"2019-01-09T07:40:51.331000\", \"size\": \"981747202\"}SCENE_2_PRODUCT_INFO :{\"id\": \"S1B_IW_GRDH_1SDV_20190109T020956_20190109T021021_014411_01AD36_9989\", \"path\": \"scenes/RTC/1/2019/1/9/IW/DV/S1B_IW_GRDH_1SDV_20190109T020956_20190109T021021_014411_01AD36_9989/\", \"missionId\": \"S1B\", \"productType\": \"RTC\", \"mode\": \"IW\", \"polarization\": \"DV\", \"startTime\": \"2019-01-09T02:09:56\", \"stopTime\": \"2019-01-09T02:10:21\", \"absoluteOrbitNumber\": 14411, \"missionDataTakeId\": \"01AD36\", \"productUniqueIdentifier\": \"9989\", \"sciHubIngestion\": \"2019-01-09T07:40:51.331000Z\", \"s3Ingestion\": \"2020-09-23T18:01:22.340412Z\", \"sciHubId\": \"709311d1-d033-487d-875a-786ff0570ebc\", \"footprint\": {\"type\": \"Polygon\", \"coordinates\": [[[-126.984451, 49.24667], [-123.469872, 49.647362], [-123.123749, 48.150101], [-126.535995, 47.75034], [-126.984451, 49.24667]]]}}TILE_ID :10UCUVALID_PIXEL_PERCENT :87.946_FillValue :0.0scale_factor :1.0add_offset :0.0long_name :Gamma0_VV\n\n\nLet’s visualize a slice of the data:\n\ns1_vv_ss = s1_vv.isel(x=slice(5000, 5500), y=slice(1000, 1500)).compute()\n\n\ns1_vv_ss.plot(cmap=plt.cm.Greys_r)\n\n&lt;matplotlib.collections.QuadMesh at 0x1b192be6750&gt;\n\n\n\n\n\nTo better visualize the data, we can apply a power to dB scale. This transformation applies a logarithmic scale to the data for easier visualisation, but it is not recommended to use this for any computations, since the data gets distorted.\n\ndef power_to_db(input_arr):\n    return (10*np.log10(np.abs(input_arr)))\n\n\npower_to_db(s1_vv_ss).plot(cmap=plt.cm.Greys_r)\n\n&lt;matplotlib.collections.QuadMesh at 0x1b192588810&gt;"
  },
  {
    "objectID": "sentinel1.html#exercise",
    "href": "sentinel1.html#exercise",
    "title": "Sentinel-1 data in Python",
    "section": "Exercise:",
    "text": "Exercise:\n\nTry to combine the s1_vv and s1_vh objects together, compute a new band with the result of VH/VV and use these three layers to generate a false color RGB composite.\n\n\ns1_vv\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (band: 1, y: 5490, x: 5490)&gt;\ndask.array&lt;open_rasterio-19cbe1dffda706ec0d650050fad8aee1&lt;this-array&gt;, shape=(1, 5490, 5490), dtype=float32, chunksize=(1, 5490, 5490), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * band         (band) int32 1\n  * x            (x) float64 3e+05 3e+05 3e+05 ... 4.098e+05 4.098e+05 4.098e+05\n  * y            (y) float64 5.4e+06 5.4e+06 5.4e+06 ... 5.29e+06 5.29e+06\n    spatial_ref  int32 0\nAttributes: (12/18)\n    ABSOLUTE_ORBIT_NUMBER:  14411\n    AREA_OR_POINT:          Area\n    DATE:                   2019-01-09\n    MISSION_ID:             S1B\n    NUMBER_SCENES:          2\n    ORBIT_DIRECTION:        ascending\n    ...                     ...\n    TILE_ID:                10UCU\n    VALID_PIXEL_PERCENT:    87.946\n    _FillValue:             0.0\n    scale_factor:           1.0\n    add_offset:             0.0\n    long_name:              Gamma0_VVxarray.DataArrayband: 1y: 5490x: 5490dask.array&lt;chunksize=(1, 5490, 5490), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n114.98 MiB\n114.98 MiB\n\n\nShape\n(1, 5490, 5490)\n(1, 5490, 5490)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\nCoordinates: (4)band(band)int321array([1])x(x)float643e+05 3e+05 ... 4.098e+05 4.098e+05array([300010., 300030., 300050., ..., 409750., 409770., 409790.])y(y)float645.4e+06 5.4e+06 ... 5.29e+06array([5399990., 5399970., 5399950., ..., 5290250., 5290230., 5290210.])spatial_ref()int320crs_wkt :PROJCS[\"WGS 84 / UTM zone 10N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-123],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32610\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :WGS 84 / UTM zone 10Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-123.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"WGS 84 / UTM zone 10N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-123],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32610\"]]GeoTransform :300000.0 20.0 0.0 5400000.0 0.0 -20.0array(0)Indexes: (3)bandPandasIndexPandasIndex(Index([1], dtype='int32', name='band'))xPandasIndexPandasIndex(Index([300010.0, 300030.0, 300050.0, 300070.0, 300090.0, 300110.0, 300130.0,\n       300150.0, 300170.0, 300190.0,\n       ...\n       409610.0, 409630.0, 409650.0, 409670.0, 409690.0, 409710.0, 409730.0,\n       409750.0, 409770.0, 409790.0],\n      dtype='float64', name='x', length=5490))yPandasIndexPandasIndex(Index([5399990.0, 5399970.0, 5399950.0, 5399930.0, 5399910.0, 5399890.0,\n       5399870.0, 5399850.0, 5399830.0, 5399810.0,\n       ...\n       5290390.0, 5290370.0, 5290350.0, 5290330.0, 5290310.0, 5290290.0,\n       5290270.0, 5290250.0, 5290230.0, 5290210.0],\n      dtype='float64', name='y', length=5490))Attributes: (18)ABSOLUTE_ORBIT_NUMBER :14411AREA_OR_POINT :AreaDATE :2019-01-09MISSION_ID :S1BNUMBER_SCENES :2ORBIT_DIRECTION :ascendingOVR_RESAMPLING_ALG :AVERAGESCENES :S1B_IW_GRDH_1SDV_20190109T020931_20190109T020956_014411_01AD36_7CA8,S1B_IW_GRDH_1SDV_20190109T020956_20190109T021021_014411_01AD36_9989SCENE_1_METADATA :{\"title\": \"S1B_IW_GRDH_1SDV_20190109T020931_20190109T020956_014411_01AD36_7CA8\", \"mission_id\": \"S1B\", \"sensor_operational_mode\": \"IW\", \"product_type\": \"RTC\", \"resolution_class\": \"H\", \"processing_level\": \"1\", \"polarization_mode\": \"DV\", \"start_time\": \"2019-01-09T02:09:31\", \"end_time\": \"2019-01-09T02:09:56\", \"absolute_orbit_number\": \"14411\", \"mission_data_take_id\": \"01AD36\", \"product_unique_identifier\": \"7CA8\", \"footprint\": \"{\\\"type\\\": \\\"Polygon\\\", \\\"coordinates\\\": [[[-126.535973, 47.750252], [-123.125053, 48.149876], [-122.782219, 46.652382], [-126.098656, 46.253361], [-126.535973, 47.750252]]]}\", \"orbit_direction\": \"ASC\", \"ingested_at\": \"2019-01-09T07:16:25.694000\", \"size\": \"914219674\"}SCENE_1_PRODUCT_INFO :{\"id\": \"S1B_IW_GRDH_1SDV_20190109T020931_20190109T020956_014411_01AD36_7CA8\", \"path\": \"scenes/RTC/1/2019/1/9/IW/DV/S1B_IW_GRDH_1SDV_20190109T020931_20190109T020956_014411_01AD36_7CA8/\", \"missionId\": \"S1B\", \"productType\": \"RTC\", \"mode\": \"IW\", \"polarization\": \"DV\", \"startTime\": \"2019-01-09T02:09:31\", \"stopTime\": \"2019-01-09T02:09:56\", \"absoluteOrbitNumber\": 14411, \"missionDataTakeId\": \"01AD36\", \"productUniqueIdentifier\": \"7CA8\", \"sciHubIngestion\": \"2019-01-09T07:16:25.694000Z\", \"s3Ingestion\": \"2020-09-23T18:01:22.339964Z\", \"sciHubId\": \"073d0c7d-47c7-44dd-be5f-bea7479c3cfa\", \"footprint\": {\"type\": \"Polygon\", \"coordinates\": [[[-126.535973, 47.750252], [-123.125053, 48.149876], [-122.782219, 46.652382], [-126.098656, 46.253361], [-126.535973, 47.750252]]]}}SCENE_2_METADATA :{\"title\": \"S1B_IW_GRDH_1SDV_20190109T020956_20190109T021021_014411_01AD36_9989\", \"mission_id\": \"S1B\", \"sensor_operational_mode\": \"IW\", \"product_type\": \"RTC\", \"resolution_class\": \"H\", \"processing_level\": \"1\", \"polarization_mode\": \"DV\", \"start_time\": \"2019-01-09T02:09:56\", \"end_time\": \"2019-01-09T02:10:21\", \"absolute_orbit_number\": \"14411\", \"mission_data_take_id\": \"01AD36\", \"product_unique_identifier\": \"9989\", \"footprint\": \"{\\\"type\\\": \\\"Polygon\\\", \\\"coordinates\\\": [[[-126.984451, 49.24667], [-123.469872, 49.647362], [-123.123749, 48.150101], [-126.535995, 47.75034], [-126.984451, 49.24667]]]}\", \"orbit_direction\": \"ASC\", \"ingested_at\": \"2019-01-09T07:40:51.331000\", \"size\": \"981747202\"}SCENE_2_PRODUCT_INFO :{\"id\": \"S1B_IW_GRDH_1SDV_20190109T020956_20190109T021021_014411_01AD36_9989\", \"path\": \"scenes/RTC/1/2019/1/9/IW/DV/S1B_IW_GRDH_1SDV_20190109T020956_20190109T021021_014411_01AD36_9989/\", \"missionId\": \"S1B\", \"productType\": \"RTC\", \"mode\": \"IW\", \"polarization\": \"DV\", \"startTime\": \"2019-01-09T02:09:56\", \"stopTime\": \"2019-01-09T02:10:21\", \"absoluteOrbitNumber\": 14411, \"missionDataTakeId\": \"01AD36\", \"productUniqueIdentifier\": \"9989\", \"sciHubIngestion\": \"2019-01-09T07:40:51.331000Z\", \"s3Ingestion\": \"2020-09-23T18:01:22.340412Z\", \"sciHubId\": \"709311d1-d033-487d-875a-786ff0570ebc\", \"footprint\": {\"type\": \"Polygon\", \"coordinates\": [[[-126.984451, 49.24667], [-123.469872, 49.647362], [-123.123749, 48.150101], [-126.535995, 47.75034], [-126.984451, 49.24667]]]}}TILE_ID :10UCUVALID_PIXEL_PERCENT :87.946_FillValue :0.0scale_factor :1.0add_offset :0.0long_name :Gamma0_VV\n\n\n\ns1_vh\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray (band: 1, y: 5490, x: 5490)&gt;\ndask.array&lt;open_rasterio-d85bc69bab7c5795dc7b6c42fe93892e&lt;this-array&gt;, shape=(1, 5490, 5490), dtype=float32, chunksize=(1, 5490, 5490), chunktype=numpy.ndarray&gt;\nCoordinates:\n  * band         (band) int32 1\n  * x            (x) float64 3e+05 3e+05 3e+05 ... 4.098e+05 4.098e+05 4.098e+05\n  * y            (y) float64 5.4e+06 5.4e+06 5.4e+06 ... 5.29e+06 5.29e+06\n    spatial_ref  int32 0\nAttributes: (12/18)\n    ABSOLUTE_ORBIT_NUMBER:  14411\n    AREA_OR_POINT:          Area\n    DATE:                   2019-01-09\n    MISSION_ID:             S1B\n    NUMBER_SCENES:          2\n    ORBIT_DIRECTION:        ascending\n    ...                     ...\n    TILE_ID:                10UCU\n    VALID_PIXEL_PERCENT:    87.946\n    _FillValue:             0.0\n    scale_factor:           1.0\n    add_offset:             0.0\n    long_name:              Gamma0_VHxarray.DataArrayband: 1y: 5490x: 5490dask.array&lt;chunksize=(1, 5490, 5490), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n114.98 MiB\n114.98 MiB\n\n\nShape\n(1, 5490, 5490)\n(1, 5490, 5490)\n\n\nDask graph\n1 chunks in 2 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\nCoordinates: (4)band(band)int321array([1])x(x)float643e+05 3e+05 ... 4.098e+05 4.098e+05array([300010., 300030., 300050., ..., 409750., 409770., 409790.])y(y)float645.4e+06 5.4e+06 ... 5.29e+06array([5399990., 5399970., 5399950., ..., 5290250., 5290230., 5290210.])spatial_ref()int320crs_wkt :PROJCS[\"WGS 84 / UTM zone 10N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-123],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32610\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :WGS 84 / UTM zone 10Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-123.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"WGS 84 / UTM zone 10N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-123],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32610\"]]GeoTransform :300000.0 20.0 0.0 5400000.0 0.0 -20.0array(0)Indexes: (3)bandPandasIndexPandasIndex(Index([1], dtype='int32', name='band'))xPandasIndexPandasIndex(Index([300010.0, 300030.0, 300050.0, 300070.0, 300090.0, 300110.0, 300130.0,\n       300150.0, 300170.0, 300190.0,\n       ...\n       409610.0, 409630.0, 409650.0, 409670.0, 409690.0, 409710.0, 409730.0,\n       409750.0, 409770.0, 409790.0],\n      dtype='float64', name='x', length=5490))yPandasIndexPandasIndex(Index([5399990.0, 5399970.0, 5399950.0, 5399930.0, 5399910.0, 5399890.0,\n       5399870.0, 5399850.0, 5399830.0, 5399810.0,\n       ...\n       5290390.0, 5290370.0, 5290350.0, 5290330.0, 5290310.0, 5290290.0,\n       5290270.0, 5290250.0, 5290230.0, 5290210.0],\n      dtype='float64', name='y', length=5490))Attributes: (18)ABSOLUTE_ORBIT_NUMBER :14411AREA_OR_POINT :AreaDATE :2019-01-09MISSION_ID :S1BNUMBER_SCENES :2ORBIT_DIRECTION :ascendingOVR_RESAMPLING_ALG :AVERAGESCENES :S1B_IW_GRDH_1SDV_20190109T020931_20190109T020956_014411_01AD36_7CA8,S1B_IW_GRDH_1SDV_20190109T020956_20190109T021021_014411_01AD36_9989SCENE_1_METADATA :{\"title\": \"S1B_IW_GRDH_1SDV_20190109T020931_20190109T020956_014411_01AD36_7CA8\", \"mission_id\": \"S1B\", \"sensor_operational_mode\": \"IW\", \"product_type\": \"RTC\", \"resolution_class\": \"H\", \"processing_level\": \"1\", \"polarization_mode\": \"DV\", \"start_time\": \"2019-01-09T02:09:31\", \"end_time\": \"2019-01-09T02:09:56\", \"absolute_orbit_number\": \"14411\", \"mission_data_take_id\": \"01AD36\", \"product_unique_identifier\": \"7CA8\", \"footprint\": \"{\\\"type\\\": \\\"Polygon\\\", \\\"coordinates\\\": [[[-126.535973, 47.750252], [-123.125053, 48.149876], [-122.782219, 46.652382], [-126.098656, 46.253361], [-126.535973, 47.750252]]]}\", \"orbit_direction\": \"ASC\", \"ingested_at\": \"2019-01-09T07:16:25.694000\", \"size\": \"914219674\"}SCENE_1_PRODUCT_INFO :{\"id\": \"S1B_IW_GRDH_1SDV_20190109T020931_20190109T020956_014411_01AD36_7CA8\", \"path\": \"scenes/RTC/1/2019/1/9/IW/DV/S1B_IW_GRDH_1SDV_20190109T020931_20190109T020956_014411_01AD36_7CA8/\", \"missionId\": \"S1B\", \"productType\": \"RTC\", \"mode\": \"IW\", \"polarization\": \"DV\", \"startTime\": \"2019-01-09T02:09:31\", \"stopTime\": \"2019-01-09T02:09:56\", \"absoluteOrbitNumber\": 14411, \"missionDataTakeId\": \"01AD36\", \"productUniqueIdentifier\": \"7CA8\", \"sciHubIngestion\": \"2019-01-09T07:16:25.694000Z\", \"s3Ingestion\": \"2020-09-23T18:00:51.876503Z\", \"sciHubId\": \"073d0c7d-47c7-44dd-be5f-bea7479c3cfa\", \"footprint\": {\"type\": \"Polygon\", \"coordinates\": [[[-126.535973, 47.750252], [-123.125053, 48.149876], [-122.782219, 46.652382], [-126.098656, 46.253361], [-126.535973, 47.750252]]]}}SCENE_2_METADATA :{\"title\": \"S1B_IW_GRDH_1SDV_20190109T020956_20190109T021021_014411_01AD36_9989\", \"mission_id\": \"S1B\", \"sensor_operational_mode\": \"IW\", \"product_type\": \"RTC\", \"resolution_class\": \"H\", \"processing_level\": \"1\", \"polarization_mode\": \"DV\", \"start_time\": \"2019-01-09T02:09:56\", \"end_time\": \"2019-01-09T02:10:21\", \"absolute_orbit_number\": \"14411\", \"mission_data_take_id\": \"01AD36\", \"product_unique_identifier\": \"9989\", \"footprint\": \"{\\\"type\\\": \\\"Polygon\\\", \\\"coordinates\\\": [[[-126.984451, 49.24667], [-123.469872, 49.647362], [-123.123749, 48.150101], [-126.535995, 47.75034], [-126.984451, 49.24667]]]}\", \"orbit_direction\": \"ASC\", \"ingested_at\": \"2019-01-09T07:40:51.331000\", \"size\": \"981747202\"}SCENE_2_PRODUCT_INFO :{\"id\": \"S1B_IW_GRDH_1SDV_20190109T020956_20190109T021021_014411_01AD36_9989\", \"path\": \"scenes/RTC/1/2019/1/9/IW/DV/S1B_IW_GRDH_1SDV_20190109T020956_20190109T021021_014411_01AD36_9989/\", \"missionId\": \"S1B\", \"productType\": \"RTC\", \"mode\": \"IW\", \"polarization\": \"DV\", \"startTime\": \"2019-01-09T02:09:56\", \"stopTime\": \"2019-01-09T02:10:21\", \"absoluteOrbitNumber\": 14411, \"missionDataTakeId\": \"01AD36\", \"productUniqueIdentifier\": \"9989\", \"sciHubIngestion\": \"2019-01-09T07:40:51.331000Z\", \"s3Ingestion\": \"2020-09-23T18:00:51.876961Z\", \"sciHubId\": \"709311d1-d033-487d-875a-786ff0570ebc\", \"footprint\": {\"type\": \"Polygon\", \"coordinates\": [[[-126.984451, 49.24667], [-123.469872, 49.647362], [-123.123749, 48.150101], [-126.535995, 47.75034], [-126.984451, 49.24667]]]}}TILE_ID :10UCUVALID_PIXEL_PERCENT :87.946_FillValue :0.0scale_factor :1.0add_offset :0.0long_name :Gamma0_VH\n\n\n\ns1_comined = xr.merge([s1_vv, s1_vh])\n\nValueError: unable to convert unnamed DataArray to a Dataset without providing an explicit name"
  },
  {
    "objectID": "spatial_ml.html",
    "href": "spatial_ml.html",
    "title": "Spatial ML model assessment and interpretation",
    "section": "",
    "text": "Date: 2023-08-31, 09:30–10:30 and 2023-08-31, 11:00-12:30 Speaker: Alexander Brenning\nUnderstanding Spatial ML Model Assessment: The course shed light on the advanced techniques for interpreting machine-learning models with a focus on spatial analysis. It introduced the concept of spatial prediction error profiles (SPEPs) and spatial variable importance profiles (SVIPs) as tools to dissect and understand the predictive performance of ML models over different spatial extents.\nSkill Enhancement: The training provided me with insights into: - The application of SPEPs and SVIPs for model-agnostic assessment. - The analysis of regionalization and classification tasks using various ML algorithms. - The comparison and contrast of model performance across different spatial scales and contexts.\nIn this course I’ve gathered invaluable insights and practical skills that have significantly broadened my understanding of satellite data applications. The course provided a robust foundation for working with some of the most sophisticated tools in remote sensing within Python and R environments.\nThe “Spatial ML model assessment and interpretation” course provided a comprehensive look at advanced methodologies for understanding machine learning (ML) models within a spatial context."
  },
  {
    "objectID": "spatial_ml.html#introduction",
    "href": "spatial_ml.html#introduction",
    "title": "Spatial ML model assessment and interpretation",
    "section": "Introduction",
    "text": "Introduction\nThe presentation began with a focus on the challenges of interpreting complex ML models used for spatial prediction tasks. It emphasized the need for new diagnostic tools to better understand model behavior in terms of predictive skill and variable importance over space."
  },
  {
    "objectID": "spatial_ml.html#diagnostic-tools-proposed",
    "href": "spatial_ml.html#diagnostic-tools-proposed",
    "title": "Spatial ML model assessment and interpretation",
    "section": "Diagnostic Tools Proposed",
    "text": "Diagnostic Tools Proposed\n\nSpatial Prediction Error Profiles (SPEPs): Introduced as a method to assess the spatial behavior of predictive models, focusing on the prediction distance to diagnose errors across different spatial locations.\nSpatial Variable Importance Profiles (SVIPs): Proposed for evaluating the contribution of each variable to the model’s predictive power, factoring in the spatial correlation and prediction horizon."
  },
  {
    "objectID": "spatial_ml.html#case-studies-demonstrating-the-tools",
    "href": "spatial_ml.html#case-studies-demonstrating-the-tools",
    "title": "Spatial ML model assessment and interpretation",
    "section": "Case Studies Demonstrating the Tools",
    "text": "Case Studies Demonstrating the Tools\n\nLandslide Susceptibility:\n\nThe objective was to identify areas prone to landslides using terrain attributes, land use, and other geographical features.\nThe study highlighted how geostatistical methods, linear models, and ML algorithms like random forest differ in spatial prediction when assessed with SPEPs and SVIPs.\n\nRemotely-Sensed Land Cover Classification:\n\nAimed at classifying crop types using Landsat data.\nDemonstrated the use of SPEPs and SVIPs in understanding the spatial generalizability of models and the limitations of non-spatial cross-validation techniques."
  },
  {
    "objectID": "spatial_ml.html#limitations-and-recommendations",
    "href": "spatial_ml.html#limitations-and-recommendations",
    "title": "Spatial ML model assessment and interpretation",
    "section": "Limitations and Recommendations",
    "text": "Limitations and Recommendations\n\nThe presentation reviewed the limitations of commonly used cross-validation techniques in spatial modeling and suggested modelers focus on the intended spatial prediction horizon rather than on the range of autocorrelation.\nIt advocated for SPEPs and SVIPs as tools to enrich the spatial data science toolkit, potentially improving model interpretation, selection, and design."
  },
  {
    "objectID": "spatial_ml.html#practical-guidance",
    "href": "spatial_ml.html#practical-guidance",
    "title": "Spatial ML model assessment and interpretation",
    "section": "Practical Guidance",
    "text": "Practical Guidance\n\nProvided step-by-step instructions on how to implement SPEPs and SVIPs using R, with practical code examples and discussions on the interpretation of results.\nEmphasized the importance of matching the model assessment approach to the specific spatial prediction tasks and the potential biases that may arise from inappropriate assessment methods.\n\n\nHere are some insights from the course:"
  },
  {
    "objectID": "spatial_ml.html#concluding-insights",
    "href": "spatial_ml.html#concluding-insights",
    "title": "Spatial ML model assessment and interpretation",
    "section": "Concluding Insights",
    "text": "Concluding Insights\n\nThe presentation underscored the pragmatic use of models based on their predictive performance and the role of cross-validation in reducing bias.\nIt was suggested that spatial CV should account for spatial dependence, and modelers should use SPEPs to gain detailed insights into predictive behavior.\nA caution was raised against the over-optimistic assessment of models due to the inappropriate choice of validation data or misinterpretation of variable importance."
  },
  {
    "objectID": "spatial_ml.html#final-thoughts-and-reflections",
    "href": "spatial_ml.html#final-thoughts-and-reflections",
    "title": "Spatial ML model assessment and interpretation",
    "section": "Final Thoughts and Reflections",
    "text": "Final Thoughts and Reflections\n\nThe course instilled the importance of critical assessment and interpretation of ML models in spatial applications.\nThere was a strong emphasis on the practical application of concepts learned, with a focus on ensuring the accuracy and reliability of spatial predictions."
  },
  {
    "objectID": "material/task.html",
    "href": "material/task.html",
    "title": "Task",
    "section": "",
    "text": "List and load spectral bands\n\n\n# list files from a directory\nlibrary(\"terra\")\n\nWarning: package 'terra' was built under R version 4.3.2\n\n\nterra 1.7.55\n\nfiles = list.files(\"clustering_data/data/task\", pattern = \"\\\\.TIF$\", full.names = TRUE)\nfiles\n\n[1] \"clustering_data/data/task/LC08_L2SP_191023_20230605_20230613_02_T1_SR_B1.TIF\"\n[2] \"clustering_data/data/task/LC08_L2SP_191023_20230605_20230613_02_T1_SR_B2.TIF\"\n[3] \"clustering_data/data/task/LC08_L2SP_191023_20230605_20230613_02_T1_SR_B3.TIF\"\n[4] \"clustering_data/data/task/LC08_L2SP_191023_20230605_20230613_02_T1_SR_B4.TIF\"\n[5] \"clustering_data/data/task/LC08_L2SP_191023_20230605_20230613_02_T1_SR_B5.TIF\"\n[6] \"clustering_data/data/task/LC08_L2SP_191023_20230605_20230613_02_T1_SR_B6.TIF\"\n[7] \"clustering_data/data/task/LC08_L2SP_191023_20230605_20230613_02_T1_SR_B7.TIF\"\n\n\n\n#Display metadata\n# load raster data\nlandsat = rast(files)\nlandsat # calling the object displays the metadata\n\nclass       : SpatRaster \ndimensions  : 1946, 2052, 7  (nrow, ncol, nlyr)\nresolution  : 30, 30  (x, y)\nextent      : 562455, 624015, 5797635, 5856015  (xmin, xmax, ymin, ymax)\ncoord. ref. : WGS 84 / UTM zone 33N (EPSG:32633) \nsources     : LC08_L2SP_191023_20230605_20230613_02_T1_SR_B1.TIF  \n              LC08_L2SP_191023_20230605_20230613_02_T1_SR_B2.TIF  \n              LC08_L2SP_191023_20230605_20230613_02_T1_SR_B3.TIF  \n              ... and 4 more source(s)\nnames       : LC08_~SR_B1, LC08_~SR_B2, LC08_~SR_B3, LC08_~SR_B4, LC08_~SR_B5, LC08_~SR_B6, ... \nmin values  :           6,          21,        3531,        3123,        6811,        6857, ... \nmax values  :       36332,       34628,       36371,       37924,       42025,       60674, ... \n\n\nshorten and rename spectral bands\n\nnames(landsat) # original names\n\n[1] \"LC08_L2SP_191023_20230605_20230613_02_T1_SR_B1\"\n[2] \"LC08_L2SP_191023_20230605_20230613_02_T1_SR_B2\"\n[3] \"LC08_L2SP_191023_20230605_20230613_02_T1_SR_B3\"\n[4] \"LC08_L2SP_191023_20230605_20230613_02_T1_SR_B4\"\n[5] \"LC08_L2SP_191023_20230605_20230613_02_T1_SR_B5\"\n[6] \"LC08_L2SP_191023_20230605_20230613_02_T1_SR_B6\"\n[7] \"LC08_L2SP_191023_20230605_20230613_02_T1_SR_B7\"\n\nnames(landsat) = paste0(\"B\", 1:7) # shorten the names\nnames(landsat) # new names\n\n[1] \"B1\" \"B2\" \"B3\" \"B4\" \"B5\" \"B6\" \"B7\"\n\n\n\nLoad vector data and transform CRS\n\n\n# load vector data\npoly = vect(\"clustering_data/data/task/Szamotuly.gpkg\")\npoly\n\n class       : SpatVector \n geometry    : polygons \n dimensions  : 1, 0  (geometries, attributes)\n extent      : 16.01377, 16.74077, 52.37375, 52.79406  (xmin, xmax, ymin, ymax)\n source      : Szamotuly.gpkg\n coord. ref. : lon/lat ETRS89 (EPSG:4258) \n\n\n\npoly = project(poly, \"EPSG:32633\")\ncrs(poly, describe = TRUE)$code # check EPSG after transformation\n\n[1] \"32633\"\n\n\n\nCrop raster data to the area.\n\ncolors = gray.colors(n = 20) # define the color scheme\nplot(landsat[[5]], main = \"Szamotuly county\", col = colors) # plot NIR band\nplot(poly, add = TRUE) # add polygon\n\n\n\n\n\nlandsat = crop(landsat, poly, mask = TRUE)\nplot(landsat[[5]], main = \"Szamotuly county\", col = colors)\nplot(poly, add = TRUE)\n\n\n\n\nScale the values and remove outliers\n\nsummary(landsat)\n\nWarning: [summary] used a sample\n\n\n       B1              B2              B3              B4       \n Min.   : 5944   Min.   : 2420   Min.   : 7609   Min.   : 6939  \n 1st Qu.: 7806   1st Qu.: 8046   1st Qu.: 8907   1st Qu.: 8441  \n Median : 8009   Median : 8252   Median : 9401   Median : 8835  \n Mean   : 8316   Mean   : 8613   Mean   : 9712   Mean   : 9452  \n 3rd Qu.: 8601   3rd Qu.: 8902   3rd Qu.:10108   3rd Qu.: 9958  \n Max.   :19577   Max.   :20198   Max.   :21355   Max.   :22268  \n NA's   :51153   NA's   :51152   NA's   :51151   NA's   :51151  \n       B5              B6              B7       \n Min.   : 7692   Min.   : 7322   Min.   : 7326  \n 1st Qu.:15928   1st Qu.:11605   1st Qu.: 9348  \n Median :19210   Median :12471   Median : 9948  \n Mean   :19194   Mean   :13496   Mean   :11210  \n 3rd Qu.:22071   3rd Qu.:14844   3rd Qu.:12193  \n Max.   :29478   Max.   :25647   Max.   :23481  \n NA's   :51151   NA's   :51151   NA's   :51151  \n\n\n\nlandsat = landsat * 2.75e-05 - 0.2\nsummary(landsat)\n\nWarning: [summary] used a sample\n\n\n       B1              B2              B3              B4       \n Min.   :-0.04   Min.   :-0.13   Min.   :0.01    Min.   :-0.01  \n 1st Qu.: 0.01   1st Qu.: 0.02   1st Qu.:0.04    1st Qu.: 0.03  \n Median : 0.02   Median : 0.03   Median :0.06    Median : 0.04  \n Mean   : 0.03   Mean   : 0.04   Mean   :0.07    Mean   : 0.06  \n 3rd Qu.: 0.04   3rd Qu.: 0.04   3rd Qu.:0.08    3rd Qu.: 0.07  \n Max.   : 0.34   Max.   : 0.36   Max.   :0.39    Max.   : 0.41  \n NA's   :51153   NA's   :51152   NA's   :51151   NA's   :51151  \n       B5              B6              B7       \n Min.   :0.01    Min.   :0.00    Min.   :0.00   \n 1st Qu.:0.24    1st Qu.:0.12    1st Qu.:0.06   \n Median :0.33    Median :0.14    Median :0.07   \n Mean   :0.33    Mean   :0.17    Mean   :0.11   \n 3rd Qu.:0.41    3rd Qu.:0.21    3rd Qu.:0.14   \n Max.   :0.61    Max.   :0.51    Max.   :0.45   \n NA's   :51151   NA's   :51151   NA's   :51151  \n\n\nPrepare the matrix for classification (remove empty values and sample).\n\nlandsat[landsat &lt; 0] = NA\nlandsat[landsat &gt; 1] = NA\n\n\nplot1 = plotRGB(landsat, r = 4, g = 3, b = 2, scale = 1, stretch = \"lin\")\n\n\n\n\n\nlibrary(\"cluster\")\n\n\nmat = values(landsat)\nnrow(mat) # print number of rows/pixels\n\n[1] 2553992\n\n\n\nmat_omit = na.omit(mat)\nnrow(mat_omit)\n\n[1] 1246565\n\n\n\nset.seed(1)\nmdl = kmeans(mat_omit, centers = 5)\n\n\nmdl$centers\n\n          B1         B2         B3         B4        B5        B6         B7\n1 0.02166975 0.02913068 0.05963210 0.04659851 0.3635857 0.1548141 0.08215531\n2 0.04527543 0.05493472 0.08671713 0.09044609 0.2969842 0.2398647 0.17131855\n3 0.07720274 0.09108228 0.13243481 0.15542923 0.3087454 0.3347357 0.29259717\n4 0.01932286 0.02474700 0.04490836 0.03620496 0.2066564 0.1240278 0.06635903\n5 0.01300182 0.02149046 0.05689401 0.03608233 0.4637850 0.1186973 0.05500941\n\n\n\nhead(mdl$cluster) # display the first 6 elements\n\n[1] 4 4 4 4 4 4\n\n\nUse the k-means algorithm for clustering and validate the results with the silhouette index. Check how the results change depending on the number of clusters. Optionally, you can test another clustering method.\n\nset.seed(1)\n# draw sample indexes\nidx = sample(1:nrow(mat_omit), size = 10000)\nhead(idx)\n\n[1] 452737 124413 856018  25173 640775 538191\n\n\n\n# calculate silhouette index\nsil = silhouette(mdl$cluster[idx], dist(mat_omit[idx, ]))\nsummary(sil)\n\nSilhouette of 10000 units in 5 clusters from silhouette.default(x = mdl$cluster[idx], dist = dist(mat_omit[idx, ])) :\n Cluster sizes and average silhouette widths:\n     2405      1682      1041      2637      2235 \n0.3322348 0.2783603 0.4524438 0.5989181 0.4629095 \nIndividual silhouette widths:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-0.1087  0.2861  0.4638  0.4352  0.5979  0.7465 \n\n\n\ncolors = rainbow(n = 5)\nplot(sil, border = NA, col = colors, main = \"Silhouette Index\")\n\n\n\n\nTry to interpret what the clusters represent using a boxplot and RGB composition.\n\nlibrary(\"tidyr\") # data transformation\n\nWarning: package 'tidyr' was built under R version 4.3.2\n\n\n\nAttaching package: 'tidyr'\n\n\nThe following object is masked from 'package:terra':\n\n    extract\n\nlibrary(\"ggplot2\") # data visualization\n\nWarning: package 'ggplot2' was built under R version 4.3.2\n\n\n\nstats = cbind(mat_omit[idx, ], cluster = mdl$cluster[idx])\nstats = as.data.frame(stats)\nhead(stats)\n\n         B1        B2        B3        B4        B5        B6        B7 cluster\n1 0.0163700 0.0229425 0.0522025 0.0380675 0.3392750 0.1368750 0.0792075       1\n2 0.0336675 0.0361700 0.0493150 0.0464825 0.1752375 0.1334375 0.0773100       4\n3 0.0161500 0.0264900 0.0623225 0.0539625 0.3488725 0.1362975 0.0748900       1\n4 0.0163975 0.0211275 0.0416150 0.0328150 0.1968800 0.1226025 0.0631475       4\n5 0.0165075 0.0220900 0.0490950 0.0288825 0.4048075 0.1533475 0.0627350       1\n6 0.0133175 0.0182950 0.0423850 0.0248950 0.4129750 0.1081650 0.0506075       5\n\n\n\nstats = pivot_longer(stats, cols = 1:7, names_to = \"band\", values_to = \"value\")\n# change the data type to factor\nstats$cluster = as.factor(stats$cluster)\nstats$band = as.factor(stats$band)\nhead(stats)\n\n# A tibble: 6 × 3\n  cluster band   value\n  &lt;fct&gt;   &lt;fct&gt;  &lt;dbl&gt;\n1 1       B1    0.0164\n2 1       B2    0.0229\n3 1       B3    0.0522\n4 1       B4    0.0381\n5 1       B5    0.339 \n6 1       B6    0.137 \n\n\n\nggplot(stats, aes(x = band, y = value, fill = cluster)) +\n  geom_boxplot()\n\n\n\n\n\nggplot(stats, aes(x = band, y = value, fill = cluster)) +\n  geom_boxplot(show.legend = FALSE) +\n  scale_fill_manual(values = colors) +\n  facet_wrap(vars(cluster)) +\n  xlab(\"Spectral band\") +\n  ylab(\"Reflectance\") +\n  theme_light()\n\n\n\n\n\nvec = rep(NA, ncell(landsat)) # prepare an empty vector\nvec[complete.cases(mat)] = mdl$cluster # assign clusters to vector if not NA\nclustering = rast(landsat, nlyrs = 1, vals = vec) # create raster\n\n\nPresent the results on a map and choose the appropriate color scheme.\n\n\ncolors = c(\"#91632b\", \"#086209\", \"#fdd327\", \"#d9d9d9\", \"#d20000\")\ncategory = c(\"barren\", \"forest\", \"cropland\", \"bare soil\", \"urban\")\nplot2 = plot(clustering, col = colors, type = \"classes\", levels = category)"
  },
  {
    "objectID": "material/Clustering.html",
    "href": "material/Clustering.html",
    "title": "Unsupervised classification (clustering) of satellite images",
    "section": "",
    "text": "We can download the dataset from Zenodo using the download.file() function and then unpack the .zip archive using the unzip() function. If you downloaded the data manually before, you can skip this part.\n\noptions(timeout = 600) # increase connection timeout\nurl = \"https://zenodo.org/record/8164626/files/data.zip\"\ndownload.file(url, \"data.zip\")\nunzip(\"data.zip\")"
  },
  {
    "objectID": "material/Clustering.html#data-acquisition",
    "href": "material/Clustering.html#data-acquisition",
    "title": "Unsupervised classification (clustering) of satellite images",
    "section": "",
    "text": "We can download the dataset from Zenodo using the download.file() function and then unpack the .zip archive using the unzip() function. If you downloaded the data manually before, you can skip this part.\n\noptions(timeout = 600) # increase connection timeout\nurl = \"https://zenodo.org/record/8164626/files/data.zip\"\ndownload.file(url, \"data.zip\")\nunzip(\"data.zip\")"
  },
  {
    "objectID": "material/Clustering.html#data-loading",
    "href": "material/Clustering.html#data-loading",
    "title": "Unsupervised classification (clustering) of satellite images",
    "section": "Data loading",
    "text": "Data loading\n\n#install.packages(c(\"terra\", \"tidyr\", \"ggplot2\"))\n\n\n# load the package\nlibrary(\"terra\")\n\nIn the first step, we need to create a list of files (rasters) that we are going to load. To do this, we can use the list.files() function, which takes a path to a folder with files as an argument. In addition, we must indicate what kind of files we want to load (pattern = \"\\\\.TIF$\") and return full paths to the files (full.names = TRUE). If you unpacked the data in a different location, then you must indicate the correct path.\n\n# list files from a directory\nfiles = list.files(\"clustering_data/data/data\", pattern = \"\\\\.TIF$\", full.names = TRUE)\nfiles\n\n[1] \"clustering_data/data/data/LC08_L2SP_191023_20230605_20230613_02_T1_SR_B1.TIF\"\n[2] \"clustering_data/data/data/LC08_L2SP_191023_20230605_20230613_02_T1_SR_B2.TIF\"\n[3] \"clustering_data/data/data/LC08_L2SP_191023_20230605_20230613_02_T1_SR_B3.TIF\"\n[4] \"clustering_data/data/data/LC08_L2SP_191023_20230605_20230613_02_T1_SR_B4.TIF\"\n[5] \"clustering_data/data/data/LC08_L2SP_191023_20230605_20230613_02_T1_SR_B5.TIF\"\n[6] \"clustering_data/data/data/LC08_L2SP_191023_20230605_20230613_02_T1_SR_B6.TIF\"\n[7] \"clustering_data/data/data/LC08_L2SP_191023_20230605_20230613_02_T1_SR_B7.TIF\"\n\n\nOnce we have created a list of files, we can load them using the rast() function from the terra package and then display the metadata.\n\n# load raster data\nlandsat = rast(files)\nlandsat # calling the object displays the metadata\n\nclass       : SpatRaster \ndimensions  : 2360, 2469, 7  (nrow, ncol, nlyr)\nresolution  : 30, 30  (x, y)\nextent      : 594915, 668985, 5777865, 5848665  (xmin, xmax, ymin, ymax)\ncoord. ref. : WGS 84 / UTM zone 33N (EPSG:32633) \nsources     : LC08_L2SP_191023_20230605_20230613_02_T1_SR_B1.TIF  \n              LC08_L2SP_191023_20230605_20230613_02_T1_SR_B2.TIF  \n              LC08_L2SP_191023_20230605_20230613_02_T1_SR_B3.TIF  \n              ... and 4 more source(s)\nnames       : LC08_~SR_B1, LC08_~SR_B2, LC08_~SR_B3, LC08_~SR_B4, LC08_~SR_B5, LC08_~SR_B6, ... \nmin values  :          31,          28,        2739,        2745,        7413,        6857, ... \nmax values  :       36332,       34628,       36618,       32237,       50996,       61014, ... \n\n\nWe can also shorten or rename the spectral bands. Before this, make sure that the bands are loaded in the correct order.\n\nnames(landsat) # original names\n\n[1] \"LC08_L2SP_191023_20230605_20230613_02_T1_SR_B1\"\n[2] \"LC08_L2SP_191023_20230605_20230613_02_T1_SR_B2\"\n[3] \"LC08_L2SP_191023_20230605_20230613_02_T1_SR_B3\"\n[4] \"LC08_L2SP_191023_20230605_20230613_02_T1_SR_B4\"\n[5] \"LC08_L2SP_191023_20230605_20230613_02_T1_SR_B5\"\n[6] \"LC08_L2SP_191023_20230605_20230613_02_T1_SR_B6\"\n[7] \"LC08_L2SP_191023_20230605_20230613_02_T1_SR_B7\"\n\nnames(landsat) = paste0(\"B\", 1:7) # shorten the names\nnames(landsat) # new names\n\n[1] \"B1\" \"B2\" \"B3\" \"B4\" \"B5\" \"B6\" \"B7\"\n\n# or alternatively rename\n# names(landsat) = c(\"Ultra Blue\", \"Blue\", \"Green\", \"Red\", \"NIR\", \"SWIR1\", \"SWIR2\")\n\nLoading vector data is done in an analogous way using the vect() function.\n\n# load vector data\npoly = vect(\"clustering_data/data/data/Poznan.gpkg\")\npoly\n\n class       : SpatVector \n geometry    : polygons \n dimensions  : 1, 0  (geometries, attributes)\n extent      : 326611.5, 391121.8, 477976.1, 536838.4  (xmin, xmax, ymin, ymax)\n source      : Poznan.gpkg\n coord. ref. : ETRF2000-PL / CS92 (EPSG:2180) \n\n\nAs we can see from the metadata, raster and vector data have different coordinate reference systems (CRS), which is troublesome. The easiest way is to transform the vector data into a raster’s CRS and we can do it with the project() function and specifying the EPSG code.\n\npoly = project(poly, \"EPSG:32633\")\ncrs(poly, describe = TRUE)$code # check EPSG after transformation\n\n[1] \"32633\"\n\n\nNow we can prepare a simple visualization using the near infrared band (NIR; B5) and polygon as an example. You can either use index ([[5]]) or name ([[\"B5\"]]) to select a band (raster layer).\n\ncolors = gray.colors(n = 20) # define the color scheme\nplot(landsat[[5]], main = \"Poznan county\", col = colors) # plot NIR band\nplot(poly, add = TRUE) # add polygon"
  },
  {
    "objectID": "material/Clustering.html#raster-processing",
    "href": "material/Clustering.html#raster-processing",
    "title": "Unsupervised classification (clustering) of satellite images",
    "section": "Raster processing",
    "text": "Raster processing\nThe extent of our analysis area is limited to the Poznan county, while the satellite scene has a much larger extent. In such a situation, we can crop the rasters, so that their further processing will be faster and the results will take up less space on disk. The crop() function is used to crop the rasters, and we need to specify the raster and vector as arguments.\nNote that the rasters are represented as matrices, so the cropping is done to the bounding box. To include only the area of our polygon in the analysis, we need to mask the pixels outside the boundary. This can be done by setting the mask = TRUE argument in the aforementioned function.\n\nlandsat = crop(landsat, poly, mask = TRUE)\nplot(landsat[[5]], main = \"Poznan county\", col = colors)\nplot(poly, add = TRUE)\n\n\n\n\nIn the next step, we can easily check the descriptive statistics of our dataset.\n\nsummary(landsat)\n\n       B1              B2              B3              B4       \n Min.   : 4095   Min.   : 1959   Min.   : 8075   Min.   : 7655  \n 1st Qu.: 7813   1st Qu.: 8037   1st Qu.: 8987   1st Qu.: 8408  \n Median : 8176   Median : 8429   Median : 9659   Median : 9170  \n Mean   : 8464   Mean   : 8771   Mean   : 9901   Mean   : 9706  \n 3rd Qu.: 8879   3rd Qu.: 9229   3rd Qu.:10408   3rd Qu.:10499  \n Max.   :23937   Max.   :25640   Max.   :28745   Max.   :30744  \n NA's   :42589   NA's   :42588   NA's   :42588   NA's   :42588  \n       B5              B6              B7       \n Min.   : 7413   Min.   : 7447   Min.   : 7406  \n 1st Qu.:16791   1st Qu.:11743   1st Qu.: 9318  \n Median :18907   Median :13078   Median :10541  \n Mean   :18980   Mean   :13783   Mean   :11553  \n 3rd Qu.:21018   3rd Qu.:15265   3rd Qu.:12847  \n Max.   :33376   Max.   :34485   Max.   :37960  \n NA's   :42588   NA's   :42588   NA's   :42588  \n\n\nAs we can see, the spectral reflectance values are several thousand for each band and are encoded as integers. The spectral reflectance should be in the range from 0 to 1. Therefore, we need to scale our data using the following equation (this only applies to reflectance, not temperature!):\n\\[x = x \\cdot 0.0000275 - 0.2\\]\nFor example, the pixel value in the near infrared (NIR) band is 15000. Using the above formula, we need to multiply this value by 0.0000275 (scale factor) and then subtract 0.2 (offset). As a result, we will get a reflection equal to 0.2125. Note that each product/collection has a different formula and it is necessary to consult the documentation.\nWe don’t need to apply this formula separately for each band in the loop because the arithmetic operations in the terra package are applied to all bands by default.\n\nlandsat = landsat * 2.75e-05 - 0.2\nsummary(landsat)\n\n       B1              B2              B3              B4       \n Min.   :-0.09   Min.   :-0.15   Min.   :0.02    Min.   :0.01   \n 1st Qu.: 0.01   1st Qu.: 0.02   1st Qu.:0.05    1st Qu.:0.03   \n Median : 0.02   Median : 0.03   Median :0.07    Median :0.05   \n Mean   : 0.03   Mean   : 0.04   Mean   :0.07    Mean   :0.07   \n 3rd Qu.: 0.04   3rd Qu.: 0.05   3rd Qu.:0.09    3rd Qu.:0.09   \n Max.   : 0.46   Max.   : 0.51   Max.   :0.59    Max.   :0.65   \n NA's   :42589   NA's   :42588   NA's   :42588   NA's   :42588  \n       B5              B6              B7       \n Min.   :0.00    Min.   :0.00    Min.   :0.00   \n 1st Qu.:0.26    1st Qu.:0.12    1st Qu.:0.06   \n Median :0.32    Median :0.16    Median :0.09   \n Mean   :0.32    Mean   :0.18    Mean   :0.12   \n 3rd Qu.:0.38    3rd Qu.:0.22    3rd Qu.:0.15   \n Max.   :0.72    Max.   :0.75    Max.   :0.84   \n NA's   :42588   NA's   :42588   NA's   :42588  \n\n\nWe can still see that some values exceed the range of 0 to 1. These are outliers that are usually associated with incorrect measurement or oversaturation. We can solve this problem in two ways:\n\nReplace these values with missing data (NA).\nTrim to minimum and maximum value.\n\nThe first way can cause us to lose a large part of the dataset. The second way, on the other hand, can cause skewed results.\n\n# method 1\nlandsat[landsat &lt; 0] = NA\nlandsat[landsat &gt; 1] = NA\n\n\n# method 2\nlandsat[landsat &lt; 0] = 0\nlandsat[landsat &gt; 1] = 1\n\nAfter scaling the values, we can display the RGB composition. In this case, instead of plot() function, use plotRGB() function and define the order of red, green and blue bands. In addition, we need to specify the maximum reflection value for the bands (in our case scale = 1). It often happens that compositions are too dark/bright, then it is helpful to apply color stretching using the stretch = \"lin\" or stretch = \"hist\" argument.\n\n# plotRGB(landsat, r = 4, g = 3, b = 2, scale = 1)\nplotRGB(landsat, r = 4, g = 3, b = 2, scale = 1, stretch = \"lin\")"
  },
  {
    "objectID": "material/Clustering.html#clustering",
    "href": "material/Clustering.html#clustering",
    "title": "Unsupervised classification (clustering) of satellite images",
    "section": "Clustering",
    "text": "Clustering\n\n# load clustering package\nlibrary(\"cluster\")\n\nData for modeling must be prepared in an appropriate way. Classification models most often require a matrix or data frame at the training stage. Raster data can be transformed into a matrix using the values() function.\n\nmat = values(landsat)\nnrow(mat) # print number of rows/pixels\n\n[1] 4182465\n\n\nUsing the interactive View() function, we can see what our matrix looks like.\n\nView(mat)\n\nAs we can see, a lot of its values are marked as missing data (mostly they are outside the analysis area). Usually models do not support NA, so we need to remove them. A dedicated function na.omit() can be used for this.\n\nmat_omit = na.omit(mat)\nnrow(mat_omit)\n\n[1] 2402430\n\n\nNow we will move on to the next stage of the analysis, which is to train the model. There are many clustering methods and models (see CRAN Task View), but in this example we will use the simplest k-means clustering method. This model only requires the number of groups/clusters (centers argument) to be given in advance. This is a stochastic algorithm, so it returns different results each time. To make the analysis repeatable we need to set the seed of randomness – set.seed().\n\nset.seed(1)\nmdl = kmeans(mat_omit, centers = 6)\n\nAs a result of the above operation, we received, among others:\n\nCalculated group averages for each band (mdl$centers).\nVector with classified matrix (pixels) values (mdl$cluster).\n\nLet’s display these objects:\n\nmdl$centers\n\n          B1         B2         B3         B4        B5        B6         B7\n1 0.05103899 0.06176081 0.09707305 0.10302303 0.3134292 0.2538940 0.18729837\n2 0.02161415 0.02811265 0.05688793 0.04397068 0.3501170 0.1548471 0.07983935\n3 0.01568182 0.02102859 0.04266913 0.03074910 0.2153262 0.1025743 0.05127214\n4 0.01476647 0.02272622 0.05795271 0.03789260 0.4545335 0.1238540 0.05838875\n5 0.04022702 0.05004405 0.07896698 0.08065334 0.2440231 0.1842851 0.13326570\n6 0.08394913 0.09824070 0.14036534 0.16473647 0.3085605 0.3406860 0.30397409\n\n\n\nhead(mdl$cluster) # display the first 6 elements\n\n[1] 2 2 2 2 2 4\n\n\nThis means that the first row (representing a single pixel) belongs to group 2, the second to group 2, the third to group 2, and so on."
  },
  {
    "objectID": "material/Clustering.html#validation",
    "href": "material/Clustering.html#validation",
    "title": "Unsupervised classification (clustering) of satellite images",
    "section": "Validation",
    "text": "Validation\nAn inseparable element of modeling is the validation of the created models. The challenge is to choose the right grouping method for a specific dataset and determine the appropriate number of groups. Note that increasing the number of clusters increases the similarity between objects in a cluster, but with more clusters, their interpretation becomes more difficult.\nThe most common way to validate clustering results is to use internal metrics, such as Dunn index, Davies–Bouldin index or silhouette index. In this example, we will use the latter.\nSilhouette index evaluates the compactness and separation of the clusters based on the distances between objects within the same cluster and between objects in different clusters. The values of this index range from -1 to 1. A value close to 1 indicates that the object is well clustered and is far away from neighboring clusters. A value close to -1 suggests that the object may have been assigned to the wrong cluster. A value near 0 indicates that the object is very close to the boundary between different clusters. Thus, in general, a higher value of this index indicates better clustering results. See the cluster::silhouette() documentation for more details.\nNow let’s try to calculate this index. Basically, using this index requires calculating the similarity of each object with every object, which in our case is an impossible task (our dataset consists of 2.5 million objects). To do this, we need to draw a smaller sample (let’s say \\(n = 10 000\\)). In the function, we need to specify two objects – a vector with clusters and a dissimilarity matrix, which can be calculated in advance using the dist() function.\n\nset.seed(1)\n# draw sample indexes\nidx = sample(1:nrow(mat_omit), size = 10000)\nhead(idx)\n\n[1] 2221565 1485099  856018 2122325 1343338  640775\n\n\n\n# calculate silhouette index\nsil = silhouette(mdl$cluster[idx], dist(mat_omit[idx, ]))\nsummary(sil)\n\nSilhouette of 10000 units in 6 clusters from silhouette.default(x = mdl$cluster[idx], dist = dist(mat_omit[idx, ])) :\n Cluster sizes and average silhouette widths:\n     1532      2863      1512      1678      1450       965 \n0.2361307 0.3171400 0.4657474 0.4235420 0.3291018 0.4483677 \nIndividual silhouette widths:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n-0.1014  0.2139  0.3828  0.3595  0.5183  0.6519 \n\n\nThe average cluster convergence is 0.36. This is not the best result. We should try to increase the number of clusters or use another clustering method. We can also check the results on the chart.\n\ncolors = rainbow(n = 6)\nplot(sil, border = NA, col = colors, main = \"Silhouette Index\")"
  },
  {
    "objectID": "material/Clustering.html#interpretation",
    "href": "material/Clustering.html#interpretation",
    "title": "Unsupervised classification (clustering) of satellite images",
    "section": "Interpretation",
    "text": "Interpretation\nThe essence of grouping is to create a group of similar objects, but our task is to interpret what the created groups represent and name them. Interpretation is a difficult task, and often the results are unclear. For this purpose, it is necessary to analyze the descriptive statistics of groups and to use various plots and map compositions. Knowledge of the spectral properties of objects is also very useful.\nSo let’s try to interpret the obtained clusters by assisting with a boxplot. The ggplot2 package works best for creating visualizations. Here you can find a free manual and ready-made recipes.\nggplot2 requires preparing the dataset to the appropriate form. The data must be presented as a data frame in the so-called long form (multiple rows), while base functions for visualization require wide form (multiple columns). This change can be made easily using the tidyr package.\n\n# install.packages(c(\"tidyr\", \"ggplot2\"))\nlibrary(\"tidyr\") # data transformation\n\nWarning: package 'tidyr' was built under R version 4.3.2\n\nlibrary(\"ggplot2\") # data visualization\n\nWarning: package 'ggplot2' was built under R version 4.3.2\n\n\nAs we noted earlier, our dataset is quite large and there is no need to present all the data. We can do it more efficiently by using a previously drawn sample. Now we need to combine the drawn rows from the matrix with the corresponding clusters (cbind()). Then we will convert the matrix into a data frame (as.data.frame()).\n\nstats = cbind(mat_omit[idx, ], cluster = mdl$cluster[idx])\nstats = as.data.frame(stats)\nhead(stats)\n\n         B1        B2        B3        B4        B5        B6        B7 cluster\n1 0.0499475 0.0673825 0.1141875 0.1329425 0.3903975 0.3669400 0.2197325       6\n2 0.0282500 0.0369400 0.0651000 0.0564925 0.3507150 0.1613225 0.1018675       2\n3 0.0117225 0.0179925 0.0372975 0.0255275 0.2450600 0.1129225 0.0512950       3\n4 0.0235475 0.0349050 0.0828375 0.0643300 0.4111325 0.1421000 0.0912250       4\n5 0.0780800 0.0862475 0.1151500 0.1311000 0.2536125 0.3102075 0.2714600       6\n6 0.0753300 0.0904000 0.1325025 0.1606350 0.3108950 0.3309700 0.3002250       6\n\n\nThe displayed data is in a wide form (each spectral band is stored in a separate column). Now we need to change the form, in which we get two columns – the band and the value. To do this, we will use the pivot_longer() function.\n\nstats = pivot_longer(stats, cols = 1:7, names_to = \"band\", values_to = \"value\")\n# change the data type to factor\nstats$cluster = as.factor(stats$cluster)\nstats$band = as.factor(stats$band)\nhead(stats)\n\n# A tibble: 6 × 3\n  cluster band   value\n  &lt;fct&gt;   &lt;fct&gt;  &lt;dbl&gt;\n1 6       B1    0.0499\n2 6       B2    0.0674\n3 6       B3    0.114 \n4 6       B4    0.133 \n5 6       B5    0.390 \n6 6       B6    0.367 \n\n\nThe data structure is already prepared. Now let’s create a simple boxplot.\n\nggplot(stats, aes(x = band, y = value, fill = cluster)) +\n  geom_boxplot()\n\n\n\n\nBy changing a few default parameters, we can improve the perception of this figure.\n\nggplot(stats, aes(x = band, y = value, fill = cluster)) +\n  geom_boxplot(show.legend = FALSE) +\n  scale_fill_manual(values = colors) +\n  facet_wrap(vars(cluster)) +\n  xlab(\"Spectral band\") +\n  ylab(\"Reflectance\") +\n  theme_light()\n\n\n\n\nBased on the above graph, we can analyze the spectral properties of the clusters, and therefore interpret what objects they represent. Simplified conclusions may be as follows:\n\nCluster 1 – the significant difference between the NIR and RED bands indicates the presence of vegetation, in addition, we can see a high reflection in the SWIR bands, which relates to soils. Thus, we can conclude that this cluster represents barren areas with little vegetation.\nCluster 2 – the large difference between the NIR and RED bands, indicates a high level of biomass. Clusters 2 and 4 have similar distributions, but in cluster 2 there is less difference between the mentioned bands. The data is from the beginning of June, so we can assume that crops have almost reached the maximum level of biomass (in this climate zone), which should be higher than that of forests. Therefore, this cluster represents a forest.\nCluster 3 – this cluster looks similar to cluster 2 except that there are outliers close to 0 in all bands. These values represent water objects that absorb radiation. Of course, this is not a correct classification – water objects and forests should be assigned to separate clusters.\nCluster 4 – cropland (see description of cluster 2).\nCluster 5 – low reflectance in the visible bands and higher reflectance in the NIR and SWIR bands may indicate buildings (urban area), generally artificial objects.\nCluster 6 – relatively high reflection in all bands (including NIR and SWIR) indicates a bright object. In this case, they are bare soils without vegetation cover, which are usually light brown or grey."
  },
  {
    "objectID": "material/Clustering.html#final-map",
    "href": "material/Clustering.html#final-map",
    "title": "Unsupervised classification (clustering) of satellite images",
    "section": "Final map",
    "text": "Final map\nThe last step is to prepare a classification (so-called land cover) map. First, we need to prepare an empty vector with the length of the number of raster pixels. This can be checked using the ncell() function. In our case it is 4,182,465. Next, we need to assign our clusters in the vector to the appropriate places, i.e. those that are not masked (NA). The unmasked values can be referenced by the complete.cases() function. In the last step, copy the metadata of the landsat object, but only with one layer, and assign it the values of the vec vector.\n\nvec = rep(NA, ncell(landsat)) # prepare an empty vector\nvec[complete.cases(mat)] = mdl$cluster # assign clusters to vector if not NA\nclustering = rast(landsat, nlyrs = 1, vals = vec) # create raster\n\nNow let’s represent the result of clustering on the map using the appropriate colors and names of the clusters.\n\ncolors = c(\"#91632b\", \"#086209\", \"#086209\", \"#fdd327\", \"#d20000\", \"#d9d9d9\")\ncategory = c(\"barren\", \"forest\", \"forest/water\", \"cropland\", \"urban\", \"bare soil\")\nplot(clustering, col = colors, type = \"classes\", levels = category)\n\n\n\n\nIf the result is satisfactory, we can save it using the writeRaster() function. Such a file can be later loaded in R or another program that supports spatial data (e.g. QGIS). In addition, for categorical data, it is useful to set the datatype as Byte / INT1U when saving.\n\nwriteRaster(clustering, \"clustering2.tif\", datatype = \"INT1U\")"
  },
  {
    "objectID": "material/Clustering.html#summary",
    "href": "material/Clustering.html#summary",
    "title": "Unsupervised classification (clustering) of satellite images",
    "section": "Summary",
    "text": "Summary\nThis workshop is only an outline of the use of unsupervised classification for satellite imagery. The content can be expanded to include more topics on:\n\nautomatic search and download of satellite data\nmulti-temporal analysis\ncloud data processing\nintegration of various sensors (e.g. Sentinel 2) and data (e.g. DEM)\nspatial validation\nselection of explanatory variables and dimensionality reduction\n\nTo reference to the above, the following issues can also be addressed:\n\nPost-processing of results – the used clustering method is pixel-based, which means that neighboring pixels are not considered in the classification. This causes the pepper and salt effect. This can be slightly improved by using a modal filter (terra::focal()) or sieve filter (terra::sieve()). Another approach is to use explanatory variables that are calculated in a moving window or at smaller spatial scales.\nSeparate forests from water objects – in our clustering, forests and water objects were incorrectly classified into one cluster. As a solution, a water spatial index can be calculated to detect water (check Table 2 from this publication). Moreover, other types of spectral indexes, and the thermal and panchromatic bands (at a higher resolution of 15m) can be included in this analysis.\nPrediction in larger or new areas – our analysis covered a small area, so we could load all the data into memory. However, usually the model is trained on a sample and then applied to the whole area. Unfortunately, the kmeans() function does not have a predict method, so we have to write it ourselves. It is not complicated; it just requires calculating the pixel distance for each cluster and selecting the closest one. The second thing, in order to speed up the prediction, it would be worth parallelizing this process. A final note, keep in mind that the developed model may work incorrectly in other locations.\nComparison of results with supervised classification – there are many land cover maps (see CORINE Land Cover, ESA WorldCover, ESRI Land Cover). It would be nice to compare the two approaches.\n\nIf you are interested in this topic, you can find more information in the following free books:\n\nSpatial Data Science with R and “terra”\nGeocomputation with R\nSpatial Data Science: With Applications in R\n\nIt is also worth checking out other packages for spatial data analysis and machine learning (mlr3 and tidymodels frameworks in particular).\nIf you have any problem, it is best to look for help on StackOverflow or RStudio Community. Often interesting discussions appear on Twitter / Mastodon (#rspatial) and GitHub (https://github.com/rspatial; https://github.com/r-spatial)."
  },
  {
    "objectID": "material/tidy.html",
    "href": "material/tidy.html",
    "title": "Tidy geographic data",
    "section": "",
    "text": "These materials were created for the OpenGeoHub Summer School 2023.\nThey can be used with reference to the accompanying slides, available at ogh23.robinlovelace.net/opengeohub2023.\nSee the parent repo and session description in the agenda for context."
  },
  {
    "objectID": "material/tidy.html#learning-objectives",
    "href": "material/tidy.html#learning-objectives",
    "title": "Tidy geographic data",
    "section": "1.1 Learning objectives",
    "text": "1.1 Learning objectives\nBy the end of the session, participants will be able to:\n\nRead, write, manipulate, and plot geographic data using the sf package\nUse the tidyverse metapackage to speed-up the writing of geographic data analysis pipelines\nUse the geos package to perform geometric operations on geographic data\nUnderstand the strengths and weaknesses of the tidyverse for geographic data analysis"
  },
  {
    "objectID": "material/tidy.html#prerequisites",
    "href": "material/tidy.html#prerequisites",
    "title": "Tidy geographic data",
    "section": "1.2 Prerequisites",
    "text": "1.2 Prerequisites\nWe recommend you run the code in the practical session with a modern integrated development environment (IDE) such as\n\nRStudio: an IDE focussed on data science and software development with R. See posit.co for installation instructions.\nVS Code: a general purpose, popular and future-proof IDE with support for R. See github.com/REditorSupport/vscode-R and quarto.org for installation instructions.\n\nAfter you have installed a suitable IDE you will need to install R packages used in this tutorial. You can install the packages we’ll use with the following commands:\n\n# Install remotes if not already installed\nif (!requireNamespace(\"remotes\")) {\n    install.packages(\"remotes\")\n}\n\n# The packages we'll use\npkgs = c(\n    \"sf\",\n    \"tidyverse\",\n    \"geos\",\n    \"ggspatial\",\n    \"spData\"\n)\n\n\nremotes::install_cran(pkgs)\n\nAfter running the above commands, you should be able to load the packages with the following command (we will load the packages individually in subsequent sections):\n\nsapply(pkgs, require, character.only = TRUE)"
  },
  {
    "objectID": "material/tidy.html#reading-and-writing-geographic-data",
    "href": "material/tidy.html#reading-and-writing-geographic-data",
    "title": "Tidy geographic data",
    "section": "2.1 Reading and writing geographic data",
    "text": "2.1 Reading and writing geographic data\nYou can read and write a wide range of vector geographic data with sf. Save the countries object to a file called countries.geojson and inspect the result.\n\nsf::write_sf(countries, \"countries.geojson\", delete_dsn = TRUE)\n\nYou can read the file in again with read_sf() (which returns a ‘tidyverse compliant’ tibble data frame) or st_read(), as shown below.\n\ncountries_new1 = sf::read_sf(\"countries.geojson\")\ncountries_new2 = sf::st_read(\"countries.geojson\")\n\nReading layer `countries' from data source \n  `C:\\Users\\leoni\\Documents\\Projekte\\OGH2023\\material\\countries.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 4 features and 10 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 12.24011 ymin: 47.75843 xmax: 26.58828 ymax: 56.37253\nGeodetic CRS:  WGS 84\n\n\nFor most purposes the two representations are the same, although the ‘tibble’ version’s print outpout is slightly different.\n\ncountries_new1 |&gt;\n  head(2)\n\nSimple feature collection with 2 features and 10 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 14.07452 ymin: 49.0274 xmax: 26.58828 ymax: 56.37253\nGeodetic CRS:  WGS 84\n# A tibble: 2 × 11\n  iso_a2 name_long continent region_un subregion   type  area_km2    pop lifeExp\n  &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;     &lt;chr&gt;       &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 PL     Poland    Europe    Europe    Eastern Eu… Sove…  310402. 3.80e7    77.6\n2 LT     Lithuania Europe    Europe    Northern E… Sove…   63831. 2.93e6    74.5\n# ℹ 2 more variables: gdpPercap &lt;dbl&gt;, geometry &lt;MULTIPOLYGON [°]&gt;\n\ncountries_new2 |&gt;\n  head(2)\n\nSimple feature collection with 2 features and 10 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 14.07452 ymin: 49.0274 xmax: 26.58828 ymax: 56.37253\nGeodetic CRS:  WGS 84\n  iso_a2 name_long continent region_un       subregion              type\n1     PL    Poland    Europe    Europe  Eastern Europe Sovereign country\n2     LT Lithuania    Europe    Europe Northern Europe Sovereign country\n   area_km2      pop  lifeExp gdpPercap                       geometry\n1 310402.33 38011735 77.60244  24347.07 MULTIPOLYGON (((23.48413 53...\n2  63831.09  2932367 74.51707  26258.21 MULTIPOLYGON (((26.49433 55...\n\n\nA nice function to explore the differences between the two objects is waldo::compare(). It shows that, other than their classes, the two objects are identical:\n\nwaldo::compare(countries_new1, countries_new2)\n\n`class(old)`: \"sf\" \"tbl_df\" \"tbl\" \"data.frame\"\n`class(new)`: \"sf\"                \"data.frame\"\n\n\nSee the full list of file formats that you can read and write with sf with the following commands:\n\ndrvs = sf::st_drivers() |&gt;\n  as_tibble()\nhead(drvs)\n\n# A tibble: 6 × 7\n  name        long_name                    write copy  is_raster is_vector vsi  \n  &lt;chr&gt;       &lt;chr&gt;                        &lt;lgl&gt; &lt;lgl&gt; &lt;lgl&gt;     &lt;lgl&gt;     &lt;lgl&gt;\n1 PCIDSK      PCIDSK Database File         TRUE  FALSE TRUE      TRUE      TRUE \n2 netCDF      Network Common Data Format   TRUE  TRUE  TRUE      TRUE      FALSE\n3 PDS4        NASA Planetary Data System 4 TRUE  TRUE  TRUE      TRUE      TRUE \n4 VICAR       MIPL VICAR file              TRUE  TRUE  TRUE      TRUE      TRUE \n5 JP2OpenJPEG JPEG-2000 driver based on O… FALSE TRUE  TRUE      TRUE      TRUE \n6 PDF         Geospatial PDF               TRUE  TRUE  TRUE      TRUE      TRUE \n\n\n\n2.1.1 Exercises\n\nRe-create the country_centroids object, using world_centroids and poland and inputs, but this time using base R syntax with the [ operator.\n\nBonus: use the bench::mark() function to compare the performance of the base R and tidyverse implementation\nOpen question: Is this a good thing to benchmark? Why or why not?\n\n\n\nInspect the full list of drivers, e.g. with the command View(drvs).\n\nWhich formats are you likely to use and why?\nBonus: take a look at Chapter 8 of Geocomputation with R for more on reading and writing geographic (including raster) data with R."
  },
  {
    "objectID": "material/tidy.html#attribute-operations-with-dplyr",
    "href": "material/tidy.html#attribute-operations-with-dplyr",
    "title": "Tidy geographic data",
    "section": "2.2 Attribute operations with dplyr",
    "text": "2.2 Attribute operations with dplyr\ndplyr is a large package with many functions for working with data frames. The five key ‘verbs’ described as:\n\n\nmutate() adds new variables that are functions of existing variables\nselect() picks variables based on their names.\nfilter() picks cases based on their values.\nsummarise() reduces multiple values down to a single summary.\narrange() changes the ordering of the rows.\n\n\nLet’s take a brief look at each.\n\ncountries_modified = countries |&gt;\n  mutate(pop_density = pop / area_km2) |&gt;\n  select(name_long, pop_density) |&gt;\n  filter(pop_density &gt; 100) |&gt;\n  arrange(desc(pop_density))\ncountries_modified\n\nSimple feature collection with 3 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 12.24011 ymin: 47.75843 xmax: 24.02999 ymax: 54.85154\nGeodetic CRS:  WGS 84\n# A tibble: 3 × 3\n  name_long      pop_density                                                geom\n  &lt;chr&gt;                &lt;dbl&gt;                                  &lt;MULTIPOLYGON [°]&gt;\n1 Czech Republic        130. (((15.017 51.10667, 14.57072 51.00234, 14.30701 51…\n2 Poland                122. (((23.48413 53.9125, 23.24399 54.22057, 22.7311 54…\n3 Slovakia              115. (((22.55814 49.08574, 21.60781 49.47011, 20.88796 …\n\n\nThe summarise() function is often used in combination with group_by(), e.g. as follows:\n\ncountries_summarised = countries |&gt;\n  group_by(contains_a = str_detect(name_long, \"a\")) |&gt;\n  summarise(n = n(), mean_pop = mean(pop))\ncountries_summarised\n\nSimple feature collection with 2 features and 3 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 12.24011 ymin: 47.75843 xmax: 26.58828 ymax: 56.37253\nGeodetic CRS:  WGS 84\n# A tibble: 2 × 4\n  contains_a     n  mean_pop                                                geom\n  &lt;lgl&gt;      &lt;int&gt;     &lt;dbl&gt;                                       &lt;POLYGON [°]&gt;\n1 FALSE          1 10525347  ((15.017 51.10667, 14.57072 51.00234, 14.30701 51.…\n2 TRUE           3 15454250. ((26.49433 55.61511, 25.53305 56.1003, 25.00093 56…\n\n\nThe operation creates a new variable called contains_a that is TRUE if the country name contains an “a” and FALSE otherwise. Perhaps more impressively, it also automatically updated the geometry column of the combined countries containing the letter “a”, highlighting dplyr’s ability to work with geographic data represented as sf objects.\n\ncountries_summarised |&gt;\n  ggplot() +\n    geom_sf(aes(fill = contains_a)) +\n    geom_sf(data = countries, fill = NA, linetype = 3) \n\n\n\n\nFigure 2: Result of running dplyr group_by() and summarise() functions on countries data\n\n\n\n\n\n2.2.1 Exercises\n\nCreate a new data frame called countries_modified2 that contains the name, population and area of countries with a population density of more than 100 people per km2, sorted by area in descending order.\nDo the same with base R functions and the [ operator.\n\nWhat are the pros and cons of each?\nWhich do you prefer?"
  },
  {
    "objectID": "material/tidy.html#making-maps-with-ggplot2",
    "href": "material/tidy.html#making-maps-with-ggplot2",
    "title": "Tidy geographic data",
    "section": "2.3 Making maps with ggplot2",
    "text": "2.3 Making maps with ggplot2\nAs shown above, geom_sf() works ‘out of the box’ with geographic data. We can modify plotting commands to control outputs as showing in Figure 3 and generate publishable maps.\n\nlibrary(ggspatial)\n\nWarning: package 'ggspatial' was built under R version 4.3.2\n\ncountries |&gt;\n  ggplot() +\n    geom_sf(fill = \"grey80\", color = \"black\") +\n    geom_sf(data = countries_modified, aes(fill = pop_density)) +\n    scale_fill_viridis_c() +\n    theme_minimal()\n\n\n\n\nFigure 3: Map created with ggplot2, with fill color controlled by the pop_density variable and multiple layers.\n\n\n\n\nMap making is an iterative and time consuming process. Iterate on the code above, e.g. by changing the color palette, adding a title, and adding a legend.\nThere are many add-ons to ggplot2. ggspatial can be used to add a basemap to a plot with annotation_map_tile(), as illustrated in Figure 4.\n\nrosm::osm.types()\n\n [1] \"osm\"                    \"opencycle\"              \"hotstyle\"              \n [4] \"loviniahike\"            \"loviniacycle\"           \"stamenbw\"              \n [7] \"stamenwatercolor\"       \"osmtransport\"           \"thunderforestlandscape\"\n[10] \"thunderforestoutdoors\"  \"cartodark\"              \"cartolight\"            \n\nggplot() +\n  annotation_map_tile() +\n  layer_spatial(countries_modified, aes(fill = pop_density),\n                linewidth = 3, alpha = 0.3) +\n  scale_fill_viridis_c()\n\n\n\n\nFigure 4: Map created with ggplot2, with a basemap added with annotation_map_tile().\n\n\n\n\n\n2.3.1 Exercises\n\nWith reference to the documentation at ggplot2.tidyverse.org/index.html, modify the code above to create a map with a title, legend and a different color palette.\nWith reference to paleolimbot.github.io/ggspatial/, add annotations including scale bar, north arrow and a text label to the map.\nBonus: try map making with tmap and test out the interactive mode (set with tmap_mode(\"interactive\")).”\nBonus: try reproducing maps presented in Chapter 9 of Geocomputation with R with ggplot2 and ggspatial. Which mapping framework do you prefer and why?\nIf you use raster data, take a look at the tidyterra documentation."
  },
  {
    "objectID": "material/tidy.html#loading-a-gpx-file",
    "href": "material/tidy.html#loading-a-gpx-file",
    "title": "Tidy geographic data",
    "section": "3.1 Loading a GPX file",
    "text": "3.1 Loading a GPX file\nLet’s load a GPX file representing a route from the Faculty to FairPlayce.\n\nu_gpx = \"https://www.openstreetmap.org/trace/9741677/data\"\nf_gpx = paste0(basename(u_gpx), \".gpx\")\ndownload.file(u_gpx, f_gpx)\nsf::st_layers(f_gpx)\n\nDriver: GPX \nAvailable layers:\n    layer_name     geometry_type features fields crs_name\n1    waypoints             Point        0     23   WGS 84\n2       routes       Line String        0     12   WGS 84\n3       tracks Multi Line String        1     12   WGS 84\n4 route_points             Point        0     25   WGS 84\n5 track_points             Point     1525     26   WGS 84\n\ngpx = sf::read_sf(f_gpx, layer = \"track_points\")\n\nWe can divide the GPS points into n groups of equal length as follows:\n\ngpx_mutated = gpx |&gt;\n  mutate(minute = lubridate::round_date(time, \"minute\")) |&gt;\n  mutate(second = lubridate::round_date(time, \"second\")) \nsummary(gpx_mutated$minute)\n\n                      Min.                    1st Qu. \n\"2023-08-27 10:02:00.0000\" \"2023-08-27 10:20:00.0000\" \n                    Median                       Mean \n\"2023-08-27 10:36:00.0000\" \"2023-08-27 10:38:42.8065\" \n                   3rd Qu.                       Max. \n\"2023-08-27 10:59:00.0000\" \"2023-08-27 11:14:00.0000\" \n\n\nLet’s create an animated map, as illustrated in Figure 6, with the following code:\n\n# ?tmap_animation\nm_faceted = m_osm +\n  tm_shape(gpx_mutated[pois_buffer, ]) +\n  tm_dots(size = 0.8, legend.show = FALSE) +\n  tm_facets(\"second\", free.coords = FALSE, ncol = 1, nrow = 1) +\n  tm_scale_bar()\ntmap_animation(m_faceted, delay = 2, filename = \"gpx.gif\")\n\n\n\n\n\nFigure 6: Animated map of a GPX file representing a route from central Poznan to FairPlayce."
  },
  {
    "objectID": "material/tidy.html#exercises-3",
    "href": "material/tidy.html#exercises-3",
    "title": "Tidy geographic data",
    "section": "3.2 Exercises",
    "text": "3.2 Exercises\n\nCreate sf objects representing the following features in Poznan (hint: try using functions for geocoding such as stplanr::geo_code() or tmaptools::geocode_OSM()):\n\nThe main train station\nThe airport\n\nIdentify interesting features in the surrounding area from OSM and plot them in static and interactive maps."
  },
  {
    "objectID": "material/tidy.html#finding-suitable-coordinate-reference-systems",
    "href": "material/tidy.html#finding-suitable-coordinate-reference-systems",
    "title": "Tidy geographic data",
    "section": "4.1 Finding suitable coordinate reference systems",
    "text": "4.1 Finding suitable coordinate reference systems\ngeos is designed to work with projected data, so we will reproject the countries object to a different CRS before proceeding.\n\nsuitable_crs = crsuggest::suggest_crs(countries)\nsuitable_crs\n\n# A tibble: 10 × 6\n   crs_code crs_name                        crs_type crs_gcs crs_units crs_proj4\n   &lt;chr&gt;    &lt;chr&gt;                           &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;    \n 1 3328     Pulkovo 1942(58) / GUGiK-80     project…    4179 m         +proj=st…\n 2 2180     ETRF2000-PL / CS92              project…    9702 m         +proj=tm…\n 3 3120     Pulkovo 1942(58) / Poland zone… project…    4179 m         +proj=st…\n 4 2173     Pulkovo 1942(58) / Poland zone… project…    4179 m         +proj=st…\n 5 2172     Pulkovo 1942(58) / Poland zone… project…    4179 m         +proj=st…\n 6 2177     ETRF2000-PL / CS2000/18         project…    9702 m         +proj=tm…\n 7 2178     ETRF2000-PL / CS2000/21         project…    9702 m         +proj=tm…\n 8 8353     S-JTSK [JTSK03] / Krovak East … project…    8351 m         +proj=kr…\n 9 8352     S-JTSK [JTSK03] / Krovak        project…    8351 m         +proj=kr…\n10 5514     S-JTSK / Krovak East North      project…    4156 m         +proj=kr…\n\n\nWe’ll use the second of these, EPSG:2180, after checking (the package’s top suggestion is not always the most up-to-date or appropriate option).\n\ncrs1 = paste0(\"EPSG:\", suitable_crs$crs_code[2])\ncrs1\n\n[1] \"EPSG:2180\"\n\ncountries_projected = sf::st_transform(countries, crs = crs1)\n\n\ncountries_geos = as_geos_geometry(sf::st_geometry(countries_projected))\ncountries_geos\n\n&lt;geos_geometry[4] with CRS=ETRF2000-PL / CS92&gt;\n[1] &lt;MULTIPOLYGON [169518 135742...854986 777315]&gt;\n[2] &lt;MULTIPOLYGON [628064 681310...982752 961090]&gt;\n[3] &lt;MULTIPOLYGON [343349 -11504...759703 189400]&gt;\n[4] &lt;MULTIPOLYGON [18570 83048...489369 371643]&gt;  \n\n\nThe package only deals with geometries: the attribute data is removed when you convert an sf object to a geos object. You can store geos objects in a data frame and still use dplyr functions to process them:\n\ncountries_geos_df = bind_cols(countries_df, geos = countries_geos)\ncountries_summarised_df = countries_geos_df |&gt;\n  group_by(contains_a = str_detect(name_long, \"a\")) |&gt;\n  summarise(n = n(), mean_pop = mean(pop))\ncountries_summarised_df\n\n# A tibble: 2 × 3\n  contains_a     n  mean_pop\n  &lt;lgl&gt;      &lt;int&gt;     &lt;dbl&gt;\n1 FALSE          1 10525347 \n2 TRUE           3 15454250.\n\n\nNote: the geos column has gone! This is because geos columns are not ‘sticky’ like sf columns. Let’s see how to get them back.\n\ncountries_union1 = countries_geos |&gt;\n  geos_unary_union()\nplot(countries_union1)\ncountries_union2 = countries_geos |&gt;\n  geos_make_collection() |&gt;\n  geos_unary_union()\nplot(countries_union2)\n\n\n\n\n\n\n\n\n\n\n\nHowever, you can add the union of the grouped columns as follows:\n\ncountries_summarised_geos = countries_geos_df |&gt;\n  group_by(contains_a = str_detect(name_long, \"a\")) |&gt;\n  summarise(n = n(), mean_pop = mean(pop),\n  geometry = geos_unary_union(geos_make_collection(geos)))\ncountries_summarised_geos\n\n# A tibble: 2 × 4\n  contains_a     n  mean_pop geometry                                 \n  &lt;lgl&gt;      &lt;int&gt;     &lt;dbl&gt; &lt;geos_geom&gt;                              \n1 FALSE          1 10525347  &lt;POLYGON [18570 83048...489369 371643]&gt;  \n2 TRUE           3 15454250. &lt;POLYGON [169518 -11504...982752 961090]&gt;\n\nplot(countries_summarised_geos$geometry)\n\n\n\n\nConvert back to an sf object as follows:\n\ncountries_summarised_geos_sf = st_as_sf(countries_summarised_geos)\n# waldo::compare(\n#   countries_summarised,\n#   countries_summarised_geos_sf\n#   )\n\nAside from geometry names and minor differences in the geometries, the two objects are identical. This raises the question: why use geos at all? The answer can be found by following the exercises below."
  },
  {
    "objectID": "material/tidy.html#exercises-4",
    "href": "material/tidy.html#exercises-4",
    "title": "Tidy geographic data",
    "section": "4.2 Exercises",
    "text": "4.2 Exercises\n\nBenchmark the union operation in geos and sf with the bench::mark() function.\n\nWhich is faster?\nWhich is easier to use?\nWhich do you prefer?"
  },
  {
    "objectID": "material/tidy.html#getting-and-reading-in-the-data",
    "href": "material/tidy.html#getting-and-reading-in-the-data",
    "title": "Tidy geographic data",
    "section": "5.1 Getting and reading-in the data",
    "text": "5.1 Getting and reading-in the data\nTo get the data for this session, download and unzip the data.zip file in the releases. You can do that in R with the following commands:\n\nu = \"https://github.com/Robinlovelace/opengeohub2023/releases/download/data/data.zip\"\nf = basename(u)\nif (!dir.exists(\"data\")) {\n  download.file(u, f)\n  unzip(f)\n}\n\nCheck you have downloaded the files with the following command:\n\nlist.files(\"data\")[1:3]\n\n[1] \"gtfs\" \"hls\"  \"osm\""
  },
  {
    "objectID": "material/tidy.html#vector-data",
    "href": "material/tidy.html#vector-data",
    "title": "Tidy geographic data",
    "section": "5.2 Vector data",
    "text": "5.2 Vector data\nLet’s start by reading-in a dataset representing transport-related features around Poznan (note: you need to have downloaded and unzipped the data.zip file into your project or working directory for this to work):\n\npol_all = sf::read_sf(\"./data/osm/gis_osm_transport_a_free_1.shp\")\npol_all\n\nSimple feature collection with 282 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 15.76877 ymin: 51.42587 xmax: 18.51031 ymax: 53.52821\nGeodetic CRS:  WGS 84\n# A tibble: 282 × 5\n   osm_id    code fclass          name                                  geometry\n   &lt;chr&gt;    &lt;int&gt; &lt;chr&gt;           &lt;chr&gt;                            &lt;POLYGON [°]&gt;\n 1 27923283  5656 apron           &lt;NA&gt;                 ((16.84088 52.42479, 16.…\n 2 28396243  5656 apron           &lt;NA&gt;                 ((16.9675 52.32743, 16.9…\n 3 28396249  5656 apron           &lt;NA&gt;                 ((16.98029 52.32399, 16.…\n 4 28396250  5656 apron           &lt;NA&gt;                 ((16.97407 52.32418, 16.…\n 5 30164579  5656 apron           &lt;NA&gt;                 ((16.71011 53.16458, 16.…\n 6 32225811  5601 railway_station Czerwonak            ((16.9798 52.46868, 16.9…\n 7 36204378  5622 bus_station     &lt;NA&gt;                 ((16.95469 52.40964, 16.…\n 8 50701732  5651 airport         Lądowisko Poznań-Be… ((17.19788 52.53491, 17.…\n 9 55590985  5622 bus_station     Dworzec PKS-stanowi… ((17.20243 52.80927, 17.…\n10 56064358  5651 airport         Port lotniczy Zielo… ((15.76877 52.13175, 15.…\n# ℹ 272 more rows\n\n\nLet’s filter-out a feature that matches a particular character string:\n\npol = pol_all |&gt;\n  filter(str_detect(name, \"Port*.+Poz\"))\n\nPlot it, first with base R and then with {ggplot2}and {tmap}, resulting in maps shown below.\n\nplot(pol)\npol |&gt;\n  ggplot() +\n  geom_sf()\ntm_shape(pol) + tm_polygons()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe’ll read-in a point layer from a CSV file as shown below.\n\nstops_raw = read_csv('data/gtfs/stops.txt')\n\nRows: 2921 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): stop_code, stop_name, zone_id\ndbl (3): stop_id, stop_lat, stop_lon\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nstops_df = stops_raw |&gt;\n  select(-stop_code)\nstops = st_as_sf(stops_df, coords = c(\"stop_lon\", \"stop_lat\"), crs = \"EPSG:4326\")\n\n\n5.2.1 Buffers\nThe most widly used way to create buffers in R is with the function st_buffer() from the sf package. Let’s create buffers of 150 m around each of the points in the poi_sf dataset. This is done in the following chunk, which first checks to see if the s2 spherical geometry engine is set to run (it is by default).\n\nsf::sf_use_s2()\n\n[1] TRUE\n\npoi_buffers = st_buffer(poi_sf, dist = 150)\n\nAs described in Chapter 7 or Geocomputation with R, sf ‘knows that the world is round’ and uses a spherical geometry engine to calculate distances for unprojected data. This is a major advantage of sf over other packages for working with geographic data, such as GeoPandas in Python, which does not currently support spherical geometry operations (see issue 2098 in the GeoPandas issue tracker for details).\nWe can measure the area of the buffers with the following command:\n\nareas = st_area(poi_buffers)\n\nA nice feature of sf is that it returns the area in square meters, even though the input data is in degrees. sf uses the units package behind the scenes to convert between units, meaning you can convert the output to different units, as shown below.\n\nareas |&gt;\n  units::set_units(ha)\n\nUnits: [ha]\n[1] 7.165668 7.164428 7.165692 7.166715\n\n\nSometimes it’s useful to drop the units class, which can be done with the units::drop_units() function, as shown below.\n\nareas |&gt;\n  units::set_units(ha) |&gt;\n  units::drop_units() |&gt;\n  round()\n\n[1] 7 7 7 7\n\n\n\n\n5.2.2 Spatial subsetting\nNote: this section is adapted from Section 2.12 of Working with Spatial Data in Python. Let’s find the bus stops that are within 150 m of the poi_sf points.\n\nstops_nearby = stops[poi_buffers, ]\nstops_nearby\n\nSimple feature collection with 4 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 16.92882 ymin: 52.44307 xmax: 16.94161 ymax: 52.4653\nGeodetic CRS:  WGS 84\n# A tibble: 4 × 4\n  stop_id stop_name             zone_id            geometry\n    &lt;dbl&gt; &lt;chr&gt;                 &lt;chr&gt;           &lt;POINT [°]&gt;\n1     418 UAM Wydział Geografii A       (16.94108 52.46419)\n2     467 Umultowska            A       (16.92882 52.44426)\n3     468 Umultowska            A       (16.93039 52.44307)\n4     417 UAM Wydział Geografii A        (16.94161 52.4653)\n\n\n\n\n5.2.3 Spatial joins\nSpatial joins can be performed with the st_join() function as follows:\n\npois_joined = st_join(poi_buffers, stops)\npois_joined\n\nSimple feature collection with 6 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 16.92856 ymin: 52.44223 xmax: 16.95195 ymax: 52.46567\nGeodetic CRS:  WGS 84\n# A tibble: 6 × 5\n  name                                        geometry stop_id stop_name zone_id\n* &lt;chr&gt;                                  &lt;POLYGON [°]&gt;   &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;  \n1 Faculty        ((16.93959 52.46441, 16.93957 52.464…     418 UAM Wydz… A      \n2 Faculty        ((16.93959 52.46441, 16.93957 52.464…     417 UAM Wydz… A      \n3 Hotel ForZa    ((16.94759 52.44224, 16.94762 52.442…      NA &lt;NA&gt;      &lt;NA&gt;   \n4 Hotel Lechicka ((16.93275 52.44435, 16.93275 52.444…     467 Umultows… A      \n5 Hotel Lechicka ((16.93275 52.44435, 16.93275 52.444…     468 Umultows… A      \n6 FairPlayce     ((16.9477 52.461, 16.94765 52.46092,…      NA &lt;NA&gt;      &lt;NA&gt;   \n\n\n\n\n5.2.4 Exercises\n\nCreate a static map of the stops in Poznan, using the stops object created above, with a mapping package of your preference. Set the colour of each stop by zone_id.\n\nBonus: also create an interactive map.\n\nAdvanced: Reproduce the results presented above by following the Python code at geobgu.xyz/presentations/p_2023_ogh/01-vector.html.\n\nWhich language do you prefer for the types of task presented here and why?"
  },
  {
    "objectID": "material/tidy.html#raster-data-example",
    "href": "material/tidy.html#raster-data-example",
    "title": "Tidy geographic data",
    "section": "5.3 Raster data example",
    "text": "5.3 Raster data example\nBuilding on the introduction to raster data with Python, this section introduces raster data with the {terra} package.\nLoad it as follows:\n\nlibrary(terra)\n\nWarning: package 'terra' was built under R version 4.3.2\n\n\nterra 1.7.55\n\n\n\nAttaching package: 'terra'\n\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n\n\nRead-in and plot a single raster layer with the following command:\n\nsrc = rast('data/hls/HLS.S30.T33UXU.2022200T095559.v2.0.B02.tiff')\nterra::plot(src, col = gray.colors(10))\n\n\n\n\nFigure 7: Plotting a single raster layer with terra\n\n\n\n\nWe will translate the following Python code to R:\nfiles = glob.glob('data/hls/*.tiff')\n\nfiles = list.files(\"data/hls\", pattern = \"tiff\", full.names = TRUE)\nfiles\n\n[1] \"data/hls/HLS.S30.T33UXU.2022200T095559.v2.0.B02.tiff\"\n[2] \"data/hls/HLS.S30.T33UXU.2022200T095559.v2.0.B03.tiff\"\n[3] \"data/hls/HLS.S30.T33UXU.2022200T095559.v2.0.B04.tiff\"\n[4] \"data/hls/HLS.S30.T33UXU.2022200T095559.v2.0.B08.tiff\"\n\n\n\nr = rast(files)\nr\n\nclass       : SpatRaster \ndimensions  : 3660, 3660, 4  (nrow, ncol, nlyr)\nresolution  : 30, 30  (x, y)\nextent      : 6e+05, 709800, 5790240, 5900040  (xmin, xmax, ymin, ymax)\ncoord. ref. : WGS 84 / UTM zone 33N (EPSG:32633) \nsources     : HLS.S30.T33UXU.2022200T095559.v2.0.B02.tiff  \n              HLS.S30.T33UXU.2022200T095559.v2.0.B03.tiff  \n              HLS.S30.T33UXU.2022200T095559.v2.0.B04.tiff  \n              HLS.S30.T33UXU.2022200T095559.v2.0.B08.tiff  \nnames       : Blue, Green, Red, NIR_Broad \n\nsummary(r)\n\nWarning: [summary] used a sample\n\n\n      Blue            Green             Red           NIR_Broad   \n Min.   :-213.0   Min.   :  15.0   Min.   : -12.0   Min.   :  56  \n 1st Qu.: 202.0   1st Qu.: 435.0   1st Qu.: 313.0   1st Qu.:2088  \n Median : 319.0   Median : 617.0   Median : 586.0   Median :2469  \n Mean   : 342.3   Mean   : 623.7   Mean   : 669.2   Mean   :2648  \n 3rd Qu.: 434.0   3rd Qu.: 746.0   3rd Qu.: 955.0   3rd Qu.:3174  \n Max.   :4508.0   Max.   :5131.0   Max.   :5428.0   Max.   :6092  \n\n\nWe can plot the result as follows:\n\nplot(r)\n\n\n\n\nFigure 8: Output of plot(r), showing the four bands of the raster layer\n\n\n\n\nAs shown, the result is an object with Blue, Green, Red and NIR bands, in that order. We can select only Red, Green, Blue bands, in that order, as follows:\n\nr_rgb = r[[c(\"Red\", \"Green\", \"Blue\")]]\n\nIf you try plotting the result with plotRGB(r), you will get an error. You can use the stretch argument of the function to stretch the values and avoid errors caused by outliers.\n\nplotRGB(r, stretch = \"lin\")\n\n\n\n\nFigure 9: Plotting a RGB raster layer with terra\n\n\n\n\nWe can also remove outliers with the stretch() or clamp() functions or manually, as shown below:\n\n# r_clamp = clamp(r, 0, 4000)\nr_stretch = stretch(r_rgb, minq = 0.001, maxq = 0.999)\ntop_01pct = quantile(values(r_rgb), probs = 0.999, na.rm = TRUE)\nbottom_01pct = quantile(values(r_rgb), probs = 0.001, na.rm = TRUE)\nr_to_plot = r_rgb\nr_to_plot[r_rgb &gt; top_01pct] = top_01pct\nr_to_plot[r_rgb &lt; bottom_01pct] = bottom_01pct\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 10: Plotting a RGB raster layer with terra, with outliers handled with stretch() (left) and manually (right)\n\n\nSave the combined raster as follows:\n\n# write the r file:\nwriteRaster(r, \"data/hls/combined.tif\", overwrite = TRUE)\nwriteRaster(r_to_plot, \"data/hls/r_to_plot.tif\", overwrite = TRUE)\n\n\n5.3.1 Masking and cropping\nWe can mask the raster with the pol polygon object as follows:\n\npol_projected = sf::st_transform(pol, crs = crs(r))\nr_masked = mask(r, pol_projected)\n\n\n|---------|---------|---------|---------|\n=========================================\n                                          \n\nsummary(r_masked)\n\nWarning: [summary] used a sample\n\n\n      Blue            Green             Red           NIR_Broad     \n Min.   : 351.0   Min.   : 623.0   Min.   : 739.0   Min.   :1165    \n 1st Qu.: 482.0   1st Qu.: 744.8   1st Qu.: 803.0   1st Qu.:2136    \n Median : 526.0   Median : 775.0   Median : 892.0   Median :2338    \n Mean   : 578.1   Mean   : 843.7   Mean   : 963.0   Mean   :2228    \n 3rd Qu.: 569.2   3rd Qu.: 821.2   3rd Qu.: 985.2   3rd Qu.:2485    \n Max.   :1618.0   Max.   :2016.0   Max.   :2231.0   Max.   :2709    \n NA's   :100467   NA's   :100467   NA's   :100467   NA's   :100467  \n\n\nAs shown in the summary of the result, the majority of the values are now NA. That’s how masking works: it sets all values outside the polygon to NA. We can crop the raster to a 500 m buffer around the polygon as follows:\n\nr_cropped = crop(r, sf::st_buffer(pol_projected, dist = 500))\n\nLet’s plot the result, illustrated in Figure 11.\n\ntm_shape(stretch(r_cropped[[c(\"Red\", \"Green\", \"Blue\")]], minq = 0.001, maxq= 0.98)) +\n  tm_rgb() +\n  tm_shape(pol_projected) +\n  tm_borders(col = \"white\", lty = 3) +\n  tm_fill(col = \"red\", alpha = 0.1) +\n  tm_scale_bar(bg.color = \"white\", bg.alpha = 0.6, text.size = 0.8) \n\n\n\n\nFigure 11: Result of plotting a cropped RGB raster layer with the tmap package\n\n\n\n\n\n\n5.3.2 Exercises\n\nExperiment with arguments passed to clamp(), stretch() and plotRGB() to see how they affect the output.\nTry plotting the raster in another program like QGIS, which looks better?\nAdvanced: Reproduce the results presented above by following the Python code at geobgu.xyz/presentations/p_2023_ogh/02-raster.html.\n\nWhich language do you prefer for the types of task presented here and why?\n\nAdvanced: Try plotting the raster with {ggplot2} and {tmap}.\n\nWhich do you prefer and why?"
  },
  {
    "objectID": "material/tidy.html#tidypolars",
    "href": "material/tidy.html#tidypolars",
    "title": "Tidy geographic data",
    "section": "6.1 tidypolars",
    "text": "6.1 tidypolars\nIf you want to give this package a spin, run the following command:\n\ninstall.packages(\n  'tidypolars', \n  repos = c('https://etiennebacher.r-universe.dev/bin/linux/jammy/4.3', getOption(\"repos\"))\n)"
  },
  {
    "objectID": "material/tidy.html#rsgeo",
    "href": "material/tidy.html#rsgeo",
    "title": "Tidy geographic data",
    "section": "6.2 rsgeo",
    "text": "6.2 rsgeo\nA work in progress is the rsgeo package, which aims to provide an seamless interface between R and the geo Rust crate. This could open the possiblity of calling other high-performance Rust libraries from R, although the package is at an early stage of development and probably not ready for production use.\nWe can check the installation works as follows:\n\ninstall.packages('rsgeo', repos = c('https://josiahparry.r-universe.dev', 'https://cloud.r-project.org'))\n\n\nlibrary(rsgeo)\ncountries_rs  = as_rsgeo(sf::st_geometry(countries_projected))\ncountries_rs\nbench::mark(check = FALSE,\n  sf = sf::st_union(countries_projected),\n  geos = geos::geos_make_collection(geos::geos_unary_union(countries_geos)),\n  rsgeo = rsgeo::union_geoms(countries_rs)\n)"
  },
  {
    "objectID": "material/tidy.html#arrow",
    "href": "material/tidy.html#arrow",
    "title": "Tidy geographic data",
    "section": "6.3 Arrow",
    "text": "6.3 Arrow\n\nlibrary(arrow)\n\n# write countries_projected to parquet file:\nwrite_parquet(countries_projected, \"data/countries_projected.parquet\") # Fails"
  },
  {
    "objectID": "material/model_assessment.html",
    "href": "material/model_assessment.html",
    "title": "OpenGeoHub Summer School 2023, Poznan",
    "section": "",
    "text": "OpenGeoHub Summer School 2023, Poznan\n\n\nAlexander Brenning\n\n\nUniversity of Jena, Germany\n\n\n\n\n\nModel assessment with spatial cross-validation\n\n\nCase study: landslides in Ecuador\n\n\n\n\n\nFewer decimal places - works better for instructor:\noptions(digits=4)\nlibrary(“sperrorest”) # spatial CV library(“mgcv”) # GAM library(“rpart”) # CART library(“randomForest”) # Random forest\n\n\nLoad the saved training/test data:\nd &lt;- readRDS(“landslides.rds”)\n\n\nApply some transformations to the data:\nmy.trafo &lt;- function(x) { # Same for &gt;300m from deforestation: x\\(distdeforest[ x\\)distdeforest &gt; 300 ] &lt;- 300 # …and &gt;300m from road: x\\(distroad[ x\\)distroad &gt; 300 ] &lt;- 300 # Convert radians to degrees: x\\(slope &lt;- x\\)slope * 180 / pi x\\(cslope &lt;- x\\)cslope * 180 / pi # Log-transform size of catchment area - it is extremely skewed: x\\(log.carea &lt;- log10(x\\)carea) # Plan and profile curvature have outliers -&gt; trim both variables: x\\(plancurv[ x\\)plancurv &lt; -0.2 ] &lt;- -0.2 x\\(plancurv[ x\\)plancurv &gt; 0.2 ] &lt;- 0.2 x\\(profcurv[ x\\)profcurv &lt; -0.04 ] &lt;- -0.04 x\\(profcurv[ x\\)profcurv &gt; 0.04 ] &lt;- 0.04 return(x) }\nd &lt;- my.trafo(d)\n\n\nMake sure we use the exact same formula in all models:\nfo &lt;- slides89 ~ slope + plancurv + profcurv + log.carea + cslope + distroad + distdeforest\n\n\n\n\n\nStart by exploring spatial resampling in sperrorest\n\n\n\n\n\nResampling for non-spatial cross-validation:\n\n\n5 folds, 2 repetitions for illustration\nresamp &lt;- partition_cv(d, nfold=5, repetition=1:2) plot(resamp, d)\n\n\nTake a look inside:\n\n\nfirst repetition, second fold: row numbers\n\n\nof observations in the test set:\nidx &lt;- resamp[[“1”]][[2]]$test # test sample that would be used in this particular # repetition and fold: d[ idx , ]\n\n\nResampling for spatial cross-validation\n\n\nusing k-means clustering of coordinates:\nresamp &lt;- partition_kmeans(d, coords = c(“x”,“y”), nfold=5, repetition=1:2) plot(resamp, d) # Repeat this to get different partitions (depends on # data set; works better with nfold=10). # Use the seed1 argument to make your partitioning # reproducible.\np_load(“rpart”) # A wrapper function that extracts the predicted probabilities from rpart predictions: mypred_rpart &lt;- function(object, newdata) { predict(object, newdata, type=“prob”)[,2] } # Control parameters for rpart: ctrl &lt;- rpart.control(cp=0.003)\n\n\nPerform 5-repeated 5-fold non-spatial cross-validation:\nres &lt;- sperrorest(formula = fo, data = d, coords = c(“x”,“y”), model_fun = rpart, model_args = list(control=ctrl), pred_fun = mypred_rpart, smp_fun = partition_cv, smp_args = list(repetition=1:5, nfold=5)) # In “real life” we should use nfold=10 and repetition=1:100 !!! # plot(res\\(represampling, d) # may be too large to plot properly summary(res\\)error_rep) # More detailed, for each repetition: summary(res\\(error_rep, level=1) # Let's focus on AUROC on training and test set: summary(res\\)error_rep)[c(“train_auroc”,“test_auroc”),1:2] # Degree of overfitting (the more negative, the worse): diff( summary(res$error_rep)[c(“train_auroc”,“test_auroc”),“mean”] )\n\n\nLet’s get the values auroc recorded for each repetition\nauroc.test &lt;- unlist(summary(res\\(error_rep,level=1)[,\"test_auroc\"]) auroc.train &lt;- unlist(summary(res\\)error_rep,level=1)[,“train_auroc”]) mean(auroc.test) mean(auroc.train)\n\n\nWe can also summarize our results as a box plot\ndf_auroc &lt;- data.frame(training = auroc.train, testing = auroc.test) boxplot(df_auroc, ylab = “AUROC”, col = “lightblue”, ylim = c(0.5,1))\n\n\nPerform 5-repeated 5-fold SPATIAL cross-validation:\nres &lt;- sperrorest(formula = fo, data = d, coords = c(“x”,“y”), model_fun = rpart, model_args = list(control=ctrl), pred_fun = mypred_rpart, smp_fun = partition_kmeans, smp_args = list(repetition=1:5, nfold=5)) # Let’s focus on AUROC on training and test set: summary(res\\(error_rep)[c(\"train_auroc\",\"test_auroc\"),1:2] # Degree of overfitting (the more negative, the worse): diff( summary(res\\)error_rep)[c(“train_auroc”,“test_auroc”),“mean”] ) # Spatial cross-validation reveals overfitting that was not detected # by non-spatial cross-validation…\n\n\nNow let’s tidy up the code and do this for the GAM, CART and random forest.\n\n\n(Pick one method in class since this is computationally intensive.)\n\n\n\n\n\nGeneralized Additive Model\n\n\nlibrary(“mgcv”)\n\n\n\nmy_gam is a wrapper function that we need because mgcv::gam() requires\n\n\ns() terms in the formula object in order to produce nonlinear\n\n\nspline smoothers…\nmy_gam &lt;- function(formula, data, family = binomial, k = 4) { response.name &lt;- as.character(formula)[2] predictor.names &lt;- labels(terms(formula)) categorical &lt;- sapply(data[,predictor.names], is.logical) | sapply(data[,predictor.names], is.factor) formula &lt;- paste(response.name, “~”, paste(predictor.names[categorical], collapse = “+”), paste(“s(”, predictor.names[!categorical], “, k=”, k, “)”, collapse = “+”)) formula &lt;- as.formula(formula) # Return fitted GAM model: gam(formula, data, family = family, select = TRUE) }\n\n\nCheck that our wrapper function is working:\n\n\nfit &lt;- my.gam(fo,d)\n\n\nsummary(fit)\n\n\nplot(fit)\n\n\nPerform 5-repeated 5-fold non-spatial cross-validation:\nres &lt;- sperrorest(formula = fo, data = d, coords = c(“x”,“y”), model_fun = my_gam, pred_args = list(type=“response”), smp_fun = partition_cv, smp_args = list(repetition=1:5, nfold=5)) summary(res\\(error_rep)[c(\"train_auroc\",\"test_auroc\"),1:2] # Degree of overfitting (the more negative, the worse): diff( summary(res\\)error_rep)[c(“train_auroc”,“test_auroc”),“mean”] )\n\n\nPerform 5-repeated 5-fold spatial cross-validation:\nres &lt;- sperrorest(formula = fo, data = d, coords = c(“x”,“y”), model_fun = my_gam, pred_args = list(type=“response”), smp_fun = partition_kmeans, smp_args = list(repetition=1:5, nfold=5)) summary(res\\(error_rep)[c(\"train_auroc\",\"test_auroc\"),1:2] # Degree of overfitting (the more negative, the worse): diff( summary(res\\)error_rep)[c(“train_auroc”,“test_auroc”),“mean”] )\n\n\n\n\n\nClassification tree\n\n\nlibrary(“rpart”) # A wrapper function that extracts the predicted probabilities from rpart predictions: mypred_rpart &lt;- function(object, newdata) { predict(object, newdata, type=“prob”)[,2] } # Control parameters for rpart: ctrl &lt;- rpart.control(cp=0.003)\n\n\n\nPerform 5-repeated 5-fold non-spatial cross-validation:\nres &lt;- sperrorest(formula = fo, data = d, coords = c(“x”,“y”), model_fun = rpart, model_args = list(control=ctrl), pred_fun = mypred_rpart, smp_fun = partition_cv, smp_args = list(repetition=1:5, nfold=5)) summary(res\\(error_rep)[c(\"train_auroc\",\"test_auroc\"),1:2] # Degree of overfitting (the more negative, the worse): diff( summary(res\\)error_rep)[c(“train_auroc”,“test_auroc”),“mean”] )\n\n\nPerform 5-repeated 5-fold SPATIAL cross-validation:\nres &lt;- sperrorest(formula = fo, data = d, coords = c(“x”,“y”), model_fun = rpart, model_args = list(control=ctrl), pred_fun = mypred_rpart, smp_fun = partition_kmeans, smp_args = list(repetition=1:5, nfold=5)) summary(res\\(error_rep)[c(\"train_auroc\",\"test_auroc\"),1:2] # Degree of overfitting (the more negative, the worse): diff( summary(res\\)error_rep)[c(“train_auroc”,“test_auroc”),“mean”] )\n\n\n\n\n\nRandom forest\n\n\nlibrary(“randomForest”)\n\n\n\nExercise for you:\n\n\nTry using the random forest implementation in the ranger package instead!\n\n\nA wrapper function that extracts the predicted\n\n\nprobabilities from rpart predictions:\nmypred_rf &lt;- function(object, newdata) { predict(object, newdata, type=“prob”)[,2] }\n\n\nPerform 5-repeated 5-fold non-spatial cross-validation:\nres &lt;- sperrorest(formula = fo, data = d, coords = c(“x”,“y”), model_fun = randomForest, pred_fun = mypred_rf, smp_fun = partition_cv, smp_args = list(repetition=1:5, nfold=5)) summary(res\\(error_rep)[c(\"train_auroc\",\"test_auroc\"),1:2] # Degree of overfitting (the more negative, the worse): diff( summary(res\\)error_rep)[c(“train_auroc”,“test_auroc”),“mean”] )\n\n\nPerform 5-repeated 5-fold spatial cross-validation:\nres &lt;- sperrorest(formula = fo, data = d, coords = c(“x”,“y”), model_fun = randomForest, pred_fun = mypred_rf, smp_fun = partition_kmeans, smp_args = list(repetition=1:5, nfold=5)) summary(res\\(error_rep)[c(\"train_auroc\",\"test_auroc\"),1:2] # Degree of overfitting (the more negative, the worse): diff( summary(res\\)error_rep)[c(“train_auroc”,“test_auroc”),“mean”] )"
  },
  {
    "objectID": "material/model_interpretation.html",
    "href": "material/model_interpretation.html",
    "title": "OpenGeoHub Summer School 2023, Poznan",
    "section": "",
    "text": "OpenGeoHub Summer School 2023, Poznan\n\n\nAlexander Brenning\n\n\nUniversity of Jena, Germany\n\n\n\n\n\nModel interpretation\n\n\nCase study: Mapping crop types from Landsat imagery\n\n\n\n\n\nFewer decimal places - works better for instructor:\noptions(digits=4)\nlibrary(“sperrorest”) # PVI in spatial CV library(“randomForest”) # Random forest library(“rpart”) # CART library(“pdp”) # Partial dependence plots library(“ggplot2”) # Plotting\n\n\nLoad the data set:\nd &lt;- readRDS(“Maipo_fields.rds”)\n\n\nadd this many random noise variable to the data set:\np_noise &lt;- 10\n\n\nAdd 10 noise variables for illustrative purposes:\nfor(i in 0:p_noise){ d[paste(‘rdmvar’, i, sep = ““)] &lt;- rnorm(nrow(d)) }\n\nChoose one of the following formula objects:\nfo1 &lt;- croptype ~ ndvi01 + ndvi02 + ndvi03 + ndvi04 + ndvi05 + ndvi06 + ndvi07 + ndvi08 + rdmvar1\n\n\n\nUse a larger feature set than previously,\n\n\nincluding the ‘noise’ variables:\nfo2 &lt;- as.formula( paste(“croptype ~”, paste( paste(“b”, outer(1:8,2:7,paste,sep = ““), sep=”“), collapse=”+” ), “+”, paste( paste(“ndvi0”, 1:8, sep = ““), collapse=”+“),”+“, paste( paste(”ndwi0”, 1:8, sep = ““), collapse=”+“),”+“, paste( paste(”rdmvar”, 0:p_noise, sep = ““), collapse=”+“) )) # What have we done: fo2\n\n\nPick one of fo1, fo2:\nfo &lt;- fo1\n\n\n\n\nRandom Forest:\n\n\nstart with tools from the randomForest package\n\n\nfit &lt;- randomForest(fo, data = d) # try e.g. nodesize = 60\nrandomForest::varImpPlot(fit) # type = 1 (mean decrease in accuracy) won’t work with croptype data set??\n\n\n\n\nExamples of a PDP using function from randomForest package:\nd2 &lt;- d d2$croptype &lt;- NULL par(mfrow = c(2,2)) randomForest::partialPlot(fit, x.var = “ndvi04”, pred.data = d2, which.class = “crop1”) randomForest::partialPlot(fit, x.var = “ndvi04”, pred.data = d2, which.class = “crop2”) randomForest::partialPlot(fit, x.var = “ndvi04”, pred.data = d2, which.class = “crop3”) randomForest::partialPlot(fit, x.var = “ndvi04”, pred.data = d2, which.class = “crop4”)\nrf_imp &lt;- randomForest::importance(fit) top3 &lt;- names(rf_imp[order(rf_imp[,“MeanDecreaseGini”], decreasing = TRUE),])[1:3] partialPlot(fit, x.var = top3[1], pred.data = d, which.class = “crop1”, xlab = top3[1]) partialPlot(fit, x.var = top3[2], pred.data = d, which.class = “crop1”, xlab = top3[2]) partialPlot(fit, x.var = top3[3], pred.data = d, which.class = “crop1”, xlab = top3[3])\n\n\n\n\nRandom Forest:\n\n\nUse sperrorest for (spatial) variable importance\n\n\n\n\n\n\nCalculate importance for these variables:\nimp_vars &lt;- all.vars(fo)[-1] imp_vars\n\n\nPerform spatial cross-validation; using simplified settings to test the code:\nres &lt;- sperrorest(formula = fo, data = d, coords = c(“utmx”,“utmy”), model_fun = randomForest, model_args = list(ntree = 100), pred_args = list(type=“class”), smp_fun = partition_kmeans, smp_args = list(repetition=1:5, nfold=10), importance = TRUE, imp_permutations = 10, imp_variables = imp_vars) # Cross-validation estimate of error rate & accuracy: imp &lt;- summary(res$importance) # … a data.frame with results…\n\n\nE.g. mean decrease in accuracy when permuting ndvi01:\nimp[“ndvi04”, “mean.accuracy”] # Its standard deviation over the repetitions: imp[“ndvi04”, “sd.accuracy”]\nimp &lt;- imp[order(imp$mean.accuracy, decreasing = TRUE),] imp[1:5, c(“mean.accuracy”, “sd.accuracy”)]\n\n\nCreate a barplot - looks better with greater importances at the top:\nimp &lt;- imp[order(imp\\(mean.accuracy, decreasing = FALSE),] imp[1:5, c(\"mean.accuracy\", \"sd.accuracy\")] par(mar = c(5,7,1,1)) # bottom, left, top, right margins barplot(imp\\)mean.accuracy, names.arg = rownames(imp), horiz = TRUE, las = 1, xlab = “Mean decrease in accuracy”)\n\n\n\n\nRandom Forest:\n\n\nuse pdp package for partial dependence plots\n\n\n\n\n\n\nLet’s just focus on these three predictors for now:\ntop3 &lt;- rownames(imp[order(imp$mean.accuracy, decreasing = TRUE),])[1:3] # carefully read the ?partial help page! make sure you understand the settings! autoplot(pdp::partial(fit, pred.var = top3[1], which.class = “crop1”)) autoplot(pdp::partial(fit, pred.var = top3[2], which.class = “crop1”)) autoplot(pdp::partial(fit, pred.var = top3[3], which.class = “crop1”))\n\n\n…only looking at classification of crop1!\n\n\n\n\nRandom Forest:\n\n\nuse iml package for partial dependence and ALE plot\n\n\nlibrary(“iml”) # ML model interpretation library(“ggplot2”) # Plotting library(“patchwork”) # Plotting\n\n\n\n\nuse the smaller feature set, fo1:\nfo &lt;- fo1\nfit &lt;- randomForest(fo, data = d, importance = TRUE)\npredvars &lt;- all.vars(fo)[-1] predictors &lt;- d[, predvars] response &lt;- d$croptype\npredictor &lt;- iml::Predictor$new(fit, data = predictors, y = response)\n\n\nPermutation variable importance on the training set (!):\nimp &lt;- iml::FeatureImp$new(predictor, loss = “ce”, n.repetitions = 100, compare = “difference”) plot(imp)\n\n\nPVI, randomForest style (for comparison)\npar(mfrow = c(1,1)) varImpPlot(fit, type = 1)\n\n\nCalculate SHAP feature importance from Shapley values:\n\n\nThis is very SLOW and not parallelized!\nextract_shapleys &lt;- function(x) Shapley\\(new(predictor,  x.interest = predictors[x,],  sample.size = 10 # use default of 100! -&gt; slower  )\\)results$phi shaps &lt;- sapply(1:nrow(d), extract_shapleys) shap &lt;- apply(abs(shaps), 1, mean) # average over all four classes: shap &lt;- tapply(shap, rep(predvars, 4), mean) barplot(shap[order(shap)], horiz = TRUE, las = 1, xlab = “SHAP feature importance”)\n\n\nInteraction strength using iml package:\ninterac &lt;- iml::Interaction$new(predictor) plot(interac)\n\n\nndvi01, ndvi03 and ndvi04 showed the strongest interactions with other\n\n\npredictors, therefore take a closer look at how they interact:\ninterac &lt;- Interaction$new(predictor, feature = “ndvi01”) plot(interac)\ninterac &lt;- Interaction$new(predictor, feature = “ndvi03”) plot(interac)\ninterac &lt;- Interaction$new(predictor, feature = “ndvi04”) plot(interac)\n\n\nPDP / ALE plot using iml package (use method argument!):\neffs &lt;- iml::FeatureEffects$new(predictor, method = “pdp”, features = top3) plot(effs)\neffs &lt;- iml::FeatureEffects$new(predictor, method = “ale”, features = top3) plot(effs)\n\n\n\n\nRepeat the above for classification trees\n\n\nfit &lt;- rpart(fo, data = d, control = rpart.control(cp=0, maxdepth=5)) par(xpd=TRUE, mfrow=c(1,1)) plot(fit) text(fit, use.n = TRUE) par(xpd = FALSE)\n\n\n\n\nControl parameters for rpart:\nctrl &lt;- rpart.control(cp = 0, maxdepth = 5)\n\n\nCalculate importance for these variables:\nimp_vars &lt;- all.vars(fo)[-1] imp_vars\n\n\nPerform 5-repeated 10-fold spatial cross-validation:\nres &lt;- sperrorest(formula = fo, data = d, coords = c(“utmx”,“utmy”), model_fun = rpart, model_args = list(control=ctrl), pred_args = list(type=“class”), smp_fun = partition_kmeans, smp_args = list(repetition=1:5, nfold=10), importance = TRUE, imp_permutations = 10, imp_variables = imp_vars) # Cross-validation estimate of AUROC: imp &lt;- summary(res$importance) # … a data.frame with results…\n\n\nE.g. mean decrease in accuracy when permuting ndvi01:\nimp[“ndvi05”, “mean.accuracy”] # Its standard deviation over the repetitions: imp[“ndvi05”, “sd.accuracy”]\nimp &lt;- imp[order(imp$mean.accuracy, decreasing = TRUE),] imp[1:5, c(“mean.accuracy”, “sd.accuracy”)]\n\nVariable importance plot:\n\n\n\nCreate a barplot - looks better with greater importances at the top:\nimp &lt;- imp[order(imp\\(mean.accuracy, decreasing = FALSE),] par(mar = c(5,7,1,1)) # bottom, left, top, right margins barplot(imp\\)mean.accuracy, names.arg = rownames(imp), horiz = TRUE, las = 1, xlab = “Mean decrease in accuracy”)\n\nPartial dependence plots for the top-ranking predictors:\ntop3 &lt;- rownames(imp[order(imp$mean.accuracy, decreasing = TRUE),])[1:3] # carefully read the ?partial help page! make sure you understand the settings! autoplot(partial(fit, pred.var = top3[1], which.class = “crop1”)) autoplot(partial(fit, pred.var = top3[2], which.class = “crop1”)) autoplot(partial(fit, pred.var = top3[3], which.class = “crop1”))\n\n\n\nDo these plots accurately depict the classifier’s structure? (see tree plot!)\n\n\nWhat is missing?\n\n\nHint: Does it get better if we look at the following subsets:\nautoplot(partial(fit, pred.var = “ndvi04”, which.class = “crop1”, train = d[d\\(ndvi01 &lt; 0.4,])) autoplot(partial(fit, pred.var = \"ndvi04\", which.class = \"crop1\",  train = d[d\\)ndvi01 &gt;= 0.4,])) # …compared to: autoplot(partial(fit, pred.var = “ndvi04”, which.class = “crop1”))"
  },
  {
    "objectID": "material/index_r.html",
    "href": "material/index_r.html",
    "title": "Environmental analysis using satellite image time series in R",
    "section": "",
    "text": "Load the packages:\n\n#install.packages(\"pacman\")\npacman::p_load(\"tidyverse\", \"tsibble\", \"bfast\", \"data.table\", \"mgcv\",\"forecast\", \"zoo\", \"anytime\", \"fabletools\", \"signal\", \"fable\", \"tibble\")\n\nImport data - raw MTCI values from Sentinel-2 acquired from GEE:\n\ndf = read.csv(\"species_mtci.csv\")\nstr(df)\n\n'data.frame':   1446996 obs. of  3 variables:\n $ system.index: chr  \"20170329T095021_20170329T095024_T33UXR_00000000000000000042\" \"20170329T095021_20170329T095024_T33UXR_00000000000000000043\" \"20170329T095021_20170329T095024_T33UXR_00000000000000000044\" \"20170329T095021_20170329T095024_T33UXR_00000000000000000045\" ...\n $ MTCI        : num  NA NA NA NA NA NA NA NA NA NA ...\n $ species_cd  : chr  \"GB\" \"GB\" \"GB\" \"GB\" ...\n\nsummary(df)\n\n system.index            MTCI          species_cd       \n Length:1446996     Min.   :-8.2      Length:1446996    \n Class :character   1st Qu.: 1.3      Class :character  \n Mode  :character   Median : 3.1      Mode  :character  \n                    Mean   : 3.0                        \n                    3rd Qu.: 4.4                        \n                    Max.   :17.8                        \n                    NA's   :1430563                     \n\n\nAs you can see, there is a lot of NA values, also, if we plot index values there are a lot of outliers.\n\nplot(df$MTCI)\n\n\n\n\nModify column with date and change columns names:\n\ndf$system.index = as.Date(df$system.index, format =  \"%Y%m%d\")\nnames(df) = c(\"date\", \"index\", \"type\")\n\nFiltering values, removing NA, mean of duplicates:\n\ndf_clean = df %&gt;% \n  drop_na() %&gt;%\n  group_by(date, type) %&gt;%\n  summarise(index = mean(index)) %&gt;% \n  ungroup() %&gt;%\n  dplyr::filter(index &lt; 7 & index &gt; 0 & date &gt; \"2018-03-05\") \n\nggplot(df_clean, aes(date, index, color = type))+\n  geom_point()+\n  theme_light()\n\n\n\n\n\n\n\n\ndf_gb = df_clean %&gt;%\n  dplyr::filter(type == \"GB\")\nggplot(df_gb, aes(date, index))+\n  geom_line(color = \"darkgreen\", linewidth = 1)+\n  theme_light()\n\n\n\n\nFirstly, identify and replace outliers using simple linear interpolation:\n\ndf_gb$index_out = df_gb$index %&gt;% \n  tsclean()\n\nggplot(df_gb)+\n  geom_point(aes(date, index), color = \"red\")+\n  geom_point(aes(date, index_out), color = \"darkgreen\")+\n  theme_light()\n\n\n\n\n\n\n\n\ndf_gb$avg3 = rollmean(df_gb$index_out ,3, fill = NA)\ndf_gb$avg10 = rollmean(df_gb$index_out ,10, fill = NA)\n\nggplot(df_gb)+\n  geom_line(aes(date, index_out))+\n  geom_line(aes(date, avg3), color = \"blue\", linewidth = 1.0)+\n  geom_line(aes(date, avg10), color = \"red\", linewidth = 1.0)+\n  theme_light()\n\n\n\n\n\n\n\nWe need to create regular (1-day) time series with NA for missing values. And then interpolate the unknown values using na.approx() from the zoo package:\n\ndf_tsb = tsibble(df_gb[,c(1,4)], index = date, regular = TRUE) %&gt;%\n  fill_gaps() %&gt;%\n  mutate(approx = na.approx(index_out))\n\nApply Savitzky-Golay filter. n is a filter length (odd number) - test different values.\n\ndf_tsb$sg = df_tsb$approx %&gt;%\n  sgolayfilt(n = 71) \n\nAnalyze the results on plot - line represent time series smoothed by S-G, red dots - original values and blue dots - interpolated values\n\nggplot(df_tsb)+\n  geom_point(aes(date, approx), color = \"blue\", alpha = 0.2)+\n  geom_point(aes(date, index_out), color = \"red\", alpha = 0.7)+\n  geom_line(aes(date, sg), size = 1.1)+\n  theme_light()\n\n\n\n\n\n\n\nThe first step is the same as in Savitzky-Golay - we will create regular time series with NA values:\n\ndf_tsb_gam = tsibble(df_gb[,c(1,4)], index = date, regular = TRUE) %&gt;%\n  fill_gaps() %&gt;%\n  ts() %&gt;% #but here also we need to change date format from y-m-d to numeric (unix time)\n  as.data.frame()\n\nBut now we can go straight to modelling without dealing with missing values!\nGAM modelling with dates as predictor (Generalized Additive Mixed Models):\n\nmodel = gamm(df_tsb_gam$index_out ~ s(date, k = 60), \n             data = df_tsb_gam , method = \"REML\")\n\nPredicting values using GAM model and plotting the results:\n\ndf_tsb_gam$predicted = predict.gam(model$gam, df_tsb_gam)\ndf_tsb_gam$date = anydate(df_tsb_gam$date)\n\nggplot(df_tsb_gam)+\n  geom_point(aes(date, index_out), color = \"red\", alpha = 0.4)+\n  geom_line(aes(date, predicted), linewidth = 1)+\n  theme_light()\n\n\n\n\nCompare S-G (blue line) and GAM (black line):\n\ndf_tsb_gam$sg = df_tsb$sg\n\nggplot(df_tsb_gam)+\n  geom_point(aes(date, index_out), color = \"red\", alpha = 0.4)+\n  geom_line(aes(date, predicted), alpha = 0.8, linewidth = 1)+\n  geom_line(aes(date, sg), color = \"blue\", alpha = 0.8, linewidth = 1)+\n  theme_light()\n\n\n\n\n\nExcercise 1\nRead landsat_ndvi_veg_2.csv file and analyze the dataframe. Based on preliminary analysis, select one vegetation type, use cleaning/outlier removing if necessary, and perform one selected method smoothing/fitting. Finally, visualize the results and evaluate its performance! Pay attention to:\n\ncorrectly convert system.index variable to date format (use e.g. substr() function)\ndefining correct min and max values\npay attention to the date range\nwhen using moving average and SG - set appropriate window size (n)"
  },
  {
    "objectID": "material/index_r.html#part-1-pre-processing-and-smoothing-satellite-image-time-series",
    "href": "material/index_r.html#part-1-pre-processing-and-smoothing-satellite-image-time-series",
    "title": "Environmental analysis using satellite image time series in R",
    "section": "",
    "text": "Load the packages:\n\n#install.packages(\"pacman\")\npacman::p_load(\"tidyverse\", \"tsibble\", \"bfast\", \"data.table\", \"mgcv\",\"forecast\", \"zoo\", \"anytime\", \"fabletools\", \"signal\", \"fable\", \"tibble\")\n\nImport data - raw MTCI values from Sentinel-2 acquired from GEE:\n\ndf = read.csv(\"species_mtci.csv\")\nstr(df)\n\n'data.frame':   1446996 obs. of  3 variables:\n $ system.index: chr  \"20170329T095021_20170329T095024_T33UXR_00000000000000000042\" \"20170329T095021_20170329T095024_T33UXR_00000000000000000043\" \"20170329T095021_20170329T095024_T33UXR_00000000000000000044\" \"20170329T095021_20170329T095024_T33UXR_00000000000000000045\" ...\n $ MTCI        : num  NA NA NA NA NA NA NA NA NA NA ...\n $ species_cd  : chr  \"GB\" \"GB\" \"GB\" \"GB\" ...\n\nsummary(df)\n\n system.index            MTCI          species_cd       \n Length:1446996     Min.   :-8.2      Length:1446996    \n Class :character   1st Qu.: 1.3      Class :character  \n Mode  :character   Median : 3.1      Mode  :character  \n                    Mean   : 3.0                        \n                    3rd Qu.: 4.4                        \n                    Max.   :17.8                        \n                    NA's   :1430563                     \n\n\nAs you can see, there is a lot of NA values, also, if we plot index values there are a lot of outliers.\n\nplot(df$MTCI)\n\n\n\n\nModify column with date and change columns names:\n\ndf$system.index = as.Date(df$system.index, format =  \"%Y%m%d\")\nnames(df) = c(\"date\", \"index\", \"type\")\n\nFiltering values, removing NA, mean of duplicates:\n\ndf_clean = df %&gt;% \n  drop_na() %&gt;%\n  group_by(date, type) %&gt;%\n  summarise(index = mean(index)) %&gt;% \n  ungroup() %&gt;%\n  dplyr::filter(index &lt; 7 & index &gt; 0 & date &gt; \"2018-03-05\") \n\nggplot(df_clean, aes(date, index, color = type))+\n  geom_point()+\n  theme_light()\n\n\n\n\n\n\n\n\ndf_gb = df_clean %&gt;%\n  dplyr::filter(type == \"GB\")\nggplot(df_gb, aes(date, index))+\n  geom_line(color = \"darkgreen\", linewidth = 1)+\n  theme_light()\n\n\n\n\nFirstly, identify and replace outliers using simple linear interpolation:\n\ndf_gb$index_out = df_gb$index %&gt;% \n  tsclean()\n\nggplot(df_gb)+\n  geom_point(aes(date, index), color = \"red\")+\n  geom_point(aes(date, index_out), color = \"darkgreen\")+\n  theme_light()\n\n\n\n\n\n\n\n\ndf_gb$avg3 = rollmean(df_gb$index_out ,3, fill = NA)\ndf_gb$avg10 = rollmean(df_gb$index_out ,10, fill = NA)\n\nggplot(df_gb)+\n  geom_line(aes(date, index_out))+\n  geom_line(aes(date, avg3), color = \"blue\", linewidth = 1.0)+\n  geom_line(aes(date, avg10), color = \"red\", linewidth = 1.0)+\n  theme_light()\n\n\n\n\n\n\n\nWe need to create regular (1-day) time series with NA for missing values. And then interpolate the unknown values using na.approx() from the zoo package:\n\ndf_tsb = tsibble(df_gb[,c(1,4)], index = date, regular = TRUE) %&gt;%\n  fill_gaps() %&gt;%\n  mutate(approx = na.approx(index_out))\n\nApply Savitzky-Golay filter. n is a filter length (odd number) - test different values.\n\ndf_tsb$sg = df_tsb$approx %&gt;%\n  sgolayfilt(n = 71) \n\nAnalyze the results on plot - line represent time series smoothed by S-G, red dots - original values and blue dots - interpolated values\n\nggplot(df_tsb)+\n  geom_point(aes(date, approx), color = \"blue\", alpha = 0.2)+\n  geom_point(aes(date, index_out), color = \"red\", alpha = 0.7)+\n  geom_line(aes(date, sg), size = 1.1)+\n  theme_light()\n\n\n\n\n\n\n\nThe first step is the same as in Savitzky-Golay - we will create regular time series with NA values:\n\ndf_tsb_gam = tsibble(df_gb[,c(1,4)], index = date, regular = TRUE) %&gt;%\n  fill_gaps() %&gt;%\n  ts() %&gt;% #but here also we need to change date format from y-m-d to numeric (unix time)\n  as.data.frame()\n\nBut now we can go straight to modelling without dealing with missing values!\nGAM modelling with dates as predictor (Generalized Additive Mixed Models):\n\nmodel = gamm(df_tsb_gam$index_out ~ s(date, k = 60), \n             data = df_tsb_gam , method = \"REML\")\n\nPredicting values using GAM model and plotting the results:\n\ndf_tsb_gam$predicted = predict.gam(model$gam, df_tsb_gam)\ndf_tsb_gam$date = anydate(df_tsb_gam$date)\n\nggplot(df_tsb_gam)+\n  geom_point(aes(date, index_out), color = \"red\", alpha = 0.4)+\n  geom_line(aes(date, predicted), linewidth = 1)+\n  theme_light()\n\n\n\n\nCompare S-G (blue line) and GAM (black line):\n\ndf_tsb_gam$sg = df_tsb$sg\n\nggplot(df_tsb_gam)+\n  geom_point(aes(date, index_out), color = \"red\", alpha = 0.4)+\n  geom_line(aes(date, predicted), alpha = 0.8, linewidth = 1)+\n  geom_line(aes(date, sg), color = \"blue\", alpha = 0.8, linewidth = 1)+\n  theme_light()\n\n\n\n\n\nExcercise 1\nRead landsat_ndvi_veg_2.csv file and analyze the dataframe. Based on preliminary analysis, select one vegetation type, use cleaning/outlier removing if necessary, and perform one selected method smoothing/fitting. Finally, visualize the results and evaluate its performance! Pay attention to:\n\ncorrectly convert system.index variable to date format (use e.g. substr() function)\ndefining correct min and max values\npay attention to the date range\nwhen using moving average and SG - set appropriate window size (n)"
  },
  {
    "objectID": "material/index_r.html#part-2-detecting-trends-and-breaks",
    "href": "material/index_r.html#part-2-detecting-trends-and-breaks",
    "title": "Environmental analysis using satellite image time series in R",
    "section": "Part 2: Detecting trends and breaks",
    "text": "Part 2: Detecting trends and breaks\nIn this part we will use Savitzky-Golay smoothing and then try to detect breaks and trends in satellite time series for the part of Poznań\n\nChecking and smoothing selected pixels (samples)\nLoad the data (already pre-processed:)\n\ndf = read.csv(\"poznan_ndvi_clean.csv\")\nstr(df)\n\n'data.frame':   398387 obs. of  4 variables:\n $ X           : int  1 2 3 4 5 6 7 8 9 10 ...\n $ system.index: chr  \"2018-04-06\" \"2018-04-06\" \"2018-04-06\" \"2018-04-06\" ...\n $ pointid     : int  1 2 3 4 5 6 7 8 9 10 ...\n $ index       : num  0.395 0.365 0.427 0.405 0.454 ...\n\nsummary(df)\n\n       X          system.index          pointid           index        \n Min.   :     1   Length:398387      Min.   :   1.0   Min.   :-0.2184  \n 1st Qu.: 99598   Class :character   1st Qu.: 450.0   1st Qu.: 0.2277  \n Median :199194   Mode  :character   Median : 900.0   Median : 0.4004  \n Mean   :199194                      Mean   : 903.1   Mean   : 0.4344  \n 3rd Qu.:298791                      3rd Qu.:1357.0   3rd Qu.: 0.6487  \n Max.   :398387                      Max.   :1813.0   Max.   : 0.9997  \n\ndf = df[,-1]\ndf$system.index = as.Date(df$system.index, format = \"%Y-%m-%d\")\nnames(df) = c(\"date\", \"pointid\", \"index\")\n\n\nggplot(sample_n(df, 5000), aes(date, index))+\n  geom_point(alpha = 0.5)+\n  theme_light()\n\n\n\n\nCheck examples examples with pointid 551 - vegetation development; 1311 and 472 - new built-up; 1623 conifer trees; 1149 built up to green space\n\ndf_sel = df %&gt;%\n  dplyr::filter(pointid %in% c(472, 551,1149,1311, 1623))\n\nggplot(df_sel, aes(date, index, \n                   group = pointid, color = as.factor(pointid)))+\n  geom_line(linewidth = 1, alpha = 0.6)+\n  scale_color_manual(values = c(\"#FF6666\", \"green\", \"purple\", \"#FF9900\", \"darkgreen\"))+\n  theme_light()\n\n\n\n\nLet’s now check the just the place with vegetation development and than smooth the time series:\n\ndf_sel = df %&gt;%\n  dplyr::filter(pointid %in% c(551))\nggplot(df_sel, aes(date, index, \n                   group = pointid, color = as.factor(pointid)))+\n  geom_line(linewidth = 1)+\n  theme_light()\n\n\n\n\nBased on previous part, we will use Savitzky-Golay smoothing - to make it easier you can find the function with all necessary steps (e.g. producing regular time series) and applying S-G function. The input for this is id (pointid in our loaded dataframe) and input_df, with 3 variables: date, id, and index value.\n\nsg = function(id, input_df) {\n  df_sel = input_df %&gt;%\n    dplyr::filter(pointid == id)\n  df_tsb = tsibble(df_sel[,c(1,3)], index = date, regular = TRUE) %&gt;%\n    fill_gaps() %&gt;%\n    mutate(approx = na.approx(index))\n  df_tsb$sg = df_tsb$approx %&gt;%\n    sgolayfilt(n = 91) \n  df_tsb$id = id\n  return(df_tsb[,-2])\n}\n\n\nsg(551, df) %&gt;%\n  ggplot()+\n  geom_line(aes(date, sg), \n            alpha = 0.8, linewidth = 1)+\n  theme_light()\n\n\n\n\n\n\nTime series decomposition\nFirst example - vegetation development again:\n\ndf_sg = sg(551, df)\n\ndf_sg_ts = df_sg[,c(1,3)] %&gt;%\n  ts(frequency = 365)\n\ndf_sg_ts[,2] %&gt;% decompose() %&gt;%\n  plot()\n\n\n\n\nSecond example - new built up area in the vegetated land:\n\ndf_sg = sg(1068, df)\n\ndf_sg_ts = df_sg[,c(1,3)] %&gt;%\n  ts(frequency = 365)\n\ndf_sg_ts[,2] %&gt;% decompose() %&gt;%\n  plot()\n\n\n\n\nDifferent method - stl: Seasonal Decomposition of Time Series by Loess:\n\ndf_sg_ts[,2] %&gt;% \n  stl(s.window = 7) %&gt;%\n  plot()\n\n\n\n\n\n\nDetecting breaks\nDetect breaks using bfast function - firstly, apply S-G smoothing (the data should be a regular ts() object without NAs). This is the example for pixel no 1311.\n\nchange1 = sg(1311, df) %&gt;%\n  select(date, sg) %&gt;%\n  ts(frequency = 365)\n\nUse bfast function - which is an iterative break detection in seasonal and trend component of a time series; plot the results and the detected break date:\n\nfit = bfast(change1[,2], season = \"harmonic\", max.iter = 1, breaks = 1) \nplot(fit)\n\n\n\n\n\nanydate(change1[1] + fit$Time)\n\n[1] \"2021-11-23\"\n\n\nAnd another example\n\nchange1 = sg(472, df) %&gt;%\n  select(date, sg) %&gt;%\n  ts(frequency = 365)\nfit = bfast(change1[,2], season = \"harmonic\", max.iter = 1, breaks = 1) \nplot(fit)\n\n\n\n\n\nanydate(change1[1] + fit$Time)\n\n[1] \"2020-03-01\"\n\n\nAnother useful function is bfast01 which checks for one major break in the time series\n\nfit = bfast01(change1[,2]) \nplot(fit)\n\n\n\n\nThen these results can be, for example, joined with spatial data - and we can produce map of new built-up areas, like in the example below.\n\nStill, method is not perfect, you can try testing other parameters! :)\n\nExcercise 2 \nUse landsat_ndvi_veg_2.csv dataframe again and decompose the time series for selected vegetation type!"
  },
  {
    "objectID": "python_toolchain.html",
    "href": "python_toolchain.html",
    "title": "Mapping Explanation: Python Toolchain for Spatial Interpretative Machine Learning",
    "section": "",
    "text": "Date: 2023-08-31, 09:00–10:30 and 2023-08-31, 11:00–12:30\nSpeaker: Jarek Jasiewicz"
  },
  {
    "objectID": "python_toolchain.html#course-overview",
    "href": "python_toolchain.html#course-overview",
    "title": "Mapping Explanation: Python Toolchain for Spatial Interpretative Machine Learning",
    "section": "Course Overview",
    "text": "Course Overview\nThis course delved into interpretive machine learning methods applied to geospatial analysis. It focused on decomposing complex models to understand the criteria influencing outcomes in geospatial data. The comprehensive curriculum covered data preparation, model training, data transformation, analysis, and result interpretation, with a focus on spatial visualization. Tools like the SHAP library, and components of scikit-learn, geopandas, and matplotlib were featured.\nThis course offered an in-depth exploration of interpretive machine learning (IML) methods, tailored specifically for geospatial analysis. It began with a comprehensive theoretical foundation of IML, explaining how these advanced techniques can decompose complex, non-linear machine learning models. The primary focus was on understanding the decision-making processes within these ‘black box’ models, particularly in the context of geospatial data. The course covered the entire Python toolchain necessary for this analysis, from initial data preparation to the final stages of spatial visualization."
  },
  {
    "objectID": "python_toolchain.html#python-toolchain-and-methods",
    "href": "python_toolchain.html#python-toolchain-and-methods",
    "title": "Mapping Explanation: Python Toolchain for Spatial Interpretative Machine Learning",
    "section": "Python Toolchain and Methods:",
    "text": "Python Toolchain and Methods:\n\nData Preparation: Utilizing libraries like pandas and geopandas for manipulating and preparing spatial and non-spatial data.\nModel Training: Employing scikit-learn for building sophisticated machine learning models. Techniques like regression, classification, and clustering were explored in the context of spatial data.\nInterpretive Analysis: The course heavily focused on the SHAP (SHapley Additive exPlanations) library. SHAP values help in understanding the contribution of each feature to the prediction of a machine learning model, providing a deeper insight into the model’s decision process.\nData Transformation Process: Demonstrated how to transform raw data into formats suitable for interpretive analysis, such as converting geographic data into shapely objects.\nSpatial Visualization: Using matplotlib and other visualization tools for depicting complex spatial data patterns. The course emphasized the importance of effective visualization in conveying the nuances of IML findings."
  },
  {
    "objectID": "python_toolchain.html#case-study---u.s.-presidential-election-analysis",
    "href": "python_toolchain.html#case-study---u.s.-presidential-election-analysis",
    "title": "Mapping Explanation: Python Toolchain for Spatial Interpretative Machine Learning",
    "section": "Case Study - U.S. Presidential Election Analysis",
    "text": "Case Study - U.S. Presidential Election Analysis\nThe practical aspect of the course centered around the 2016 U.S. presidential election results, exploring Clinton vs. Trump. It involved collecting and transforming explanatory variables into shapely numbers, analyzing their impact on election outcomes in each county. This method highlighted spatial patterns in the electoral process, utilizing shapely numbers for efficient clustering and pattern revelation."
  },
  {
    "objectID": "python_toolchain.html#notebooks-overview",
    "href": "python_toolchain.html#notebooks-overview",
    "title": "Mapping Explanation: Python Toolchain for Spatial Interpretative Machine Learning",
    "section": "Notebooks Overview",
    "text": "Notebooks Overview\n\nMapping_Explanations.ipynb\nThis notebook serves as a comprehensive guide to the interpretive machine learning toolchain in Python, using the U.S. presidential election data. It walks through the process of data preparation, variable transformation, and pattern analysis using SHAP values.\n\n\n\n\nSupplementary_PCA.ipynb\nThis notebook focuses on Principal Component Analysis (PCA) in the context of interpretive machine learning. It demonstrates how PCA can be used to identify key patterns and clusters in the transformed geospatial data.\n\n\n\n\nSupplementary_Visual_Map_Series.ipynb\nThis notebook offers a deep dive into spatial visualization techniques. It illustrates how to effectively use Python’s mapping libraries to visualize complex spatial data and the patterns revealed through the interpretive machine learning process.\n```{=html} \n\n\nSupplementary_Waterfalls.ipynb\nThis notebook explores the waterfall plots method to understand the impact of various explanatory variables in the context of the U.S. presidential election results. It provides insights into the spatial dynamics of voting patterns.\n```{=html}"
  },
  {
    "objectID": "python_toolchain.html#final-thoughts",
    "href": "python_toolchain.html#final-thoughts",
    "title": "Mapping Explanation: Python Toolchain for Spatial Interpretative Machine Learning",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nThe course was an enlightening journey into the world of interpretive machine learning for geospatial data. It not only provided practical skills in Python toolchains but also offered a new perspective on analyzing and understanding complex spatial patterns."
  },
  {
    "objectID": "moving_pandas.html",
    "href": "moving_pandas.html",
    "title": "Data Engineering for Mobility Data Science (with Python and DVC)",
    "section": "",
    "text": "Date: 2023-08-31, 13:30–15:00 Speaker: Anita Graser"
  },
  {
    "objectID": "moving_pandas.html#course-overview",
    "href": "moving_pandas.html#course-overview",
    "title": "Data Engineering for Mobility Data Science (with Python and DVC)",
    "section": "Course Overview",
    "text": "Course Overview\nThis session was dedicated to exploring the integration of MovingPandas and DVC in Mobility Data Science. The course was designed for those with a basic understanding of (Geo)Pandas and version control systems like Git, focusing on practical applications of these advanced tools in mobility data analysis."
  },
  {
    "objectID": "moving_pandas.html#movingpandas",
    "href": "moving_pandas.html#movingpandas",
    "title": "Data Engineering for Mobility Data Science (with Python and DVC)",
    "section": "MovingPandas",
    "text": "MovingPandas\nMovingPandas stands as a powerful Python library for analyzing and visualizing movement data. Built on GeoPandas, it provides comprehensive functionalities to manipulate and plot trajectories, offering a robust toolkit for movement analytics. For examples of analytics supported by MovingPandas, attendees were encouraged to visit: MovingPandas Examples."
  },
  {
    "objectID": "moving_pandas.html#dvc-data-version-control",
    "href": "moving_pandas.html#dvc-data-version-control",
    "title": "Data Engineering for Mobility Data Science (with Python and DVC)",
    "section": "DVC (Data Version Control)",
    "text": "DVC (Data Version Control)\nDVC is a groundbreaking tool for data version control and machine learning experiment tracking. It operates similarly to source code version control systems, such as Git, but is geared towards managing data and experiments. In this session, DVC was used in tandem with Git to maintain a comprehensive track of movement data analytics workflows."
  },
  {
    "objectID": "moving_pandas.html#notebooks-overview",
    "href": "moving_pandas.html#notebooks-overview",
    "title": "Data Engineering for Mobility Data Science (with Python and DVC)",
    "section": "Notebooks Overview",
    "text": "Notebooks Overview\n\nIntroduction\nThis introductory notebook provided a foundational understanding of MovingPandas, demonstrating its capabilities in movement data analysis. It walked participants through the initial steps of data manipulation and trajectory plotting, setting the stage for more complex analytics.\n\n\n\n\nNotebook\nThis Notebook delved deeper into the application of MovingPandas and DVC in Mobility Data Science. This session highlighted the integration of these tools, showcasing how to effectively manage and version control large datasets and complex analytics workflows.\n\n\n\n\nTutorial Overview\nThe tutorial offered a comprehensive guide on the use of MovingPandas and DVC, from installation to practical application. It served as a valuable reference material for participants, providing step-by-step instructions and best practices in data engineering for mobility data science.\n```{=html}"
  },
  {
    "objectID": "moving_pandas.html#final-thoughts",
    "href": "moving_pandas.html#final-thoughts",
    "title": "Data Engineering for Mobility Data Science (with Python and DVC)",
    "section": "Final Thoughts",
    "text": "Final Thoughts\nThis course provided an insightful look into the innovative applications of MovingPandas and DVC in the field of Mobility Data Science. It emphasized the importance of efficient data engineering practices and the integration of advanced tools in handling complex movement data. The combination of theoretical knowledge and practical exercises made this session highly beneficial for professionals and enthusiasts in the field."
  },
  {
    "objectID": "sharing.html",
    "href": "sharing.html",
    "title": "Sharing Your Geospatial Knowledge in the Open",
    "section": "",
    "text": "Date: 2023-09-01, 11:00–12:30 Speaker: Jakub Nowosad"
  },
  {
    "objectID": "sharing.html#session-overview",
    "href": "sharing.html#session-overview",
    "title": "Sharing Your Geospatial Knowledge in the Open",
    "section": "Session Overview",
    "text": "Session Overview\nThis course, led by Jakub Nowosad, was an engaging and mostly improvised session on creating an online book with geospatial content. It emphasized the significance of sharing geospatial knowledge openly and effectively using tools like Quarto."
  },
  {
    "objectID": "sharing.html#importance-of-online-presence",
    "href": "sharing.html#importance-of-online-presence",
    "title": "Sharing Your Geospatial Knowledge in the Open",
    "section": "Importance of Online Presence",
    "text": "Importance of Online Presence\nJakub highlighted the crucial role of online visibility in the professional and academic world. He shared insights into how the online profiles of participants were considered during the summer school selection process, underscoring the value of having a strong digital footprint."
  },
  {
    "objectID": "sharing.html#personal-reflection",
    "href": "sharing.html#personal-reflection",
    "title": "Sharing Your Geospatial Knowledge in the Open",
    "section": "Personal Reflection",
    "text": "Personal Reflection\nAs an attendee, this course resonated deeply with me. I’ve already been keen on sharing my projects online for several reasons:\n\nIt provides a straightforward way to showcase my work and studies to others.\nSharing links to my website and GitHub has been instrumental in job applications.\nIt serves as personal documentation of my projects, helping me organize and present my work in a coherent and attractive manner."
  },
  {
    "objectID": "sharing.html#integrating-quarto-for-project-sharing",
    "href": "sharing.html#integrating-quarto-for-project-sharing",
    "title": "Sharing Your Geospatial Knowledge in the Open",
    "section": "Integrating Quarto for Project Sharing",
    "text": "Integrating Quarto for Project Sharing\nJakub’s presentation focused on the use of Quarto, a tool for creating dynamic and interactive online content. He demonstrated how Quarto can be used to share projects, code, and papers in a way that is not only visually appealing but also promotes reproducibility."
  },
  {
    "objectID": "sharing.html#link-to-personal-website-and-github",
    "href": "sharing.html#link-to-personal-website-and-github",
    "title": "Sharing Your Geospatial Knowledge in the Open",
    "section": "Link to Personal Website and GitHub",
    "text": "Link to Personal Website and GitHub\n\nWebsite: My Personal Website\nGitHub: My GitHub Profile"
  },
  {
    "objectID": "sharing.html#course-impact-and-application",
    "href": "sharing.html#course-impact-and-application",
    "title": "Sharing Your Geospatial Knowledge in the Open",
    "section": "Course Impact and Application",
    "text": "Course Impact and Application\nThis course inspired me to create this Quarto website, where summaries of other courses I’ve attended are shared. The session was a revelation in terms of digital content sharing, offering a new, interactive, and structured approach to presenting projects and research online."
  },
  {
    "objectID": "sharing.html#final-thoughts",
    "href": "sharing.html#final-thoughts",
    "title": "Sharing Your Geospatial Knowledge in the Open",
    "section": "Final Thoughts",
    "text": "Final Thoughts\n“Sharing Your Geospatial Knowledge in the Open” was an inspiring course that opened new avenues for me in terms of online content creation and sharing. It’s a testament to how digital platforms can enhance the visibility and impact of our work in the geospatial domain. In general, I am very grateful to be able to meet Jakub at the OpenGeoHub summer school, for the fantastic organisation and new inputs."
  },
  {
    "objectID": "index.html#event-overview",
    "href": "index.html#event-overview",
    "title": "OpenGeoHub Summer School 2023: Processing and Visualizing Large Geospatial Data Using R, Python, and Julia",
    "section": "",
    "text": "Dates: 27 August 2023 – 02 September 2023\nLocation: Adam Mickiewicz University, Poznan, Poland\nWebsite: OGHSummerSchool2023\nWelcome to my personal summary of the OpenGeoHub Summer School 2023. This year, the event, held at Adam Mickiewicz University in Poznan, focused on “Processing and Visualizing Large Geospatial Data Using R, Python, and Julia”. As a participant, I had the opportunity to dive into a range of topics, from data engineering in Python to geospatial analysis with Julia and R. This website is a curated collection of my experiences, offering insights into the courses I attended and the knowledge I gained. While this selection is not exhaustive, it represents the sessions that resonated most with me, both during the event and in my follow-up studies."
  },
  {
    "objectID": "index.html#whats-inside",
    "href": "index.html#whats-inside",
    "title": "OpenGeoHub Summer School 2023: Processing and Visualizing Large Geospatial Data Using R, Python, and Julia",
    "section": "What’s Inside",
    "text": "What’s Inside\n\nLive Presentations and Demos: Engaging sessions by leading R and OSGeo developers.\nInteractive Workshops: Hands-on experience with the latest geospatial tools and techniques.\nDiscussion Panels and Machine Learning Competitions: Opportunities for learning and showcasing skills.\nSocial Events: Excursions, games, and activities for networking and fun."
  },
  {
    "objectID": "index.html#social-activities",
    "href": "index.html#social-activities",
    "title": "OpenGeoHub Summer School 2023: Processing and Visualizing Large Geospatial Data Using R, Python, and Julia",
    "section": "Social Activities",
    "text": "Social Activities\n\nSunday, August 27: My journey began with a pleasant surprise upon discovering the local transport app – a true highlight. The dormitory at Adam Mickiewicz University exuded a unique soviet charm, and eduroam’s fear of commitment immediately reminded me of Augsburg. The evening unfolded with an exciting axe-throwing session, a novel way to meet fellow participants, followed by a delightful dinner at a Greek restaurant, humorously chosen by our Italian peers who, throughout the week, ensured we dined only at ‘Italian-approved’ eateries.\nMonday, August 28: The day started with a shared drive to the university, where Tom Hengl welcomed us with an overview of the week’s activities, including the upcoming hackathons. The coffee breaks, with their incredibly delicious cakes, were a daily highlight. The afternoon featured an intense ‘research speed dating’ session, a unique approach to networking and learning about each other’s work.\nTuesday, August 29: An outdoor excursion led us to the Morasko Sanctuary and its famous meteorite discovery site. Our guide, Miroslaw Makohonienko, captivated us with his enthusiasm and extensive knowledge about the area.\nWednesday, August 30: The day was marked by insightful discussion panels and opportunities for deeper networking with peers and experts.\nThursday, August 31: A ‘city, location-based game’ allowed us to explore Poznan in a fun and engaging way. The day concluded with a happy hour in a local pub, where we savored traditional Polish snacks.\nFriday, September 1: The final sessions of the summer school, including the announcement of the hackathon winners, marked the culmination of an intellectually enriching week.\nSaturday, September 2: Our adventure in Poznan continued with a full-day excursion, once again guided by the charismatic Miroslaw Makohonienko. Highlights included visits to the cathedral, the archaeological museum, and the fascinating Enigma Museum, a testament to the vital role of Polish mathematicians in World War II history."
  },
  {
    "objectID": "index.html#words-of-appreciation",
    "href": "index.html#words-of-appreciation",
    "title": "OpenGeoHub Summer School 2023: Processing and Visualizing Large Geospatial Data Using R, Python, and Julia",
    "section": "Words of Appreciation",
    "text": "Words of Appreciation\nI’m incredibly grateful for the opportunity to attend the OpenGeoHub Summer School. The event was not only educational but also an excellent platform for networking and sharing ideas. A big thank you to the OpenGeoHub Foundation and everyone involved in making this event a success. I look forward to applying the knowledge gained in my future projects and career.\n\nExplore the other pages for detailed summaries and insights from various courses held during the summer school."
  },
  {
    "objectID": "index.html#exploring-the-courses",
    "href": "index.html#exploring-the-courses",
    "title": "OpenGeoHub Summer School 2023: Processing and Visualizing Large Geospatial Data Using R, Python, and Julia",
    "section": "Exploring the Courses",
    "text": "Exploring the Courses\nThis website is structured as a collection of separate pages, each dedicated to a specific course I attended at the OpenGeoHub Summer School, either in person in Poznan or revisited later through provided documentation and videos. Due to the parallel scheduling of the sessions, I carefully selected courses that aligned closely with my interests and professional goals. On these pages, you’ll find detailed summaries, reflections, and key takeaways from each course, offering a glimpse into my learning journey and the diverse range of topics covered, from advanced geospatial data processing to innovative methods in data sharing and visualization. This selection provides a unique perspective on the depth and breadth of the summer school’s curriculum."
  },
  {
    "objectID": "r_lovelace.html#ressources",
    "href": "r_lovelace.html#ressources",
    "title": "Tidy Geographic Data in R",
    "section": "Ressources",
    "text": "Ressources\nCourse overview Github Video"
  },
  {
    "objectID": "xcube.html#materials",
    "href": "xcube.html#materials",
    "title": "xcube for Spatiotemporal Data Analysis and Visualization",
    "section": "Materials",
    "text": "Materials\nCourse overview Github Video"
  },
  {
    "objectID": "sharing.html#materials",
    "href": "sharing.html#materials",
    "title": "Sharing Your Geospatial Knowledge in the Open",
    "section": "Materials",
    "text": "Materials\nCourse overview Github Video"
  },
  {
    "objectID": "r_lovelace.html#materials",
    "href": "r_lovelace.html#materials",
    "title": "Tidy Geographic Data in R",
    "section": "Materials",
    "text": "Materials\nCourse overview Github Video"
  },
  {
    "objectID": "panel_discussion.html#materials",
    "href": "panel_discussion.html#materials",
    "title": "Combating Climate Crisis: Insights from R, Python, and Julia Communities",
    "section": "Materials",
    "text": "Materials\nCourse overview Video"
  },
  {
    "objectID": "moving_pandas.html#materials",
    "href": "moving_pandas.html#materials",
    "title": "Data Engineering for Mobility Data Science (with Python and DVC)",
    "section": "Materials",
    "text": "Materials\nCourse overview Github Video"
  },
  {
    "objectID": "env_time_series.html#materials",
    "href": "env_time_series.html#materials",
    "title": "Environmental Analysis Using Satellite Image Time Series",
    "section": "Materials",
    "text": "Materials\nCourse overview Github Video"
  },
  {
    "objectID": "clustering_spatial_r.html#materials",
    "href": "clustering_spatial_r.html#materials",
    "title": "Unsupervised Classification of Satellite Images",
    "section": "Materials",
    "text": "Materials\nCourse overview Github Video"
  },
  {
    "objectID": "julia.html#materials",
    "href": "julia.html#materials",
    "title": "Processing Geospatial Data with JuliaGeo",
    "section": "Materials",
    "text": "Materials\nCourse overview Github Video"
  },
  {
    "objectID": "openeo.html#materials",
    "href": "openeo.html#materials",
    "title": "Cloud-based Analysis of Earth Observation Data using openEO Platform, R, and Python",
    "section": "Materials",
    "text": "Materials\nCourse overview Github Video"
  },
  {
    "objectID": "python_toolchain.html#materials",
    "href": "python_toolchain.html#materials",
    "title": "Mapping Explanation: Python Toolchain for Spatial Interpretative Machine Learning",
    "section": "Materials",
    "text": "Materials\nCourse overview material Video"
  },
  {
    "objectID": "Sentinel.html#materials",
    "href": "Sentinel.html#materials",
    "title": "Sentinel Satellite Data Analysis Course",
    "section": "Materials",
    "text": "Materials\nCourse overview Github Video"
  },
  {
    "objectID": "spatial_ml.html#materials",
    "href": "spatial_ml.html#materials",
    "title": "Spatial ML model assessment and interpretation",
    "section": "Materials",
    "text": "Materials\nCourse overview Github Video"
  }
]